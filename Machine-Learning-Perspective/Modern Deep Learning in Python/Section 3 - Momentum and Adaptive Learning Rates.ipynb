{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Using Momentum to Speed Up Training\n",
    "We will now take a look at one of the most effective methods at improving plain gradient descent, called **momentum**. This can be thought of as the 80% factor to improve your learning procedure. \n",
    "\n",
    "A way to think of this is as follows: Gradient descent without momentum requires a *force* or *push* each time we want to get the weights to move. In other words, each time we want to move, there has to a be a gradient so that we can move in the direction of the gradient. If we had **momentum**, we can imagine that our update could keep moving, even without the gradient being present. \n",
    "\n",
    "This can be thought of as pushing a box on ice vs. pushing a box on gravel. If we are pushing the box on gravel, the minute we stop applying force, the box will also stop moving. This is analogous to gradient descent without momentum. However, if we were pushing the box on ice we could and then let go and it would continue moving for a period of time, before stopping. This is analogous to gradient descent with momentum. Another way to phrase this is as follows:\n",
    "> With momentum included in our update, our weight vector will build up a velocity in any direction that has a *consistent gradient*.\n",
    "\n",
    "Let's put this into math. \n",
    "\n",
    "## 1.1 Gradient Descent, *without* Momentum\n",
    "Our update for $\\theta$ can be described as:\n",
    "#### $$\\theta_t \\leftarrow \\theta_{t-1} - \\eta g_t$$\n",
    "This says that $\\theta_t$ is equal to the previous value of $theta$, minus the learning rate, times the gradient $g_t$. From this we can see that if the gradient is 0, nothing will happen to $\\theta_t$. It just gets updated to it's old value and doesn't change. \n",
    "\n",
    "## 1.2 Gradient Descent, *with* Momentum\n",
    "Now let's say that we add in **momentum**. Note that the term momentum is used very loosely here, since it has nothing to do with actual physical momentum. What we do is create a new variable, $v$, which stands for the velocity. It is equal to $\\mu$ (the momentum term) times its old velocity, minus the learning rate times the gradient. Notice that now, the gradient only directly influences the velocity, which in turn has an effect on the position (our weight vector), $\\theta$. \n",
    "\n",
    "#### $$v_t \\leftarrow \\mu v_{t-1} - \\eta g_t$$\n",
    "\n",
    "This new term, $\\mu v_{t-1}$, gives us the ability to \"slide on ice\" if you will. In other words, it allows us to continue to move in the same direction that we were going before. Now, we talked about how if a box is sliding on ice, it will still stop eventually. That means that we are going to want our updated $v$ to be a fraction of the prior $v$, and hence $\\mu$ should be a fraction. Typical values of $\\mu$ are 0.9, 0.95, 0.99, etc. This means that without any $g$, the equation will still eventually \"slow down\". Our update rule for $\\theta_t$ then becomes:\n",
    "\n",
    "#### $$\\theta_t \\leftarrow \\theta_{t-1} + v_t$$\n",
    "\n",
    "Now, if we combine these two equations we can see that our total update rule is:\n",
    "\n",
    "#### $$\\theta_t \\leftarrow \\theta_{t-1} + \\mu v_{t-1} -\\eta g_t $$\n",
    "\n",
    "And we can see that if we set the momentum term, $\\mu$, equal to zero, we end up with the same update rule we originally had for gradient descent. \n",
    "\n",
    "## 1.3 The Effect of Momentum\n",
    "You may be wondering, what is the effect of using momentum? Well we can see below that by using momentum, the cost converges to its minimum value much faster. This significantly speeds up training! \n",
    "\n",
    "<img src=\"images/momentum.png\">\n",
    "\n",
    "From another perspective, we can think of a situation where we have unequal gradients in different directions. In the image below, we have a very large gradient that creates the valley (each side is very steep), and then in the other direction (the stream flowing down), it is a very small gradient. \n",
    "\n",
    "<img src=\"images/large-small-gradient.png\">\n",
    "\n",
    "For visualization purposes, lets assume we have 2 parameters to optimize: the vertical and horizontal parameter. The gradient in one direction is very steep, and the gradient in the other direction is very shallow. The idea is that if you don't have momentum, then you rely purely on the gradient, which points more in the steep direction than in the shallow direction-this is just a property of the gradient, it is the direction of steepest descent. Since this gradient vector points more in the steep direction, we are going to zigzag back and forth across the valley. That is a very inefficient way of reaching the minimum. \n",
    "\n",
    "<img src=\"images/contours-momentum.png\">\n",
    "\n",
    "Once we add momentum, however, things change. Because in the shallow direction, we move in the same direction every time, those velocities are going to accumulate, so we will have a portion of our old velocity, added to our new velocity to help us along in that direction. The result is that we get there faster by taking bigger steps in the shallow direction of the gradient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br></br>\n",
    "# 2. Nesterov Momentum\n",
    "Nesterov momentum was coined by **Y Nesterov** in 1983. It is described as:\n",
    "> \"A method for unconstrained convex minimization problem with rate of convergence O(1/$k^2$)\"\n",
    "\n",
    "The core idea is that when the current weight vector is at some position, lets say $w$, then looking at original momentum update from earlier, we know that the momentum term alone (ignoring the term with the gradient), is about to nudge the parameter vector by $\\mu v_{t-1}$. Therefore, if we are about to compute the gradient, we can treat the future approximate position of $w$, $w + \\mu v_{t-1}$, as a \"lookahead\" - as in this is a point in the vicinity of where we are going to end up. Hence, it makes sense to compute the gradient at the $w + \\mu v_{t-1}$, instead of the old/stale position $w$. \n",
    "\n",
    "<br></br>\n",
    "<img src=\"images/nesterov-vs-normal.png\">\n",
    "\n",
    "The image above makes it clear that instead of evaluating the gradient at the current position of $w$, (red circle), we know that our momentum is about to carry us to the tip of the green arrow. With Nesterov momentum we therefore instead evaluate the gradient at this \"looked-ahead\" position. Also, keep in mind that in the image above the blue vector is referring to our update to the velocity, $v_t$, and not to the update of $w_t$. \n",
    "\n",
    "Okay, so we have a basic idea of **nesterov momentum** now, but let's just try and reiterate from a few different perspectives, to help is sink in. So, instead of just using momentum to blindly keep going in the direction that we were already going, let's instead peak ahead, by taking a big jump in the direction of the previous velocity, and calculate the gradient from there. We can think of it as though you are gambling, and if you are going to gamble it is better to take a big jump and then make a correction, than to make a correction and then gamble. \n",
    "\n",
    "<img src=\"images/nesterov1.png\">\n",
    "\n",
    "So first we peak ahead, jumping in the direction of the previous velocity (accumulated gradient): \n",
    "\n",
    "<img src=\"images/nesterov2.png\">\n",
    "\n",
    "We then measure the gradient, and go downhill in the direction of the gradient. We use that gradient to update our velocity (accumulated gradient). In other words, we combine the big jump with our gradient to get the accumulated gradient. So in a way, its peaking ahead and then course correcting based on where we would have ended up. \n",
    "\n",
    "<img src=\"images/nesterov3.png\">\n",
    "\n",
    "We then take that accumulated gradient (first green vector), multiply by some momentum constant, $\\mu$, and then we take the next big jump in the direction of that accumulated gradient. Again, at the place where we end up (head of second brown vector), we measure the gradient, we go downhill (second red vector) to correct any errors we have made, and we get a new accumulated gradient (second green vector)\n",
    "\n",
    "We can see that the blue vectors represent where we would go if we were using standard momentum, where we first measure the gradient where it currently is (small blue vector), and it adds that to the brown vector, and ends up making a jump by the big blue vector (first brown vector plus small blue vector, i.e. the current gradient). The brown vector represents our peak ahead value. Notice that it is in the same direction as the blue vector. The red vector is the gradient at the peak ahead value. The green vector is just the vector of the brown vector and the red vector. \n",
    "\n",
    "## 2.1 Nesterov Equations\n",
    "So, with the visuals discussed, what do the equations look like? First, we are going to use $w$ to represent our weights instead of $\\theta$. Also, the majority if this is looking at how we will update $v_t$, and the last step covers $w_t$. Now, lets start with the vector that represents the previous value of our weights, $w_{t-1}$, and the previous velocity, $v_{t-1}$:\n",
    "\n",
    "<img src=\"images/nesterov-eq-1.png\">\n",
    "\n",
    "Now, we have this jump ahead, which we can call $w'_{t-1}$. We can also think of it as just our previous weight position, plus the momentum step. It is in the same direction of our previous velocity vector (because remember, the first part of updating $v_t$ was the term $\\mu v_{t-1}$, but it is slightly smaller since the jump is scaled by $\\mu$:\n",
    "\n",
    "<img src=\"images/nesterov-eq-2.png\">\n",
    "\n",
    "#### $$look \\; ahead\\; value: \\; w'_{t-1} = w_{t-1} +\\mu v_{t-1}$$\n",
    "#### $$look \\; ahead\\; value: \\; w'_{t-1} = v_{t-1} +\\mu v_{t-1}$$\n",
    "\n",
    "The above equations are equivalent because both $w_{t-1}$ and $v_{t-1}$ both have the same position (head each vector). Also, note that as seen in the image above, the jump ahead is just the previous value of the velocity (or previous weight position, $w_{t-1}$), plus the momentum term multiplied by the previous velocity. Next, we calculate the gradient at this jump ahead point, and then use that to update $v$:\n",
    "\n",
    "<img src=\"images/nesterov-eq-3.png\">\n",
    "\n",
    "<img src=\"images/nesterov-eq-4.png\">\n",
    "\n",
    "#### $$v_t \\leftarrow \\mu v_{t-1} - \\eta \\nabla J(w'_{t-1})$$\n",
    "\n",
    "Which is equal to:\n",
    "\n",
    "#### $$v_t \\leftarrow \\mu v_{t-1} - \\eta \\nabla J(w_{t-1} +\\mu v_{t-1})$$\n",
    "\n",
    "And then the last step is to update $w_t$, the accumulated gradient, which is the same as it was for standard momentum:\n",
    "\n",
    "<img src=\"images/nesterov-eq-5.png\">\n",
    "\n",
    "#### $$w_t \\leftarrow w_{t-1} + v_t$$\n",
    "\n",
    "The main difference to note is that in the standard method we are taking the gradient from the current position of $w$, and also making our momentum step from the current position of $w$, whereas in the Nesterov method we first take our momentum step from the current position of $w$, then correct by taking the gradient from that position. For a great link that goes over this topic in more detail, checkout out the follow: http://cs231n.github.io/neural-networks-3/\n",
    "\n",
    "## 2.3 Reformulation\n",
    "However, in practice, this is not how nesterov momentum is usually implemented. Instead, we will reformulate the equations. Let's try and express everything only in terms of $w'$, our lookahead value of $w$, and it is where we want to calculate the gradient from. So, we can define $w'_t$ and $w'_{t-1}$ using the same definition:\n",
    "\n",
    "#### $$w'_t = w_t + \\mu v_t$$\n",
    "#### $$w'_{t-1} = w_{t-1} + \\mu v_{t-1}$$\n",
    "\n",
    "In other words, these are the lookahead values of $w$ at two consecutive steps. The second equation is seen in the below: \n",
    "\n",
    "<img src=\"images/nesterov-eq-6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
