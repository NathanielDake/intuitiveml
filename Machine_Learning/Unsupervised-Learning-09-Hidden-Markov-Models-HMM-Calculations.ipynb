{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Hidden Markov Model Calculations\n",
    "This appendix serves as an accompaniment to hidden markov models, discrete observations. We will go over calculations concerning:\n",
    "> 1. **Probability of a Sequence**\n",
    "2. **Forward-Backward Algorithm**\n",
    "3. **Viterbi Algorithm**\n",
    "4. **Baum-Welch Algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 0. General Definitions\n",
    "We will start by restating common variables that will be used throughout our calculations. \n",
    "\n",
    "#### 0.1 Hidden States and Observations\n",
    "We will let the number of hidden states be $M$:\n",
    "\n",
    "$$\\text{Number of hidden states} = M$$\n",
    "\n",
    "And the length of our sequence of observations be $T$:\n",
    "\n",
    "$$\\text{Length of sequence of observations} = T$$\n",
    "\n",
    "#### 0.2 Joint Distribution\n",
    "We know that the joint distribution containing both our observed symbols and hidden states is:\n",
    "\n",
    "$$p(x,z)$$\n",
    "\n",
    "Where both $x$ and $z$ are vectors:\n",
    "\n",
    "$$x = \\big[x(1), x(2), ..., x(T)\\big]$$\n",
    "\n",
    "$$z = \\big[z(1), z(2), ..., z(T)\\big]$$\n",
    "\n",
    "#### 0.3 Marginalized Distribution\n",
    "And we want to find the distribution for the sequence of observed symbols:\n",
    "\n",
    "$$p\\big(x(1), x(2),...,x(T)\\big)$$\n",
    "\n",
    "This is done by _marginalizing_ out $z$. \n",
    "\n",
    "#### 0.4 Initial State Distribution $\\pi$\n",
    "We have our _initial state distribution_, $\\pi$, the probability of being in a hidden state when the sequence begins:\n",
    "\n",
    "$$\\pi$$\n",
    "\n",
    "#### 0.5 State Transition Matrix $A$\n",
    "Then there is our _state transition matrix_, $A$, which represents the probability of going from state $i$ to state $j$:\n",
    "\n",
    "$$A(i, j) = \\text{probability of going from state i to state j}$$\n",
    "\n",
    "#### 0.6 Observation Matrix $B$\n",
    "Finally, we have our _observation matrix_, $B$, which represents the probability of observing symbol $k$ while in state $j$:\n",
    "\n",
    "$$B(j,k) = \\text{probability of observing symbol k while you are in state j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Probability of a Sequence\n",
    "We have gone over the equations utilized in determining the probability of a sequence, but we will now solidify that with an actual example. Here is the problem statement:\n",
    "\n",
    "> There is a magician who has two biased coins, _coin 1_ and _coin 2_ that he is flipping. We are trying to determine the probability of observing the following sequence of coin flips:<br>\n",
    "<br>\n",
    "$$p\\big(HHT \\big)$$<br>\n",
    "$$p\\big( x(1)=H, x(2)=H, x(3)=T \\big)$$<br>\n",
    "To start, we know that since the magician has two coins, the number of hidden states, $M$, is 2. We also know that we can either observe a flipped coin being heads or tails, so the number of possible observed symbols is also 2. We are told that the magician really likes coin 1, so the initial state distribution is:<br>\n",
    "<img src=\"https://drive.google.com/uc?id=1bgp8z4TzRf9LTBHvNQE9Hxg-y-bN6rIH\" width=\"150\">\n",
    "<br>\n",
    "He is also very figity, and tends to switch between coins very often, so his state transition matrix is:<br>\n",
    "<br>\n",
    "<img src=\"https://drive.google.com/uc?id=1uhaAJxF3n3B89UZLp5gxQoihF8WWm57z\" width=\"200\">\n",
    "<br>\n",
    "Finally, the coin 1 is biased towards heads and has a 0.7 probability of being heads, and a 0.3 probability of being tails. Coin 2 is biased towards tails, and has a 0.6 probability of being tails, and a 0.4 probability of being heads. Hence, the observation matrix looks like:<br>\n",
    "<img src=\"https://drive.google.com/uc?id=1aCMvAQ-MFjnOSwBZc7sWz-0f6upXDsLG\" width=\"200\">\n",
    "<br>\n",
    "\n",
    "We now have all of the information needed to find the probability of the sequence $H,H,T$. Intuitively, we can think about it as follows: We must first take into account the probability that we start in specific state, and from that state we observed heads. We then must account for the probability that from that state we transition to another hidden state and observe heads. And finally, we must take into the account that from the second hidden state we transition to _another_ hidden state and observe tails. Let's look at each part separately.\n",
    "\n",
    "#### 1.1 The probability of the Initial State\n",
    "We can write the probability of the initial state and observing heads as:\n",
    "\n",
    "$$\\pi\\big(z(1)\\big)p\\big(x(1)=1|z(1)\\big)$$\n",
    "\n",
    "#### 1.2 The probability of transitioning from state 1 to state 2\n",
    "\n",
    "$$p\\big(z(2)|z(1)\\big) = A\\big(z(1),z(2)\\big)$$\n",
    "\n",
    "#### 1.3 The probability of observing heads from state 2\n",
    "\n",
    "$$p\\big(x(2)=1|z(2)\\big) = B\\big(z(2),x(2)=1\\big)$$\n",
    "\n",
    "Now, if we repeated this process for transitioning from state 2 to 3, we would end up with the following equation:\n",
    "\n",
    "$$p\\big(x,z \\big) = \\pi\\big(z(1)\\big)p\\big(x(1)=1|z(1)\\big) * p\\big(z(2)|z(1)\\big) * p\\big(x(2)=1|z(2)\\big) * p\\big(z(3)|z(2)\\big) * p\\big(x(3)=0|z(3)\\big)$$\n",
    "\n",
    "Which we can then update by utilizing our matrices $A$ and $B$:\n",
    "\n",
    "$$p\\big(x,z \\big) = \\pi\\big(z(1)\\big)B\\big(z(2),x(2)=1\\big) * A\\big(z(1),z(2)\\big) * B\\big(z(2),x(2)=1\\big) * A\\big(z(2),z(3)\\big) * B\\big(z(3),x(3)=0\\big)$$\n",
    "\n",
    "Now, at this point we can see that there are multiple values that $z$ can take on, and that in order to find $p(x)$ we must marginalize out $z$, like so:\n",
    "\n",
    "$$\\sum_{z_1 = 1..M,..,z_3=1..M}\\pi\\big(z(1)\\big)B\\big(z(2),x(2)=1\\big) * A\\big(z(1),z(2)\\big) * B\\big(z(2),x(2)=1\\big) * A\\big(z(2),z(3)\\big) * B\\big(z(3),x(3)=0\\big)$$\n",
    "\n",
    "We can see that since $M$ is 2, and we have $T =3$ observations, there are going to be $2^3$ different operations (separate summations) that need to be performed in order to marginalize out $z$. That would be very messy to write out, be we will calculate it in code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Probability:  0.11169000000000001\n",
      "Total Operations:  40\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initial probability distribution and transition matrices\n",
    "pi = np.array([0.8, 0.2])\n",
    "A = np.array([[0.1, 0.9],[0.9, 0.1]])\n",
    "B = np.array([[0.7, 0.3],[0.4, 0.6]])\n",
    "x = np.array([0,0,1]) # 0 for heads, 1 for tails, based on numpy indexing\n",
    "operations_per_iteration = 5\n",
    "\n",
    "# Function to calculate the probability of the observed sequence for a given z1, z2, z3\n",
    "def sequence_probability_with_z(z1, z2, z3):\n",
    "  return pi[z1]*B[z2, x[0]] * A[z1, z2]*B[z2, x[1]] * A[z2, z3]*B[z3, x[2]]\n",
    "\n",
    "# Initial marginalized sequence probability and number of iterations performed\n",
    "marginalized_sequence_prob = 0\n",
    "iterations = 0\n",
    "\n",
    "# Calculate marginalized sequence probability: p(x1, x2, x3) -> p(H, H, T)\n",
    "Z = [0,1]\n",
    "for z1 in Z:\n",
    "  for z2 in Z:\n",
    "    for z3 in Z:\n",
    "      iterations += 1 \n",
    "      marginalized_sequence_prob += sequence_probability_with_z(z1, z2, z3)\n",
    "\n",
    "print('Sequence Probability: ', marginalized_sequence_prob)\n",
    "print('Total Operations: ', iterations * operations_per_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we finally arrive at our sequence probability:\n",
    "\n",
    "$$p(H,H,T) = 0.11$$\n",
    "\n",
    "#### 1.4 Complexity\n",
    "Note that in order to achieve this we needed to take the summation of 8 different calculations, consisting of $2T-1$ operations. From this, we know that the time complexity of this algorithm is $O(TM^T)$. Visually, this can be seen clearly below:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1eM-n-qtk2-GlWusX83cbc5OolW1Y3Mqu\" width=\"750\">\n",
    "\n",
    "We can see via simply counting operations in the above visualization, that there are 5 internal operations that must be performed. In our case, $T=3$, and hence:\n",
    "\n",
    "$$2T-1 = 5$$\n",
    "\n",
    "The summation goes through all of our states at each time step, and since $M=2$, we have:\n",
    "\n",
    "$$M^T = 2 ^ 3 = 2*2*2 = 8$$ \n",
    "\n",
    "Hence, our total number of operations for our example is: \n",
    "\n",
    "$$2T-1*M^T = 5 * 8 = 40$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# 2. Forward-Backward Algorithm\n",
    "At this point we are ready to move on to an algorithm that will help reduce the exponential complexity that we are dealing with above. This algorithm, _**the Forward-Backward**_ algorithm, works by defining a variable called $\\alpha$ that represents the joint probability of seeing the sequence you have observed up until now and being in a specific state at that time:\n",
    "\n",
    "$$\\alpha(t,i) = p \\big(x(1),...,x(t),z(t)=i\\big)$$\n",
    "\n",
    "We can see that $\\alpha$ is indexed by both time and $i$, the state.\n",
    "\n",
    "#### 2.1.1 Step 1 $\\rightarrow$ Initial Value of $\\alpha$\n",
    "The first step of the forward backward algorithm is to calculate the initial value of $\\alpha$ at $t=1$:\n",
    "\n",
    "$$\\alpha(1, i) = p \\big(x(1), z(1)=i\\big)$$\n",
    "\n",
    "$$\\alpha(1, i) =  p\\big(z(1) = i \\big) p\\big(x(1) \\mid z(1)= i\\big)$$\n",
    "\n",
    "Where, we know that:\n",
    "\n",
    "$$\\pi_i = p\\big(z(1) = i \\big)$$\n",
    "\n",
    "And also that:\n",
    "\n",
    "$$p\\big(x(1) \\mid z(1)= i\\big) = B\\big(i, x(1)\\big)$$\n",
    "\n",
    "So, we can rewrite our equation for $\\alpha(1,i)$ as:\n",
    "\n",
    "$$\\alpha(1,i) = \\pi_iB\\big(i, x(1)\\big)$$\n",
    "\n",
    "Now, in terms of our example, we know that we have $M=2$ states. Hence, we need to find $\\alpha$ for each starting state (coin 1 and coin 2):\n",
    "\n",
    "$$\\alpha(1,1) = \\alpha(1, \\text{coin 1}) = \\pi_1B\\big(z(1)=1, x(1)\\big)$$\n",
    "\n",
    "$$\\alpha(1,2) = \\alpha(1, \\text{coin 2})= \\pi_2B\\big(z(1)=2, x(1)\\big)$$\n",
    "\n",
    "#### 2.1.2 Key Points\n",
    "The first thing that I want you to take note of, is that that variable, $\\alpha$, will only be updated for _specific values_. Currently it only has _two values_; that for $t=1$ and coin 1, and $t=1$ with coin 2. From an implementation standpoint, $\\alpha$ will be a 2 dimensional matrix:\n",
    "\n",
    "```\n",
    "alpha = np.zeros((T, self.M))\n",
    "```\n",
    "\n",
    "The second key point is that the entire goal of this process is to find $p\\big(x(1)\\big)$. That may not be clear, or you may wonder why we have introduced this new variable $\\alpha$. To answer that, let's first write the equation for $p\\big(x(1)\\big)$:\n",
    "\n",
    "$$p\\big(x(1)\\big) = p\\big(z(1)=1\\big) p\\big(x(1) \\mid z(1) =1 \\big) +...+p\\big(z(1)=M\\big) p\\big(x(1) \\mid z(1) =M \\big)$$\n",
    "\n",
    "$$p\\big(x(1)\\big) = \\pi_1 B \\big(1, x(1) \\big) + \\pi_2 B \\big(2, x(1) \\big)+ ... +\\pi_M B \\big(M, x(1) \\big)$$\n",
    "\n",
    "But wait! We can see that this is our definition for $\\alpha(1,i)$! If we sum $\\alpha$ over the state $i$ when $t=1$, we end up with $p\\big(x(1)\\big)$. This leads us to the critical intuition:\n",
    "\n",
    "> $\\alpha$ is a way to successively keep track of the probability of a sequence.\n",
    "\n",
    "By creating $\\alpha$, we can keep track of the probability of a sequence up to a current point in time, while also taking advantage of certain properties of probability that allow us to reduce the total number of operations we need to perform (aka, we can reduce the time complexity). \n",
    "\n",
    "#### 2.1.3 Step 2 $\\rightarrow$ The Induction Step\n",
    "At that point, we come to the _induction step_. We are trying to find $p\\big(x(1), x(2)\\big)$ now. We know that the induction step is an updating of $\\alpha$ defined as:\n",
    "\n",
    "$$\\alpha(t+1, j) = \\sum_{i=1}^M \\alpha(t,i) A(i,j)B(j, x(t+1))$$\n",
    "\n",
    "Note, if we wanted to find $\\alpha(t+1, j)$ for _all values_ that $j$ can take on, we would simply take the summation with $j$ as the index. With that said, inuitively we can think of the induction step as follows (in relation to our magician example): At $t=1$ the magician in holding one of the coins-we are not sure which-and we observe him flip a heads. We then go to $t=2$, he shuffles the coins behind his back, and then flips one of the coins where we again observe a heads. What we want to know is, what is the probability of that happening?\n",
    "\n",
    "In order to determine that we must consider that the magician could transition from coin 1 or 2 at $t=1$, to coin 1 or 2 at $t=2$, where we then must determine the probability of observing $x(2)=heads$. This can be written as:\n",
    "\n",
    "$$\\pi_1A(1,1)B(1, x(2)=heads)+ \\pi_2A(2,1)B(1, x(2)=heads)+\\pi_1A(1,2)B(2, x(2)=heads)+ \\pi_2A(2,2)B(2, x(2)=heads)$$\n",
    "\n",
    "We can include $B$ for $t=1$ as well:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\pi_1B(1, x(1)=heads)A(1,1)B(1, x(2)=heads)+ \\pi_2B(2, x(1)=heads)A(2,1)B(1, x(2)=heads)+\\pi_1B(1, x(1)=heads)A(1,2)B(2, x(2)=heads)+ \\pi_2B(2, x(1)=heads)A(2,2)B(2, x(2)=heads)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahah! This is just $\\alpha$ at time $t=2$! Note, this is technically the _sum_ of $\\alpha$ at $t=2$, over $j$ states. We can represent $\\alpha$ at $t=2$ for each individual state below: \n",
    "\n",
    "$$\\alpha(t=2, j) = \\sum_{i=1}^M \\alpha(t,i) A(i,j)B(j, x(t+1))$$\n",
    "\n",
    "$$\\alpha(t=2, j=1) = \\sum_{i=1}^M \\alpha(t,i) A(i,j=1)B(j=1, x(t+1))$$\n",
    "\n",
    "$$\\alpha(t=2, j=1) = \\pi_1B(1, x(1)=heads)A(1,1)B(1, x(2)=heads)+ \\pi_2B(2, x(1)=heads)A(2,1)B(1, x(2)=heads)$$\n",
    "\n",
    "$$\\alpha(t=2, j=2) = \\sum_{i=1}^M \\alpha(t,i) A(i,j=2)B(j=2, x(t+1))$$\n",
    "\n",
    "$$\\alpha(t=2, j=2) = \\pi_1B(1, x(1)=heads)A(1,2)B(2, x(2)=heads)+ \\pi_2B(2, x(1)=heads)A(2,2)B(2, x(2)=heads)$$\n",
    "\n",
    "Again, in order to find the total probability of the sequence $p\\big(x(1), x(2)\\big)$, we would want to marginalize out the hidden state, in this case indexed by $j$:\n",
    "\n",
    "$$p\\big(x(1), x(2)\\big) = \\sum_{j=1..M} \\alpha(t=2, j)$$\n",
    "\n",
    "However, we do not need to perform that step just yet, since we still have one more observed symbol to consider.\n",
    "\n",
    "#### 2.1.4 Step 2 $\\rightarrow$ The Termination Step\n",
    "We finally reach the point where we are trying to calculate $p\\big(x(1), x(2), x(3)\\big)$. Now, in order to do this we must perform the exact same set of steps that we just performed above, where we calculates $\\alpha(t=3, j)$, for each hidden state $j$. The only difference is that now we must take the summation over $\\alpha(t=3, j)$, for all $j$. This gives us our final sequence probability:\n",
    "\n",
    "$$p\\big(x(1), x(2), x(3)\\big) = \\sum_{j=1..M} \\alpha(t=3, j)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Probability:  0.11865600000000001\n",
      "Total Operations:  19\n"
     ]
    }
   ],
   "source": [
    "# Initial M states, T time steps, and alpha forward variable\n",
    "M = 2\n",
    "T = 3 \n",
    "alpha = np.zeros((T, M))\n",
    "\n",
    "# Initial value step\n",
    "operations_initial = 0\n",
    "for i in range(M):\n",
    "  alpha[0,i] = pi[i]*B[i, x[0]]\n",
    "  operations_initial += 1\n",
    "\n",
    "# Induction Step\n",
    "iterations = 0\n",
    "operations_per_iteration = 2\n",
    "for t in range(1, T):\n",
    "  for j in range(M):\n",
    "    for i in range(M):\n",
    "      alpha[t, j] += alpha[t-1, i]*A[i,j]*B[j,x[t]]\n",
    "      iterations += 1\n",
    "\n",
    "sequence_probability = alpha[-1].sum()\n",
    "print('Sequence Probability: ', sequence_probability)\n",
    "print('Total Operations: ', iterations * operations_per_iteration + operations_initial + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then vectorize the above process as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Probability:  0.118656\n"
     ]
    }
   ],
   "source": [
    "# Initialize alpha forward variable\n",
    "alpha = np.zeros((T, M))\n",
    "\n",
    "# Initial Value Step\n",
    "alpha[0] = pi * B[:, x[0]]\n",
    "\n",
    "# Induction Step\n",
    "for t in range(1, T):\n",
    "  alpha[t] = alpha[t-1].dot(A) * B[:, x[t]]\n",
    "  \n",
    "\n",
    "sequence_probability = alpha[-1].sum()\n",
    "print('Sequence Probability: ', sequence_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5 Complexity\n",
    "Let's quickly determine our overall number of operations for the forward algorithm in our example. In order to find $\\alpha(t=1, 1)$ we need to perform 1 multiplication, and the same goes for $\\alpha(t=1, 2)$. So our initial value step requires two operations.\n",
    "\n",
    "Then, we have our induction step. Here we are trying to find $\\alpha(t=2, 1)$ and $\\alpha(t=2, 2)$. Each requires 4 operations, so a total of 8.\n",
    "\n",
    "We then hit our termination step, which will again require 8 operations, plus an additional operation to take the summation of $\\alpha$ at $t=3$ over $j$. So that is 9 operations. \n",
    "\n",
    "We end up with a total of:\n",
    "\n",
    "$$2 + 8 + 9 = 19 \\text{ operations}$$\n",
    "\n",
    "This matches what we found above in via code. From a big O standpoint, the initial 2 operations are a constant, as is the final 1 summation. That means that we are dealing with the induction steps complexity of $M^2$ at each time step (except the first); so $T-1$ time steps. Again, the $-1$ is a constant and we will be removed, leaving us with a complexity of $O(M^2T)$. Note, following this we would have expected to get $2^2*3 = 12 \\text{ operations}$, yet we came up with 19, why? This is because we were factoring in the number of operations inside of each summation, which is a constant $2$ operations. In other words, no matter how $T$ or $M$ change, it will always be $2$ operations:\n",
    "\n",
    "$$\\alpha(t,i) A(i,j)B(j, x(t+1))$$\n",
    "\n",
    "Where the first is $\\alpha*A$ and the second is $(\\alpha*A) * B$. Because these $2$ operations are a constant, they are dropped from the computational complexity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# 3.3 Viterbi Algorithm\n",
    "So far, the question that we have been asking is: _Given a sequence of observed symbols, what is the sequence's probability?_ Another question that we are likely to want to ask is:\n",
    "\n",
    "> What is the sequence of hidden states, given the observation?\n",
    "\n",
    "This is where the _**Viterbi Algorithm**_ comes in; it calculates the most probable hidden states sequence, given the observed sequence, under the current model. Now, we will be sure to highlight that the viterbi algorithm works in a very similar manner to the forward algorithm. Whereas in the Forward Algorithm for each induction step we would take the sum of the current row of $\\alpha$ (in effect marginalizing over all states of $z$), we are now going to take the _max_ of the row. \n",
    "\n",
    "To do this, we will create two new variables:\n",
    "\n",
    "$$\\delta(t,i) = max \\Big \\{p\\big(z(1), z(t)=i, x(1),...,x(t) \\big) \\Big \\}$$\n",
    "\n",
    "$$\\psi(t,i)$$\n",
    "\n",
    "* $\\delta(t,i)$, is indexed by time and state. This will represent the maximum probability of ending up in state $i$ at time $t$, which is a joint probability distribution over the state sequence and observed sequence.\n",
    "* $\\psi(t,i)$, which is also indexed by time and state. This will keep track of the actual state sequences that end up at time $t$ and in state $i$.\n",
    "\n",
    "#### 3.3.1 Step 1 $\\rightarrow$ Initialization\n",
    "As with the forward algorithm, the first step that we will take is to find the initial values of our new variables. \n",
    "\n",
    "$$\\delta(t,i) = \\pi_i B\\big(i, x(1)\\big)$$\n",
    "$$\\psi(1,i) = 0$$\n",
    "\n",
    "Note that the initialization of $\\delta$ is identical to that of $\\alpha$. In our magician example, we would again have $M=2$ states, so we need to find $\\delta(1, i = 1)$ and $\\delta(1, i = 1)$.\n",
    "\n",
    "$$\\delta(1,i=1) = \\pi_1 B\\big(1, x(1)\\big)$$\n",
    "\n",
    "$$\\delta(1,i=2) = \\pi_2 B\\big(2, x(1)\\big)$$\n",
    "\n",
    "$$\\psi(1,i = 1) = 0$$\n",
    "\n",
    "$$\\psi(1,i = 2) = 0$$\n",
    "\n",
    "Visually this can be seen below:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1iJHBiuyTAuey1F-qU0X03mdLACfArDnc\" width=\"350\">\n",
    "\n",
    "We can see that there are two paths that can be followed (in yellow and purple). The first represents the probability of starting with coin 1 and then observing heads ($\\delta(1,i=1)$), while the second represents the probability of starting with coin 2 and observing heads ($\\delta(1,i=2)$). Note that we do not need to take the maximum since there is only one potential option for each state $i$. \n",
    "\n",
    "#### 3.3.2 Step 2 $\\rightarrow$ Recursively Update\n",
    "We now have the _recursion_ step where we update our variables for all times and states:\n",
    "\n",
    "$$\\delta(t, j) = max_{1 \\leq i \\leq M} \\big \\{ \\delta(t-1, i) A(i,j)\\big \\} B\\big(j, x(t) \\big)$$\n",
    "\n",
    "$$\\psi(t,j) = argmax_{1 \\leq i \\leq M} \\big \\{ \\delta(t-1, i) A(i,j)\\big \\}$$\n",
    "\n",
    "In our case, we would first consider time step $t=2$. Visually, we can see the scenario below:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1ss3Wtgy8Zenm6ckmyuGUAw5rvnTG4cZB\" width=\"350\">\n",
    "\n",
    "We can see that for $z(2) = 1$, in other words for the second time step when the state is coin 1, there are _two ways we can get there_. We can come from the coin 1 ($\\delta(1,1)$), or from coin 2 ($\\delta(1,2)$). These paths are represented by the yellow arrows. The goal of this step is to determine which incoming path (yellow arrow) has a higher probability. In order to determine that we need to:\n",
    "\n",
    "1. Take into account the probability of being at the origin of each yellow arrow. Mathematically, that means taking into account $\\delta(1,1)$ and $\\delta(1,2)$.\n",
    "\n",
    "2. Take into account the probability of transitioning from the state $i$, to the state $j$. Mathematically, we will use the transition matrix, $A(i,j)$, for this.\n",
    "\n",
    "So, we can state our goal as follows:\n",
    "\n",
    "> For each state in the current time step, find the incoming state, $i$, that maximizes $\\delta(t-1, i) A(i,j)$. \n",
    "\n",
    "We can go through this for $t=2$ and state $j = 1$. In order to find $\\delta(2,1)$, we can perform the following calculation:\n",
    "\n",
    "$$\\delta(2,1) = max \\Big \\{ \\big(\\delta(1, 1) A(1,1)\\big), \\big(\\delta(1, 2) A(2,1)\\big) \\Big \\} B \\big(1, x(2) = heads\\big)$$\n",
    "\n",
    "And in order to find $\\psi(t, j)$:\n",
    "\n",
    "$$\\psi(2, 1) = argmax_i \\Big \\{ \\big(\\delta(1, i=1) A(i=1,1)\\big), \\big(\\delta(1, i=2) A(i=2,1)\\big) \\Big \\}$$\n",
    "\n",
    "A way to intuitively think of $\\psi$ is as follows. Let's say for a second that we have $\\psi(t=2, j =1)$ and $\\psi(t=2, j =2)$.\n",
    "\n",
    "* $\\psi(t=2, j =1)$ is representing the coin that was most likely transitioned _from_ in order to get to coin 1.\n",
    "* $\\psi(t=2, j =2)$ is representing the coin that was most likely transitioned _from_ in order to get to coin 2.\n",
    "\n",
    "#### 3.3.3 Step 3 $\\rightarrow$ Termination Step\n",
    "For the best state sequence, in the final best state, we can perform the following calculation:\n",
    "\n",
    "$$z(T)^* = argmax_{1 \\leq i \\leq M} \\delta(T, i)$$\n",
    "\n",
    "To determine the rest of the best state sequence, we just need to back track using $\\psi$. This is done for time equals $T-1$ all the way down to 1:\n",
    "\n",
    "$$z(t)^* = \\psi (t+1, z(t+1)^*)$$\n",
    "\n",
    "The idea behind this is that we know that taking the argmax over our $\\delta$ with respect to $i$ will give us the final state. Once we know that, recall that our variable $\\psi$ is designed to keep track of what coin we most likely came from in order to get the current one. In other words, once we know our last state (by taking the argmax of $\\delta$), we can use $\\psi$ in order to find what coin we most likely transitioned from to get there. That will be our coin for the previous time step, at which point we can use $\\psi$ again! This is what is meant by _back tracking_.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta: \n",
      " [[0.56     0.08    ]\n",
      " [0.0504   0.2016  ]\n",
      " [0.054432 0.027216]]\n",
      "psi: \n",
      " [[0. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]] \n",
      "\n",
      "Hidden State Sequence (by index): \n",
      " [0 1 0] \n",
      "\n",
      "Hidden State Sequence (by coin label):  ['coin 1', 'coin 2', 'coin 1']\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to zeros matrices\n",
    "delta = np.zeros((T, M)) \n",
    "psi = np.zeros((T, M))\n",
    "\n",
    "# Initial value step\n",
    "for i in range(M):\n",
    "  delta[0, i] = pi[i]*B[i, x[0]]\n",
    "  psi[0,i] = 0 \n",
    "  \n",
    "# Recursion Step\n",
    "for t in range(1, T):\n",
    "  for j in range(M):\n",
    "    current = np.array([])\n",
    "    for i in range(M):\n",
    "      current = np.append(current, delta[t-1, i]*A[i, j])\n",
    "    currentMax = current.max()\n",
    "    currentArgMax = current.argmax()\n",
    "    delta[t, j] = currentMax * B[j, x[t]]\n",
    "    psi[t, j] = currentArgMax\n",
    "    \n",
    "print('delta: \\n', delta)\n",
    "print('psi: \\n', psi, '\\n')\n",
    "\n",
    "# Back Track\n",
    "states = np.zeros(T, dtype=np.int32)\n",
    "states[T-1] = np.argmax(delta[T-1])\n",
    "for t in range(T-2, -1, -1):\n",
    "  states[t] = psi[t+1, states[t+1]]\n",
    "print('Hidden State Sequence (by index): \\n', states, '\\n')\n",
    "\n",
    "# Map states to coin 1 and 2\n",
    "print('Hidden State Sequence (by coin label): ', \n",
    "      list(map(lambda state: 'coin 1' if state == 0 else 'coin 2', states))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Baum-Welch Algorithm\n",
    "The Baum-Welch Algorithm begins by performing the forward-backward algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi = np.array([0.8, 0.2])\n",
    "A = np.array([[0.1, 0.9],[0.9, 0.1]])\n",
    "B = np.array([[0.7, 0.3],[0.4, 0.6]])\n",
    "x = np.array([0,0,1]) # 0 for heads, 1 for tails, based on numpy indexing\n",
    "\n",
    "# Initial M states, T time steps, and alpha forward variable\n",
    "M = 2\n",
    "T = 3 \n",
    "alpha = np.zeros((T, M))\n",
    "beta = np.zeros((T, M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate the forward variable $\\alpha$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initial value step\n",
    "operations_initial = 0\n",
    "for i in range(M):\n",
    "  alpha[0,i] = pi[i]*B[i, x[0]]\n",
    "  operations_initial += 1\n",
    "\n",
    "# Induction Step\n",
    "iterations = 0\n",
    "operations_per_iteration = 2\n",
    "for t in range(1, T):\n",
    "  for j in range(M):\n",
    "    for i in range(M):\n",
    "      alpha[t, j] += alpha[t-1, i]*A[i,j]*B[j,x[t]]\n",
    "      iterations += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can calculate the backward variable $\\beta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initial value step\n",
    "operations_initial = 0\n",
    "for i in range(M):\n",
    "  beta[T-1,i] = 1\n",
    "  \n",
    "# Induction Step\n",
    "for t in range(T-2, -1, -1):\n",
    "  for i in range(M):\n",
    "    for j in range(M):\n",
    "      beta[t, i] += A[i,j] * B[j, x[t+1]] * beta[t+1, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of Alpha after forward algorithm: \n",
      " [[0.56     0.08    ]\n",
      " [0.0896   0.2048  ]\n",
      " [0.057984 0.060672]] \n",
      "\n",
      "Value of Beta after forward algorithm: \n",
      " [[0.1587 0.3723]\n",
      " [0.57   0.33  ]\n",
      " [1.     1.    ]]\n"
     ]
    }
   ],
   "source": [
    "print('Value of Alpha after forward algorithm: \\n', alpha, '\\n')\n",
    "print('Value of Beta after forward algorithm: \\n', beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
