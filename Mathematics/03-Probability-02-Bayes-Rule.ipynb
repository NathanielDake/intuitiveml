{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bayes Rule\n",
    "The main goal of this post is to dig a bit further into Bayes rule, from a purely probabilistic perspective! Before we begin I do want to make one note; a great deal of the power of Bayes Rule comes in the form of bayesian inference and bayesian statistics, which can be found in the statistics section. I would recommend reading both of those posts as well if you are interested, since they demonstrate the application of Bayes rule to real world problems. If you have caught the bayesian bug at that point then I recommend reading my posts on Bayesian AB testing, found in the Machine Learning section. \n",
    "\n",
    "One more thing to note: I am going to hold of on explaining the importance of Bayes Rule until the end, and its many use cases will in reality be spread throughout the aformentioned posts. Just another reason to go through them all. With that out of the way, let's begin! \n",
    "\n",
    "## 1.1 Mathematical Definition\n",
    "We worked with Bayes Rule briefly in the probability introduction, but just to recap, it can be derived as follows:\n",
    "\n",
    "We know that the below statement represents the conditional probability of $A$ given $B$:\n",
    "\n",
    "$$p(A \\mid B)=\\frac{p(A,B)}{p(B)}$$\n",
    "\n",
    "And we also know that the opposite is also true:\n",
    "\n",
    "$$p(B \\mid A)=\\frac{p(B,A)}{p(A)}$$\n",
    "\n",
    "And since:\n",
    "\n",
    "$$p(A,B)=p(B,A)$$\n",
    "\n",
    "We can write:\n",
    "\n",
    "$$p(A \\mid B)=\\frac{p(B \\mid A)*p(A)}{p(B)}$$\n",
    "\n",
    "Now, often times we may not have $p(B)$ directly, but this is just the marginal distribution of the joint probability $p(A,B)$, summed over all $p(A)$. It looks like:\n",
    "\n",
    "$$p(B)=\\sum_ip(A_i,B) = \\sum_ip(B \\mid A_i)*p(A_i)$$\n",
    "\n",
    "If we are working with continuous distributions, sum turns into an integral. \n",
    "\n",
    "Another way to think of this, is that the term on the bottom is just a normalization constant (Z) to ensure that the distribution sums to one. \n",
    "\n",
    "$$p(A \\mid B)=\\frac{p(B \\mid A)*p(A)}{Z}$$\n",
    "\n",
    "Another way of saying this, is that they are proportional:\n",
    "\n",
    "$$p(A \\mid B)\\propto p(B \\mid A)*p(A)$$\n",
    "\n",
    "Now this is a very powerful fact! Because the denominator ($p(B)$) does not depend on $A$, if we are simply trying to find the value of $A$ that maximizes the conditional probability of $p(A \\mid B)$, we can ignore the denominator! In other words, this is used when we are trying to find the argmax of a distribution:\n",
    "\n",
    "$$argmax_Ap(A \\mid B)$$\n",
    "\n",
    "So, we don't need to know the actual value of the probability, just the particular A that gives us the maximum probability. Because Z is independent of A:\n",
    "\n",
    "$$argmax_Ap(A \\mid B) = argmax_Ap(B \\mid A)p(A)$$ \n",
    "\n",
    "This leads us into one of the main uses for Bayes Rule.\n",
    "\n",
    "## 1.2 Bayes Rule for Classification\n",
    "In the context of the Bayes Classifier, $y$ represents the class, and $x$ represents the data.\n",
    "\n",
    "$$p(y \\mid x)=\\frac{p(x \\mid y)*p(y)}{p(x)}$$\n",
    "\n",
    "We refer to $p(x \\mid y)$ as the **generative distribution**, because it tells us what the features look like for a specific class y, which we are already given. \n",
    "\n",
    "Note, that while the bayes classifier does make use of bayes rule, it does NOT necessarily make use of bayesian statistics. For more information on exactly what that means please see the posts on Bayesian Statistics. Again, the purpose of this post is really to just demonstrate it's role when purely confined to basic probability problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examples\n",
    "\n",
    "### 2.1 The Monty Hall Problem\n",
    "We are now going to go over a few brief examples where Bayes Rule can be applied in a simple proabilistic setting. First we can start with a very famous problem in probability know as **The Monty Hall Problem**. Imagine you are on a game show and you have to pick a door. There are 3 doors, and behind 1 of the doors there is a car, and behind the other two doors there are goats. Here is how the game works:\n",
    "1. You pick a door (you do not get to see what is behind it) (door 1)\n",
    "2. Monty Hall opens a door you didn't pick, always reveals a goat (door 2)\n",
    "3. You are given a choice: stay with door 1, or switch to (door 3)\n",
    "\n",
    "The big question is, which door should you choose?\n",
    "\n",
    "#### 2.1.1 Which door should you chose\n",
    "So, remember, you choose door 1, and each probability is conditioned on this. We then define the following:\n",
    "\n",
    "$$ C = \\text{where the car really is}$$\n",
    "\n",
    "$$ p(C=1) = p(C=2) = p(C=3) = 1/3$$\n",
    "\n",
    "For example, $p(C=1)$ represents the probability that a car is behind door 1. We can then define the random variable $H$:\n",
    "\n",
    "$$ H = \\text{random variable to represent the door that Monty Hall opens}$$\n",
    "\n",
    "We can assume he opens door 2 without loss of generality, since the problem is symmetric.\n",
    "\n",
    "$$p(H=2 \\mid C=1) = 0.5$$\n",
    "\n",
    "Remember that you chose door 1. So if the car is behind door 1, he can choose either door 2 or 3 since they will each be a goat. If the car is behind door 2, he cannot open door 2, so the probability is 0:\n",
    "\n",
    "$$ p(H=2 \\mid C=2) = 0$$\n",
    "\n",
    "Similarly, if the car is behind door 3, then monty hall has to open door 2, since that is the only door left with a goat:\n",
    "\n",
    "$$p(H=2 \\mid C=3) = 1$$\n",
    "\n",
    "Now, What probability do we actually want? We want to know if we should stick with door 1 or switch to door 3. In other words we want to compare:\n",
    "\n",
    "$$p(C=1 \\mid H=2) \\text{ vs. } p(C=3 \\mid H=2)$$\n",
    "\n",
    "Now, we can do that using bayes rule!\n",
    "\n",
    "$$p(A \\mid B)=\\frac{p(B \\mid A)*p(A)}{p(B)}$$\n",
    "\n",
    "$$p(A \\mid B)=\\frac{p(B \\mid A)*p(A)}{\\sum_ip(B \\mid A_i)*p(A_i)}$$\n",
    "\n",
    "Where in our case:\n",
    "\n",
    "$$A: C=3 \\;, B: H=2$$\n",
    "\n",
    "$$p(C=3 \\mid H=2) = \\frac{p(H=2 \\mid C=3)p(C=3)}{p(H=2)}$$\n",
    "\n",
    "$$p(C=3 \\mid H=2) = \\frac{p(H=2 \\mid C=3)p(C=3)}{p(H=2 \\mid C=1)p(C=1)+p(H=2 \\mid C=2)p(C=2)+p(H=2 \\mid C=3)p(C=3)}$$\n",
    "\n",
    "$$p(C=3 \\mid H=2) = \\frac{\\frac{1}{3}}{\\frac{1}{2}*\\frac{1}{3}+0*\\frac{1}{3}+1*\\frac{1}{3}} = \\frac{2}{3}$$\n",
    "\n",
    "And we can similarly show: \n",
    "\n",
    "$$p(C=1 \\mid H=2) = \\frac{1}{3}$$\n",
    "\n",
    "Hence, by the above application of Bayes Rule it is clear that we should always switch doors! \n",
    "\n",
    "#### 2.1.2 Mathematical Intuition\n",
    "We can also think about the problem like so: \n",
    "\n",
    "$$ p(C=1) = 1/3 $$\n",
    "\n",
    "$$ p(C=2) = 1/3$$ \n",
    "\n",
    "$$ p(C=3) = 1/3$$ \n",
    "\n",
    "$$ p(C=2 \\text{ or } C=3) = 2/3$$ \n",
    "\n",
    "Now lets say that we pick door 1, and monty hall opens door 2, showing us there is a goat behind it. We now know that $p(C=2) = 0$. In other words, monty has **revealed certain information to us** that we did not have originally.  Hence, our equation $p(C=2 \\text{ or } C=3) = 2/3$ still remains true, which means that $p(C=3) = 2/3$ and $p(C=1) = 1/3$. So we want to pick door 3! Note the reason this happens is because once door 2 is opened, it is known and is no longer a random variable.\n",
    "\n",
    "#### 2.1.3 Advanced Intuition \n",
    "Now, this problem is often referred to as a **paradox**. The reason it is viewed as a paradox is because it violates general human intuition and common sense. Now, this section will touch on some more advanced topics such as **causal analysis** (which will be covered in later posts), but I would feel remiss if I did not add a few sentences on the topic. \n",
    "\n",
    "In general, human intuition operates under the logic of **causation**, while data conform to the logic of probabilties and proportions. Paradoxes often arise when we misapply the rules we have learned in one realm to another. In the case the Monty Hall problem, the main thing needed to resolve this apparent paradox is that we must take into account _not only the data_, but also the _data generating process_ (the rules of the game). The main idea is as follows:\n",
    "\n",
    "> The way that we obtain information is no less important than the information itself.\n",
    "\n",
    "Based on the rules of the game, we can deduce the following: If we open door 1, Monty cannot open door 1. However, he could have opened door 2. If, instead he choses to open door 3, it is more likely that he opened door 3 because he was forced to. This leads us to see that their is more evidence than before that the car is behind door 2. \n",
    "\n",
    "If we start wading into the waters of causation, we learn that our minds rebel at the possibility of a correlation without a causation, since we learned to associate the two since birth. Causeless correlation violates our common sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Imbalanced Classes \n",
    "Lets look at another example of where Bayes rule comes into play. Suppose we are doing disease testing. We would take a blood sample, extract some features from it, and output whether or not that person has the disease. So, we would have:\n",
    "* Input: blood sample\n",
    "* Output: Has disease, yes/no\n",
    "\n",
    "Lets look further at a realistic scenario where this is involved. Most people are healthy and non diseased, most of the time. So, suppose that only 1% of the population has the disease. We can build a classifier that just predicts \"no\" each time. In other words, it doesn't learn anything. It is already correct for 99% of cases though! Hence, accuracy is not always the best metric to utilize. Perhaps we do not care about overall accuracy? \n",
    "\n",
    "#### 2.2.1 So what should we measure? \n",
    "What we actually want to measure is $p(predict=1 | disease=1)$. This is called the **true positive rate**. In medical terminology this is referred to as **sensitivity**. In information retrieval is is known as **hit rate** or **recall**.\n",
    "\n",
    "We can solve for the above using bayes rule:\n",
    "\n",
    "$$p(prediction=1 | disease=1) = \\frac{p(prediction=1, disease=1)}{p(disease=1)}$$\n",
    "\n",
    "Typically, we count 4 things: \n",
    "1. **true positives** (you have the disease, and we predict you have the disease)\n",
    "2. **true negatives** (you don't have the disease, and we predict you dont' have the disease)\n",
    "3. **false positives** (you don't have the disease, and we predict you have the disease)\n",
    "4. **false negatives** (you have the disease, and we predict you don't have the disease)\n",
    "\n",
    "<br> \n",
    "\n",
    "||Prediction = 1 |Prediction = 0|\n",
    "|-|--------------|--------------|\n",
    "|**Disease = 1**|True Positive |False Negative |\n",
    "|**Disease = 0**|True Positive |False Negative |\n",
    "\n",
    "#### 2.2.2 Sensitivity\n",
    "With that said, we can calculate sensitivity as follows:\n",
    "\n",
    "$$p(prediction=1 | disease=1) = \\frac{p(prediction=1, disease=1)}{p(disease=1)}$$\n",
    "\n",
    "$$sensitivity = recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "#### 2.2.3 Specificity\n",
    "And we can then calculate the **specificity** (the true negative rate):\n",
    "\n",
    "$$p(prediction=0 | disease=0) = \\frac{p(prediction=0, disease=0)}{p(disease=0)}$$\n",
    "\n",
    "$$specificity = \\frac{TN}{TN+FP}$$\n",
    "\n",
    "#### 2.2.4 Precision\n",
    "Now, in information retrieval, rather than specificity, we are interested in **precision**.\n",
    "\n",
    "$$precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "What is this the probability of? Well, $TP$ can be defined as:\n",
    "\n",
    "$$TP = p(prediction=1, disease=1)$$\n",
    "\n",
    "And $TP + FP$:\n",
    "\n",
    "$$TP+FP = p(prediction=1)$$\n",
    "\n",
    "Which then looks like:\n",
    "\n",
    "$$precision = \\frac{TP}{TP+FP} = \\frac{p(prediction=1, disease=1)}{p(prediction=1)}$$\n",
    "\n",
    "Which equals:\n",
    "\n",
    "$$p(disease=1|prediction=1) = \\frac{p(prediction=1, disease=1)}{p(prediction=1)}$$\n",
    "\n",
    "This is a useful measure! Just because your results come back positive, does not mean that you have the disease! Generally, more testing is required! This will be explored further in the bayesian statistics section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
