
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="ipynb_website:version" content="0.9.4" />
<meta name="viewport" content="width=device-width, initial-scale=1" />

<link rel="stylesheet" type="text/css" href="../css/jt.css">
<link rel="stylesheet" type="text/css" href="../css/readable.css">
<link rel="stylesheet" type="text/css" href="../css/toc2.css">

<link href="../site_libs/jqueryui-1.11.4/jquery-ui.css">
<link rel="stylesheet" href="../site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<link rel="stylesheet" href="../site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />
<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.9.1/jquery-ui.min.js"></script>
<script src="../site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="../site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="../site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>

<link rel="stylesheet"
      href="../site_libs/highlightjs/null.min.css"
      type="text/css" />

<script src="../site_libs/highlightjs/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>

<script src="../js/doc_toc.js"></script>
<script src="../js/docs.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
        },
        "HTML-CSS": {
            preferredFont: "TeX",
            availableFonts: ["TeX"],
            styles: {
                scale: 110,
                ".MathJax_Display": {
                    "font-size": "110%",
                }
            }
        }
    });
</script>
<script>
function filterDataFrame(id) {
    var input = document.getElementById("search_" + id);
    var filter = input.value.toUpperCase();
    var table = document.getElementById("dataframe_" + id);
    var tr = table.getElementsByTagName("tr");
    // Loop through all table rows, and hide those who don't match the search query
    for (var i = 1; i < tr.length; i++) {
        for (var j = 0; j < tr[i].cells.length; ++j) {
            var matched = false;
            if (tr[i].cells[j].innerHTML.toUpperCase().indexOf(filter) != -1) {
                tr[i].style.display = "";
                matched = true
                break;
            }
            if (!matched)
                tr[i].style.display = "none";
        }
    }
}
function sortDataFrame(id, n, dtype) {
    var table = document.getElementById("dataframe_" + id);
    var tb = table.tBodies[0]; // use `<tbody>` to ignore `<thead>` and `<tfoot>` rows
    var tr = Array.prototype.slice.call(tb.rows, 0); // put rows into array
    if (dtype === 'numeric') {
        var fn = function(a, b) { 
            return parseFloat(a.cells[n].textContent) <= parseFloat(b.cells[n].textContent) ? -1 : 1;
        }
    } else {
        var fn = function(a, b) {
            var c = a.cells[n].textContent.trim().localeCompare(b.cells[n].textContent.trim()); 
            return c > 0 ? 1 : (c < 0 ? -1 : 0) }
    }
    var isSorted = function(array, fn) {
        if (array.length < 2)
            return 1;
        var direction = fn(array[0], array[1]); 
        for (var i = 1; i < array.length - 1; ++i) {
            var d = fn(array[i], array[i+1]);
            if (d == 0)
                continue;
            else if (direction == 0)
                direction = d;
            else if (direction != d)
                return 0;
            }
        return direction;
    }
    var sorted = isSorted(tr, fn);
    if (sorted == 1 || sorted == -1) {
        // if sorted already, reverse it
        for(var i = tr.length - 1; i >= 0; --i)
            tb.appendChild(tr[i]); // append each row in order
    } else {
        tr = tr.sort(fn);
        for(var i = 0; i < tr.length; ++i)
            tb.appendChild(tr[i]); // append each row in order
    }
}
</script>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');
  // mark it active
  menuAnchor.parent().addClass('active');
  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>
<div class="container-fluid main-container">
<!-- tabsets -->
<script src="../site_libs/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>



<title>Nathaniel Dake Blog</title>

<style type = "text/css">
body {
  font-family: "sans-serif";
  padding-top: 66px;
  padding-bottom: 40px;
}
</style>
</head>

<body>
<div tabindex="-1" id="notebook" class="border-box-sizing">
<div class="container" id="notebook-container">

<!-- code folding -->

<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">Nathaniel Dake Blog</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
<li>
  <a href="../Deep_Learning.html">Deep Learning</a>
</li>
        
<li>
  <a href="../AI.html">AI</a>
</li>
        
<li>
  <a href="../Machine_Learning.html">Machine Learning</a>
</li>
        
<li>
  <a href="../NLP.html">NLP</a>
</li>
        
<li>
  <a href="../Mathematics.html">Mathematics</a>
</li>
        
<li>
  <a href="../Projects.html">Projects</a>
</li>
        
<li>
  <a href="../Book_Reviews.html">Book Reviews</a>
</li>
        
      </ul>
        
<ul class="nav navbar-nav navbar-right">
<li>
   <a href="https://github.com/NathanielDake/nathanieldake.github.io"> source </a>
</li>
</ul>
        
      </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="4.-Advanced-RNN-Units">4. Advanced RNN Units<a class="anchor-link" href="#4.-Advanced-RNN-Units">&#182;</a></h1><p>We are now going to move into the realm of advanced RNN units. Up until this point, we have been dealing with the simple recurrent unit exclusively. However, implementing <strong>Rated</strong> units, <strong>Gated Recurrent Units</strong>, and <strong>Long Short-Term Memory</strong> will allow our models to become far more powerful.</p>
<h2 id="1.-Rated-RNN-Units">1. Rated RNN Units<a class="anchor-link" href="#1.-Rated-RNN-Units">&#182;</a></h2><p>A <strong>rated recurrent unit</strong> is simply a straightforward modification to the simple recurrent unit. Recall, a simple recurrent unit has the form:</p>
<p><img src="https://drive.google.com/uc?id=1tGeRQ2PZsHbFq8XFsj32NC3gQ-46ilWZ" width="320"></p>
<p>Which can be observed on a lower level as:</p>
<p><img src="https://drive.google.com/uc?id=1F0wDzeyGBAa1l4_mDrIAiejherkAkb8p" width="300"></p>
<p>And mathematically, we can define $h(t)$ as:</p>
<p>$$h(t) = f\big(W_x^T x(t) + W_h^T h(t-1)\big)$$</p>
<p>Where $f$ is our chosen activation function. The idea is that we we want to weight two things:</p>
<ol>
<li>$f\big(x(t), h(t-1)\big)$, which is the output that we would have gotten in a simple recurrent unit.</li>
<li>$h(t-1)$, the previous value of the hidden state.</li>
</ol>
<p>In order to accomplish this weighting, we use a matrix known as the <strong>rate matrix</strong>, $z$, which is the same size as the hidden layer. We then perform an element by element multiplication on each dimension:</p>
<p>$$h(t) = (1-z) \odot h(t-1) + z \odot f\big( x(t), h(t-1)\big)$$</p>
<p>$z$ is known as the rate. You may notice that this looks very similar to the low pass filter that we created in the previous post. The idea here to is to learn $z$ in a way that it let's the some values from previous points in time carry greater weight, and others depend mainly on the most recent values. Visually, the rated recurrent unit looks like:</p>
<p><img src="https://drive.google.com/uc?id=1Tx7TAd3tUV-7-ezVPbJztx8dZyA3yC7m" width="600"></p>
<p>The changes needed to implement this in code are relatively small and straightforward. We simply need to add a new param of size $M$, and include the above equation in the <code>recurrence</code> function.</p>
<h3 id="1.1.1-Rate-Matrix-Modifications">1.1.1 Rate Matrix Modifications<a class="anchor-link" href="#1.1.1-Rate-Matrix-Modifications">&#182;</a></h3><p>There are more options for the rate matrix than simply what was discussed above. For example, we can make it dependent on the input and previous hidden state via a sigmoid and more weight matrices.</p>
<p>We can also make it a matrix (size $M x M$) so that it multiplies against $h$ with matrix multiplication, instead of element wise multiplication. In this case, you can picture what is happening as the same type of everything connected to everything scenario that we had for the hidden to hidden state.</p>
<h3 id="1.1.2-Modifications-to-Poetry-Generation">1.1.2 Modifications to Poetry Generation<a class="anchor-link" href="#1.1.2-Modifications-to-Poetry-Generation">&#182;</a></h3><p>The next thing that we are going to do is redo our poem generation example with the rated recurrent unit. It will be clear that this is just a small modification from the simple recurrent unit, so the code is almost exactly the same. Note, this new parameter will be trained in exactly the same way as all the other parameters-via gradient descent. In fact, when we look at more complex models the training will still remiain the same.</p>
<p>To add a bit more complexity to the mix, we are going to try and solve the problem of the lines ending too quickly. Recall that this is because we have many training samples that result in the next word being the end token. Because the end token shows up in every line, it is over represented in the training data. To prevent this, we will only train for going to the end of the sequence 10% of the time. Otherwise we stop on the second to last word.</p>
<p>Another change that we will make is that we will not model the initial distribution anymore. Recall, we use this to prevent every line from starting with the same word. This would happen because neural networks will give us the same prediction every time if we use the argmax. Instead, we will use the <code>START</code> token as the input, and the output will represent a probability distribution. This is valid because we already know that softmax gives us a valid probability distribution. We can then sample from this distribution to generate the next word. This way the sequences that we generate will be more stochastic, and it will treat the output probability as an actual probability, rather than a deterministic prediction:</p>

<pre><code>p(w0) = softmax(f(START))
w0 = randint(V, p=p(w0))</code></pre>
<h3 id="1.1.3-Rated-RNN-Unit-in-Code">1.1.3 Rated RNN Unit in Code<a class="anchor-link" href="#1.1.3-Rated-RNN-Unit-in-Code">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">theano</span>
<span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="k">as</span> <span class="nn">T</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="k">import</span> <span class="n">shuffle</span>
<span class="kn">from</span> <span class="nn">rnn_util</span> <span class="k">import</span> <span class="n">init_weight</span><span class="p">,</span> <span class="n">get_robert_frost</span>


<span class="k">class</span> <span class="nc">SimpleRNN</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">D</span> <span class="c1"># dimensionality of word embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">=</span> <span class="n">M</span> <span class="c1"># hidden layer size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">V</span> <span class="o">=</span> <span class="n">V</span> <span class="c1"># vocabulary size</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">T</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">show_fig</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span>
        <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">M</span>
        <span class="n">V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">V</span>

        <span class="c1"># initial weights</span>
        <span class="n">We</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
        <span class="n">Wx</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
        <span class="n">Wh</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
        <span class="n">bh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
        <span class="c1"># z  = np.ones(M)</span>
        <span class="n">Wxz</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
        <span class="n">Whz</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
        <span class="n">bz</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
        <span class="n">Wo</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>
        <span class="n">bo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>

        <span class="n">thX</span><span class="p">,</span> <span class="n">thY</span><span class="p">,</span> <span class="n">py_x</span><span class="p">,</span> <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">We</span><span class="p">,</span> <span class="n">Wx</span><span class="p">,</span> <span class="n">Wh</span><span class="p">,</span> <span class="n">bh</span><span class="p">,</span> <span class="n">h0</span><span class="p">,</span> <span class="n">Wxz</span><span class="p">,</span> <span class="n">Whz</span><span class="p">,</span> <span class="n">bz</span><span class="p">,</span> <span class="n">Wo</span><span class="p">,</span> <span class="n">bo</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span>

        <span class="n">lr</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>

        <span class="n">cost</span> <span class="o">=</span> <span class="o">-</span><span class="n">T</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">py_x</span><span class="p">[</span><span class="n">T</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">thY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">thY</span><span class="p">]))</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
        <span class="n">dparams</span> <span class="o">=</span> <span class="p">[</span><span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">get_value</span><span class="p">()</span><span class="o">*</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">]</span>

        <span class="n">updates</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">dp</span><span class="p">,</span> <span class="n">g</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">dparams</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
            <span class="n">new_dp</span> <span class="o">=</span> <span class="n">mu</span><span class="o">*</span><span class="n">dp</span> <span class="o">-</span> <span class="n">lr</span><span class="o">*</span><span class="n">g</span>
            <span class="n">updates</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">dp</span><span class="p">,</span> <span class="n">new_dp</span><span class="p">))</span>

            <span class="n">new_p</span> <span class="o">=</span> <span class="n">p</span> <span class="o">+</span> <span class="n">new_dp</span>
            <span class="n">updates</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">new_p</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">predict_op</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">thX</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="n">prediction</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_op</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">thX</span><span class="p">,</span> <span class="n">thY</span><span class="p">,</span> <span class="n">lr</span><span class="p">],</span>
            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">cost</span><span class="p">,</span> <span class="n">prediction</span><span class="p">],</span>
            <span class="n">updates</span><span class="o">=</span><span class="n">updates</span>
        <span class="p">)</span>

        <span class="n">costs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">n_correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">n_total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">:</span>
                    <span class="n">input_sequence</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                    <span class="n">output_sequence</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">input_sequence</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">output_sequence</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="n">n_total</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_sequence</span><span class="p">)</span>

                <span class="c1"># we set 0 to start and 1 to end</span>
                <span class="n">c</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_op</span><span class="p">(</span><span class="n">input_sequence</span><span class="p">,</span> <span class="n">output_sequence</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
                <span class="c1"># print &quot;p:&quot;, p</span>
                <span class="n">cost</span> <span class="o">+=</span> <span class="n">c</span>
                <span class="c1"># print &quot;j:&quot;, j, &quot;c:&quot;, c/len(X[j]+1)</span>
                <span class="k">for</span> <span class="n">pj</span><span class="p">,</span> <span class="n">xj</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">output_sequence</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">pj</span> <span class="o">==</span> <span class="n">xj</span><span class="p">:</span>
                        <span class="n">n_correct</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;i:&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="s2">&quot;cost:&quot;</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="s2">&quot;correct rate:&quot;</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">n_correct</span><span class="p">)</span><span class="o">/</span><span class="n">n_total</span><span class="p">))</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">learning_rate</span> <span class="o">/=</span> <span class="mi">2</span>
            <span class="n">costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">show_fig</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">costs</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savez</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="o">*</span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">get_value</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">])</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">activation</span><span class="p">):</span>
        <span class="c1"># TODO: would prefer to save activation to file too</span>
        <span class="n">npz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
        <span class="n">We</span> <span class="o">=</span> <span class="n">npz</span><span class="p">[</span><span class="s1">&#39;arr_0&#39;</span><span class="p">]</span>
        <span class="n">Wx</span> <span class="o">=</span> <span class="n">npz</span><span class="p">[</span><span class="s1">&#39;arr_1&#39;</span><span class="p">]</span>
        <span class="n">Wh</span> <span class="o">=</span> <span class="n">npz</span><span class="p">[</span><span class="s1">&#39;arr_2&#39;</span><span class="p">]</span>
        <span class="n">bh</span> <span class="o">=</span> <span class="n">npz</span><span class="p">[</span><span class="s1">&#39;arr_3&#39;</span><span class="p">]</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">npz</span><span class="p">[</span><span class="s1">&#39;arr_4&#39;</span><span class="p">]</span>
        <span class="n">Wxz</span> <span class="o">=</span> <span class="n">npz</span><span class="p">[</span><span class="s1">&#39;arr_5&#39;</span><span class="p">]</span>
        <span class="n">Whz</span> <span class="o">=</span> <span class="n">npz</span><span class="p">[</span><span class="s1">&#39;arr_6&#39;</span><span class="p">]</span>
        <span class="n">bz</span> <span class="o">=</span> <span class="n">npz</span><span class="p">[</span><span class="s1">&#39;arr_7&#39;</span><span class="p">]</span>
        <span class="n">Wo</span> <span class="o">=</span> <span class="n">npz</span><span class="p">[</span><span class="s1">&#39;arr_8&#39;</span><span class="p">]</span>
        <span class="n">bo</span> <span class="o">=</span> <span class="n">npz</span><span class="p">[</span><span class="s1">&#39;arr_9&#39;</span><span class="p">]</span>
        <span class="n">V</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">We</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">Wx</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">rnn</span> <span class="o">=</span> <span class="n">SimpleRNN</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>
        <span class="n">rnn</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">We</span><span class="p">,</span> <span class="n">Wx</span><span class="p">,</span> <span class="n">Wh</span><span class="p">,</span> <span class="n">bh</span><span class="p">,</span> <span class="n">h0</span><span class="p">,</span> <span class="n">Wxz</span><span class="p">,</span> <span class="n">Whz</span><span class="p">,</span> <span class="n">bz</span><span class="p">,</span> <span class="n">Wo</span><span class="p">,</span> <span class="n">bo</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">rnn</span>

    <span class="k">def</span> <span class="nf">set</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">We</span><span class="p">,</span> <span class="n">Wx</span><span class="p">,</span> <span class="n">Wh</span><span class="p">,</span> <span class="n">bh</span><span class="p">,</span> <span class="n">h0</span><span class="p">,</span> <span class="n">Wxz</span><span class="p">,</span> <span class="n">Whz</span><span class="p">,</span> <span class="n">bz</span><span class="p">,</span> <span class="n">Wo</span><span class="p">,</span> <span class="n">bo</span><span class="p">,</span> <span class="n">activation</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">activation</span>

        <span class="c1"># redundant - see how you can improve it</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">We</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">We</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wx</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wx</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wh</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wh</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bh</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">bh</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h0</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">h0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wxz</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wxz</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Whz</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Whz</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bz</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">bz</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wo</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wo</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bo</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">bo</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">We</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Wx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Wh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Wxz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Whz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Wo</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bo</span><span class="p">]</span>

        <span class="n">thX</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">ivector</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
        <span class="n">Ei</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">We</span><span class="p">[</span><span class="n">thX</span><span class="p">]</span> <span class="c1"># will be a TxD matrix</span>
        <span class="n">thY</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">ivector</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">recurrence</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">h_t1</span><span class="p">):</span>
            <span class="c1"># returns h(t), y(t)</span>
            <span class="n">hhat_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wx</span><span class="p">)</span> <span class="o">+</span> <span class="n">h_t1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wh</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bh</span><span class="p">)</span>
            <span class="n">z_t</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wxz</span><span class="p">)</span> <span class="o">+</span> <span class="n">h_t1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Whz</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bz</span><span class="p">)</span>
            <span class="n">h_t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">z_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">h_t1</span> <span class="o">+</span> <span class="n">z_t</span> <span class="o">*</span> <span class="n">hhat_t</span>
            <span class="n">y_t</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">h_t</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wo</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bo</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">h_t</span><span class="p">,</span> <span class="n">y_t</span>

        <span class="p">[</span><span class="n">h</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">_</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span>
            <span class="n">fn</span><span class="o">=</span><span class="n">recurrence</span><span class="p">,</span>
            <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">h0</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
            <span class="n">sequences</span><span class="o">=</span><span class="n">Ei</span><span class="p">,</span>
            <span class="n">n_steps</span><span class="o">=</span><span class="n">Ei</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="n">py_x</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">py_x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predict_op</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">thX</span><span class="p">],</span>
            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">py_x</span><span class="p">,</span> <span class="n">prediction</span><span class="p">],</span>
            <span class="n">allow_input_downcast</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">thX</span><span class="p">,</span> <span class="n">thY</span><span class="p">,</span> <span class="n">py_x</span><span class="p">,</span> <span class="n">prediction</span>


    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word2idx</span><span class="p">):</span>
        <span class="c1"># convert word2idx -&gt; idx2word</span>
        <span class="n">idx2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">word2idx</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">V</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word2idx</span><span class="p">)</span>
        <span class="n">n_lines</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">X</span> <span class="o">=</span> <span class="p">[</span> <span class="mi">0</span> <span class="p">]</span>
        <span class="k">while</span> <span class="n">n_lines</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="c1"># print &quot;X:&quot;, X</span>
            <span class="n">PY_X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_op</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">PY_X</span> <span class="o">=</span> <span class="n">PY_X</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">P</span> <span class="o">=</span> <span class="p">[</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">PY_X</span><span class="p">)]</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">P</span><span class="p">])</span> <span class="c1"># append to the sequence</span>
            <span class="n">P</span> <span class="o">=</span> <span class="n">P</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># just grab the most recent prediction</span>
            <span class="k">if</span> <span class="n">P</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># it&#39;s a real word, not start/end token</span>
                <span class="n">word</span> <span class="o">=</span> <span class="n">idx2word</span><span class="p">[</span><span class="n">P</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">P</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># end token</span>
                <span class="n">n_lines</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train_poetry</span><span class="p">():</span>
    <span class="n">sentences</span><span class="p">,</span> <span class="n">word2idx</span> <span class="o">=</span> <span class="n">get_robert_frost</span><span class="p">()</span>
    <span class="n">rnn</span> <span class="o">=</span> <span class="n">SimpleRNN</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word2idx</span><span class="p">))</span>
    <span class="n">rnn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">show_fig</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
    <span class="n">rnn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;RRNN_D50_M50_epochs2000_relu.npz&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_poetry</span><span class="p">():</span>
    <span class="n">sentences</span><span class="p">,</span> <span class="n">word2idx</span> <span class="o">=</span> <span class="n">get_robert_frost</span><span class="p">()</span>
    <span class="n">rnn</span> <span class="o">=</span> <span class="n">SimpleRNN</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;RRNN_D50_M50_epochs2000_relu.npz&#39;</span><span class="p">,</span> <span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">rnn</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">word2idx</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<span class="c1">#     train_poetry()</span>
    <span class="n">generate_poetry</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:139: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>and give of people a hornyhanded kindness as the arm ground snow snow cellar out 
and piano tell here him was stop in her me 
of then acquaintance out but a house them 
they be leafs a long it didnt held 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Gated-Recurrent-Unit">2. Gated Recurrent Unit<a class="anchor-link" href="#2.-Gated-Recurrent-Unit">&#182;</a></h2><p>We are now going to introduce a unit that is more powerful than the ellman unit, the <strong>Gated Recurrent Unit</strong>, (GRU). GRU's were introduced in 2014, while LSTM's (which we will be going over next) were introduced in 1997. I have chosen to start with GRU's because they are slightly less complex, and thus a better place to begin. The GRU is very similar to LSTM, incorporating many of the same concepts, but having far fewer parameters, meaning it can train faster at a constant hidden layer size.</p>
<h3 id="2.1-GRU-Architecture">2.1 GRU Architecture<a class="anchor-link" href="#2.1-GRU-Architecture">&#182;</a></h3><p>To start, let's go over the architecture of the GRU. Before we do that, however, I want to quickly recap the previous architectures that we have seen, particularly treating the hidden unit as a black box of sorts. This compartmental point of view will help us in extending the simple unit and rated unit to the GRU.</p>
<p><strong>Feedforward Unit</strong> <br>
In the simplest feedforward network, this black box simply contains some nonlinear function like $tanh$ or $relu$:</p>
<p><img src="https://drive.google.com/uc?id=16Qe6uVFsX58tPqla11bUDtIuTyqlyyho" width="300"></p>
<p><strong>Simple Recurrent Unit</strong><br>
In a simple recurrent network, we just connect the output of the black box back to itself, with a time delay of one:</p>
<p><img src="https://drive.google.com/uc?id=1lojDOZVNBmCE23wbEmNXgD7PfYWAo_eI" width="300"></p>
<p><strong>Rated Recurrent Unit</strong><br>
With the rated recurrent unit, we add a rating operation between what would have been the output of the simple recurrent network, and the previous output value.</p>
<p><img src="https://drive.google.com/uc?id=1nLz2HGaYhP0JWnbm2FXIbpThFkb6toaM" width="500"></p>
<p>We can think of of this new operation as a gate. Since it has to take on a value between 0 and 1, and the other gate has to take on the 1 minus that value, it is a gate that is choosing between two things: taking on the old value or taking on the new value. The result here is that we get a mixture of both.</p>
<p><strong>Gated Recurrent Unit</strong><br>
Finally, we arrive at the gated recurrent unit! The architecure simply requires that we add one more gate:</p>
<p><img src="https://drive.google.com/uc?id=1BqfOZ1LYDmOhXghEa4NJ7VIQbLbArzMY" width="500"></p>
<p>The above diagram corresponds with the following mathematical equations:</p>
<p>$$r_t = \sigma \big(x_t W_{xr} + h_{t-1}W_{hr} + b_r \big)$$</p>
<p>$$z_t = \sigma \big(x_t W_{xz} + h_{t-1}W_{hz} + b_z\big)$$</p>
<p>$$\hat{h}_t = g \big(x_t W_{xh} + (r_t \odot h_{t-1})W_{hh} + b_h\big)$$</p>
<p>$$h_t = (1 - z_t) \odot h_{t-1} + z_t \odot \hat{h}_t$$</p>
<p>Note: $g$ represents an activation, and $\odot$ is the symbol for element wise multiplication. With that said, we are simply seeing more of the same thing that we have been encountering thus far; weight matrices multiplied by inputs and passed through non linear functions and gates.</p>
<p>Again, we see the update gate $z_t$ that we encountered with the rated unit. It still balances how much of the previous hidden value and how much of the new candidate hidden value combines to get the new hidden value.</p>
<p>The new component is $r_t$, or the <strong>reset gate</strong>, which has the exact same functional form as the update gate- all of its weights are the same size. However, it is position in the black box is different. The reset gate is multiplied by the previous hidden state value. It controls how much of the previous hidden state we will consider, when we create the new candidate hidden value. In other words, it has the ability to reset the hidden value.</p>
<p>For instance, consider the situation where $r_t$ is equal to 0, then we get:</p>
<p>$$\hat{h}_t = g \big(x_t W_{xh} + b_h\big)$$</p>
<p>This would be as if $x_t$ were the beginning of a new sequence. Note that this is not the full picture, since $\hat{h}$ is only a candidate for the new $h_t$, since $h_t$ will be a combination of $\hat{h}$ and $h_{t-1}$ (which is controlled by the updated gate $z_t$).</p>
<p>Now, if that all sounds a bit complex, there is a practical way to reason with it. At the most general level, we are simply adding more parameters to our model, and making it more expressive. Adding more parameters allows us to fit more complex patterns.</p>
<h3 id="2.2-GRU-in-Code">2.2 GRU in Code<a class="anchor-link" href="#2.2-GRU-in-Code">&#182;</a></h3><p>When it comes to implement a GRU in code, it should be relatively simple if you already understand the simple recurrent unit and the rated recurrent unit. We simply need to add more weights, and modify the recurrence. The next step to making our code better is to modularize it. We have mentioned that the GRU can be looked at as a black box. To do this, we can simply make the GRU into a class so that it can be abstracted away. By doing this, we can stack GRU's, meaning anywhere that a hidden layer could go, a GRU can go as well. This allows us to just think of it as a thing that takes an input and produces an output. The fact that it contains a memory of previous inputs is just an internal detail of the black box.</p>
<p>Some pseudocode is show below:</p>

<pre><code>class GRU:
    def __init__(Mi, Mo):
        Wxr = random(Mi, Mo)
        # ...

    def recurrence(x_t, h_t1):
        r = sigmoid(x_t.dot(Wxr) + h_t1.dot(Whr) + br)
        # ...
        return (1 - z)*h_t1 + z*hhat

    def output(x):
        return scan(recurrence, x)</code></pre>
<p>And, a full class implementation:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">theano</span>
<span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="k">as</span> <span class="nn">T</span>

<span class="kn">from</span> <span class="nn">rnn_util</span> <span class="k">import</span> <span class="n">init_weight</span>


<span class="k">class</span> <span class="nc">GRU</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Mi</span><span class="p">,</span> <span class="n">Mo</span><span class="p">,</span> <span class="n">activation</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Mi</span> <span class="o">=</span> <span class="n">Mi</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Mo</span> <span class="o">=</span> <span class="n">Mo</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">activation</span>

        <span class="n">Wxr</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mi</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span> <span class="c1"># Input into reset gate</span>
        <span class="n">Whr</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mo</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span> <span class="c1"># Hidden into reset gate</span>
        <span class="n">br</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Mo</span><span class="p">)</span>         <span class="c1"># Bias reset gate</span>
        <span class="n">Wxz</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mi</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span> <span class="c1"># Input to update gate</span>
        <span class="n">Whz</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mo</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span> <span class="c1"># Hidden to update gate</span>
        <span class="n">bz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Mo</span><span class="p">)</span>         <span class="c1"># Bias update gate</span>
        <span class="n">Wxh</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mi</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span>
        <span class="n">Whh</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mo</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span>
        <span class="n">bh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Mo</span><span class="p">)</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Mo</span><span class="p">)</span>

        <span class="c1"># Create theano variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wxr</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wxr</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Whr</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Whr</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">br</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">br</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wxz</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wxz</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Whz</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Whz</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bz</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">bz</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wxh</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wxh</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Whh</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Whh</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bh</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">bh</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h0</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">h0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">Wxr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Whr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">br</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Wxz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Whz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Wxh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Whh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">recurrence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">h_t1</span><span class="p">):</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wxr</span><span class="p">)</span> <span class="o">+</span> <span class="n">h_t1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Whr</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">br</span><span class="p">)</span> <span class="c1"># Reset gate</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wxz</span><span class="p">)</span> <span class="o">+</span> <span class="n">h_t1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Whz</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bz</span><span class="p">)</span> <span class="c1"># Update gate</span>
        <span class="n">hhat</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wxh</span><span class="p">)</span> <span class="o">+</span><span class="p">(</span><span class="n">r</span><span class="o">*</span><span class="n">h_t1</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Whh</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bh</span><span class="p">)</span>  <span class="c1"># Candidate for h</span>
        <span class="n">h</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span><span class="o">*</span><span class="n">h_t1</span> <span class="o">+</span> <span class="n">z</span><span class="o">*</span><span class="n">hhat</span>
        <span class="k">return</span> <span class="n">h</span>

    <span class="k">def</span> <span class="nf">output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Output for this unit taking in an input sequence X. X is 2 dimensional: Time x Dimension</span>
        <span class="n">h</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span>
            <span class="n">fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">recurrence</span><span class="p">,</span>
            <span class="n">sequences</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
            <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">h0</span><span class="p">],</span>
            <span class="n">n_steps</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.-Long-Short-Term-Memory-(LSTM)">3. Long Short-Term Memory (LSTM)<a class="anchor-link" href="#3.-Long-Short-Term-Memory-(LSTM)">&#182;</a></h2><p>We are now going to move on from the GRU and start working with the <strong>LSTM</strong>. LSTM stands for <strong>Long Short-Term Memory</strong>, and it is a type of recurrent unit that has become very popular in recent years due to its superior performance/ability to overcome the vanishing gradient problem. Each recurrent unit that we have dug into has gotten progressively more complex, and each incorporated concepts from the previous unit.</p>
<p>The LSTM is the most complex recurrent unit we will cover. However, that complexity does not involve abstract ideas or new mathematics; rather, the number of components that we are dealing with is higher. Essentially, we will now have <strong>three different gates</strong>, called the <strong>input</strong>, <strong>output</strong>, and <strong>forget</strong> gate. Additionally, we are going to add yet another internal unit that will exist alongside the hidden state, sometimes referred to as a <strong>memory cell</strong>. One way to think of this cell is that it takes the place of $\hat{h}$, or the candidate hidden value, when we talked about the GRU.</p>
<h3 id="3.1-LSTM-Mathematics">3.1 LSTM Mathematics<a class="anchor-link" href="#3.1-LSTM-Mathematics">&#182;</a></h3><p>Now, the input gate, $i_t$, and forget gate, $f_t$, should remind you of the rate gate, $z_t$, from the GRU. Before, we were using $z_t$ and $1- z_t$; however, now we just have two seperate gates:</p>
<p><strong>Input Gate</strong><br>
The input gate just controls how much of the new value goes into the cell:</p>
<p>$$i_t = \sigma\big(x_t W_{xi} + h_{t-1}W_{hi} + c_{t-1}W_{ci} + b_i\big)$$</p>
<p><strong>Forget Gate</strong><br>
The forget gate controls how much of the previous cell value goes into the current cell value:</p>
<p>$$f_t = \sigma\big( x_t W_{xf} + h_{t-1}W_{hf} + c_{t-1}W_{cf} + b_f\big)$$</p>
<p><strong>Candidate</strong><br>
The candidate for the new cell value looks a lot like what would be the simple recurrent unit's value, right before it gets multiplied by the input gate:</p>
<p>$$c_t = f_tc_{t-1} + i_t \;tanh\big(x_t W_{xc} + h_{t-1}W_{hc} + b_c\big)$$</p>
<p><strong>Output Gate</strong><br>
Finally, the output gate takes into account everything: the input at time $t$, the previous hidden state, and the current cell value:</p>
<p>$$o_t = \sigma \big( x_t W_{xo} + h_{t-1}W_{ho} + c_t W_{co} + b_o\big) $$</p>
<p><strong>New Hidden State</strong><br>
The new hidden state is just the $tanh$ of the cell value, multiplied by the output gate:</p>
<p>$$h_t = o_t \; tanh(c_t)$$</p>
<h3 id="3.2-LSTM-Parameters">3.2 LSTM Parameters<a class="anchor-link" href="#3.2-LSTM-Parameters">&#182;</a></h3><p>Now, we just introduced a substantial number of new parameters, so it may be useful to try and break down exactly what they are.</p>
<table>
<thead><tr>
<th>Model Component</th>
<th>Parameters</th>
<th>Depends on</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Input Gate</strong></td>
<td>$W_{xi}$, $W_{hi}$, $W_{ci}$, $b_i$</td>
<td>$x_t$, $h_{t-1}$, $c_{t-1}$</td>
</tr>
<tr>
<td><strong>Forget Gate</strong></td>
<td>$W_{xf}$, $W_{hf}$, $W_{cf}$, $b_f$</td>
<td>$x_t$, $h_{t-1}$, $c_{t-1}$</td>
</tr>
<tr>
<td><strong>Candidate Cell</strong></td>
<td>$W_{xc}$, $W_{hc}$, $b_c$</td>
<td>$x_t$, $h_{t-1}$</td>
</tr>
<tr>
<td><strong>Output Gate</strong></td>
<td>$W_{xo}$, $W_{ho}$, $W_{co}$, $b_o$</td>
<td>$x_t$, $h_{t-1}$, $c_{t}$</td>
</tr>
</tbody>
</table>
<p>In total, we have 15 new weights and biases for this black box! We have come a long way from our original feedforward net, where we only had 1 weight and 1 bias. Another way that we can think of this is that as we add more parameters, we enable our model to be more expressive.</p>
<h3 id="3.3-LSTM-Architecture">3.3 LSTM Architecture<a class="anchor-link" href="#3.3-LSTM-Architecture">&#182;</a></h3><p>Now, from an architecture perspective, an LSTM has the high level form of:</p>
<p><img src="https://drive.google.com/uc?id=1B1OX2ew8J3AEA2mOdjOLtyqSX4jbhk1s" width="700"></p>
<p>Where $\hat{c}$ is just meant to represent $x_t W_{xc} + h_{t-1}W_{hc} + b_c$ in the candidate equation. Now, for some this diagram may be sufficient, however, I would prefer to have a bit more insight to the inner working of the LSTM at a lower level. This can be seen below:</p>
<p><img src="https://drive.google.com/uc?id=1eaCY0O9FNtwMZyRRHKNgsIcGcqohX06Q" width="700"></p>
<p><img src="https://drive.google.com/uc?id=1YSdHlemvYVdlQ3ZxgRFsEWS35OOhIAdV" width="300"></p>
<p>And we can highlight the actual cell as follows:</p>
<p><img src="https://drive.google.com/uc?id=14cDQlcuK8cMXRXSZ2nVG8kvGSI77Qloo" width="700"></p>
<p>I encourage you to take the equations the we defined earlier and follow them through the architecture diagram above to make sure they make sense. I should point out that in order to reduce visual noise in the diagram I didn't inclue the weight matrices or biases.</p>
<h3 id="3.4-LSTM-in-Code">3.4 LSTM in Code<a class="anchor-link" href="#3.4-LSTM-in-Code">&#182;</a></h3><p>We can now implement an LSTM in code:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">theano</span>
<span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="k">as</span> <span class="nn">T</span>

<span class="kn">from</span> <span class="nn">rnn_util</span> <span class="k">import</span> <span class="n">init_weight</span>


<span class="k">class</span> <span class="nc">LSTM</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Mi</span><span class="p">,</span> <span class="n">Mo</span><span class="p">,</span> <span class="n">activation</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Mi</span> <span class="o">=</span> <span class="n">Mi</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Mo</span> <span class="o">=</span> <span class="n">Mo</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">activation</span>

        <span class="n">Wxi</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mi</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span>
        <span class="n">Whi</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mo</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span>
        <span class="n">Wci</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mo</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span>
        <span class="n">bi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Mo</span><span class="p">)</span>
        <span class="n">Wxf</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mi</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span>
        <span class="n">Whf</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mo</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span>
        <span class="n">Wcf</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mo</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span>
        <span class="n">bf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Mo</span><span class="p">)</span>
        <span class="n">Wxc</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mi</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span>
        <span class="n">Whc</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mo</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span>
        <span class="n">bc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Mo</span><span class="p">)</span>
        <span class="n">Wxo</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mi</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span>
        <span class="n">Who</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mo</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span>
        <span class="n">Wco</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mo</span><span class="p">,</span> <span class="n">Mo</span><span class="p">)</span>
        <span class="n">bo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Mo</span><span class="p">)</span>
        <span class="n">c0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Mo</span><span class="p">)</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Mo</span><span class="p">)</span>

        <span class="c1"># Create Theano variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wxi</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wxi</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Whi</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Whi</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wci</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wci</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bi</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">bi</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wxf</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wxf</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Whf</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Whf</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wcf</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wcf</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bf</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">bf</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wxc</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wxc</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Whc</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Whc</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bc</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">bc</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wxo</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wxo</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Who</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Who</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wco</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wco</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bo</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">bo</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c0</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">c0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h0</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">h0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wxi</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Whi</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wci</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bi</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wxf</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Whf</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wcf</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bf</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wxc</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Whc</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bc</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wxo</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Who</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wco</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bo</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">c0</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">h0</span><span class="p">,</span>
        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">recurrence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">h_t1</span><span class="p">,</span> <span class="n">c_t1</span><span class="p">):</span>
        <span class="n">i_t</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wxi</span><span class="p">)</span> <span class="o">+</span> <span class="n">h_t1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Whi</span><span class="p">)</span> <span class="o">+</span> <span class="n">c_t1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wci</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bi</span><span class="p">)</span>
        <span class="n">f_t</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wxf</span><span class="p">)</span> <span class="o">+</span> <span class="n">h_t1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Whf</span><span class="p">)</span> <span class="o">+</span> <span class="n">c_t1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wcf</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bf</span><span class="p">)</span>
        <span class="n">c_t</span> <span class="o">=</span> <span class="n">f_t</span><span class="o">*</span><span class="n">c_t1</span> <span class="o">+</span> <span class="n">i_t</span><span class="o">*</span><span class="n">T</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wxc</span><span class="p">)</span> <span class="o">+</span> <span class="n">h_t1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Whc</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bc</span><span class="p">)</span>
        <span class="n">o_t</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wxo</span><span class="p">)</span> <span class="o">+</span> <span class="n">h_t1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Who</span><span class="p">)</span> <span class="o">+</span> <span class="n">c_t</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wco</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bo</span><span class="p">)</span>
        <span class="n">h_t</span> <span class="o">=</span> <span class="n">o_t</span><span class="o">*</span><span class="n">T</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">c_t</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h_t</span><span class="p">,</span> <span class="n">c_t</span>

    <span class="k">def</span> <span class="nf">output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># input X should be a matrix (2-D)</span>
        <span class="c1"># rows index time</span>
        <span class="p">[</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">_</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span>
            <span class="n">fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">recurrence</span><span class="p">,</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
            <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">h0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">c0</span><span class="p">],</span> <span class="c1"># Include c so that recurrence has access to it!</span>
            <span class="n">n_steps</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.4-Learning-from-Wikipedia">3.4 Learning from Wikipedia<a class="anchor-link" href="#3.4-Learning-from-Wikipedia">&#182;</a></h2><p>We are now going to take our RNN/LSTM and utilize it on a set of data from wikipedia. Our goal is going to be to create a language model just as we had done for poetry. Both simply hold sequences of words, but wikipedia has a much larger vocabulary and total size (13 GB). We are going to see if our learned word embeddings end up producing useful word analogies, and specifically visualize them on a scatter plot (after performing dimensionality reduction).</p>
<h3 id="3.4.1-Getting-the-Data">3.4.1 Getting the Data<a class="anchor-link" href="#3.4.1-Getting-the-Data">&#182;</a></h3><p>Overall, this section does not have a ton of new information in terms of theory/RNNs, but it focus's more on a how it would be applied in a real scenario. As such, I want to take a minute to go over how we actually would get the data. It can be found <a href="https://dumps.wikimedia.org/enwiki/">here</a>. Once you have arrived, you can decide whether you want to get the entire datate set (14.7 GB at this point), or if you would rather just deal with a specific set of pages articles. I am choosing to work with a set of pages articles (i.e. not the entire dataset), because it will require some careful thought to prevent crashing python by overloading it's memory.</p>
<h3 id="3.4.2-Convert-data-to-text-files">3.4.2 Convert data to text files<a class="anchor-link" href="#3.4.2-Convert-data-to-text-files">&#182;</a></h3><p>Next, we are going to need to convert the above data into a text file format. To do this we will use the <a href="https://github.com/yohasebe/wp2txt">wp2txt library</a>. We can install it by running the following:</p>

<pre><code>sudo gem install wp2txt</code></pre>
<p>And it can then be run on a single file via:</p>

<pre><code>wp2txt -i &lt;filename&gt;</code></pre>
<h3 id="3.4.3-Processing-text-for-our-RNN">3.4.3 Processing text for our RNN<a class="anchor-link" href="#3.4.3-Processing-text-for-our-RNN">&#182;</a></h3><p>Finally, we can talk about how we are going to take our text files and get it into the right format for our neural network. To do this we will be using the function <code>get_wikipedia_data</code>:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_wikipedia_data</span><span class="p">(</span><span class="n">n_files</span><span class="p">,</span> <span class="n">n_vocab</span><span class="p">,</span> <span class="n">by_paragraph</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts Wikipedia txt files into correct format for Neural Network</span>

<span class="sd">    This function takes in a number of files that is too large to fit into memory if all data is loaded</span>
<span class="sd">    at once. 100 or less seems to be ideal. The vocabulary also needs to be limited, since it is a lot</span>
<span class="sd">    larger than the poetry dataset. We are going to have ~500,000-1,000,000 words. Note that the output</span>
<span class="sd">    target is the next word, so that is 1 million output classes, which is a lot of output classes.</span>
<span class="sd">    This makes it hard to get good accuracy, and it will make our output weight very large. To remedy</span>
<span class="sd">    this, the vocabulary size will be restricted to n_vocab. This is generally set to ~2000 most</span>
<span class="sd">    common words.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_files: Number of input files taken in</span>
<span class="sd">        n_vocab: Vocabulary size</span>
<span class="sd">        by_paragraph:</span>

<span class="sd">    Returns:</span>
<span class="sd">        sentences: list of lists containing sentences mapped to index</span>
<span class="sd">        word2idx_small: word2index mapping reduced to size n_vocab</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">wiki_relative_path</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="si">{relative_path}</span><span class="s1">wikipedia/unzipped&#39;</span>
    <span class="n">input_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">wiki_relative_path</span><span class="p">)</span> <span class="k">if</span> <span class="n">f</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;enwiki&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">f</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;txt&#39;</span><span class="p">)]</span>

    <span class="c1"># Return Variables</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">word2idx</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;START&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;END&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
    <span class="n">idx2word</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;START&#39;</span><span class="p">,</span> <span class="s1">&#39;END&#39;</span><span class="p">]</span>
    <span class="n">current_idx</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">word_idx_count</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">),</span> <span class="mi">1</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)}</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">input_files</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_files</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">n_files</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">input_files</span> <span class="o">=</span> <span class="n">input_files</span><span class="p">[:</span><span class="n">n_files</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">input_files</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Reading: &#39;</span><span class="p">,</span> <span class="n">f</span> <span class="p">)</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;</span><span class="si">{wiki_relative_path}</span><span class="s1">/</span><span class="si">{f}</span><span class="s1">&#39;</span><span class="p">):</span>
            <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="c1"># Don&#39;t count headers, structured data, lists, etc</span>
            <span class="k">if</span> <span class="n">line</span> <span class="ow">and</span> <span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;[&#39;</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="s1">&#39;|&#39;</span><span class="p">,</span> <span class="s1">&#39;=&#39;</span><span class="p">,</span> <span class="s1">&#39;{&#39;</span><span class="p">,</span> <span class="s1">&#39;}&#39;</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">by_paragraph</span><span class="p">:</span>
                    <span class="n">sentence_lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">sentence_lines</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_lines</span><span class="p">:</span>
                    <span class="n">tokens</span> <span class="o">=</span> <span class="n">my_tokenizer</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">t</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">word2idx</span><span class="p">:</span>
                            <span class="n">word2idx</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_idx</span>
                            <span class="n">idx2word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
                            <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="n">idx</span> <span class="o">=</span> <span class="n">word2idx</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
                        <span class="n">word_idx_count</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">word_idx_count</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                    <span class="n">sentences_by_idx</span> <span class="o">=</span> <span class="p">[</span><span class="n">word2idx</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
                    <span class="n">sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentences_by_idx</span><span class="p">)</span>

    <span class="c1"># Reduce vocabulary size to n_vocab</span>
    <span class="n">sorted_word_idx_count</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">word_idx_count</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="n">operator</span><span class="o">.</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">word2idx_small</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">new_idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">idx_new_idx_map</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">sorted_word_idx_count</span><span class="p">[:</span><span class="n">n_vocab</span><span class="p">]:</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">idx2word</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span>
        <span class="n">word2idx_small</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_idx</span>
        <span class="n">idx_new_idx_map</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_idx</span>
        <span class="n">new_idx</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="c1"># Let &#39;unknown&#39; be last token</span>
    <span class="n">word2idx_small</span><span class="p">[</span><span class="s1">&#39;UNKNOWN&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_idx</span>
    <span class="n">unknown</span> <span class="o">=</span> <span class="n">new_idx</span>

    <span class="k">assert</span><span class="p">(</span><span class="s1">&#39;START&#39;</span> <span class="ow">in</span> <span class="n">word2idx_small</span><span class="p">)</span>
    <span class="k">assert</span><span class="p">(</span><span class="s1">&#39;END&#39;</span> <span class="ow">in</span> <span class="n">word2idx_small</span><span class="p">)</span>
    <span class="k">assert</span><span class="p">(</span><span class="s1">&#39;king&#39;</span> <span class="ow">in</span> <span class="n">word2idx_small</span><span class="p">)</span>
    <span class="k">assert</span><span class="p">(</span><span class="s1">&#39;queen&#39;</span> <span class="ow">in</span> <span class="n">word2idx_small</span><span class="p">)</span>
    <span class="k">assert</span><span class="p">(</span><span class="s1">&#39;man&#39;</span> <span class="ow">in</span> <span class="n">word2idx_small</span><span class="p">)</span>
    <span class="k">assert</span><span class="p">(</span><span class="s1">&#39;woman&#39;</span> <span class="ow">in</span> <span class="n">word2idx_small</span><span class="p">)</span>

    <span class="c1"># Map old idx to new idx</span>
    <span class="n">sentences_small</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">new_sentence</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx_new_idx_map</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">if</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">idx_new_idx_map</span> <span class="k">else</span> <span class="n">unknown</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">]</span>
            <span class="n">sentences_small</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_sentence</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">sentences_small</span><span class="p">,</span> <span class="n">word2idx_small</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A few things to note about the above function:</p>
<ul>
<li>Because the number of files that we are working with is too large to fit into memory, we must limit the amount of data that is loaded at a single time</li>
<li>We must also limit the vocabulary size, the 2000 most common words is appropriate</li>
<li>To do this, we must keep a count of how many times a word has appeared in the dictionary. Next, we need to sort that dictionary by value, in reverse so that the highest count value comes first. This will give us the index's for the top 2000 words. However, we are still not done. Our word embedding matrix needs to be of size V = 2000, so the word index's must be from 0-2000. But the word index's we currently have are just 2000 random numbers from 0-1,000,000. Hence, we need to create a new word mapping from old index to new index, where the old word index is any number from 0 to 1 million, and the new word index is a number from 0 to 2000. This also means we need to create a new word2idx dictionary as well. </li>
</ul>
<h3 id="3.4.4-Training-on-the-entire-dataset">3.4.4 Training on the entire dataset<a class="anchor-link" href="#3.4.4-Training-on-the-entire-dataset">&#182;</a></h3><p>Now, I should now that if we train on the entire dataset there is a good chance that we will run out of memory. To prevent this, we don't want to load all of our data into memory at the same time. One strategy would be to train on each separate text file, opening each within each epoch. We would have to, of course, keep a dictionary of the word2idx mapping handy, so that it remains consistent between each file. This would be rather slow of course.</p>
<p>Another option, would be to convert each sentence into a list of word index's before running the neural network, and then save the word2idx mapping to a file as well. That way our input data can be just a bunch of arrays of word index's. This would still need to be in multiple files since it would still take up too much RAM, but we would prevent needing to convert the data each time we open the file.</p>
<p>A final option would to use a DB like MySQL in order to store the arrays of word indexes. This way we could retrieve rows at random, without needing to store them in memory.</p>
<h3 id="3.4.5-Training-RNN-with-LSTM-from-wikipedia-data">3.4.5 Training RNN with LSTM from wikipedia data<a class="anchor-link" href="#3.4.5-Training-RNN-with-LSTM-from-wikipedia-data">&#182;</a></h3><p>We will now implement this is code:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[55]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">theano</span>
<span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="k">as</span> <span class="nn">T</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="kn">from</span> <span class="nn">datetime</span> <span class="k">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="k">import</span> <span class="n">shuffle</span>
<span class="kn">from</span> <span class="nn">gru</span> <span class="k">import</span> <span class="n">GRU</span>
<span class="kn">from</span> <span class="nn">lstm</span> <span class="k">import</span> <span class="n">LSTM</span>
<span class="kn">from</span> <span class="nn">rnn_util</span> <span class="k">import</span> <span class="n">init_weight</span><span class="p">,</span> <span class="n">get_wikipedia_data</span>


<span class="k">class</span> <span class="nc">RNN</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="p">,</span> <span class="n">V</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;RNN class constructor</span>

<span class="sd">        Args:</span>
<span class="sd">            hidden_layer_sizes: Number of units in each hidden layer</span>
<span class="sd">            D: Embedding size</span>
<span class="sd">            V: Vocabulary size</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="n">hidden_layer_sizes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">D</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">V</span> <span class="o">=</span> <span class="n">V</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">show_fig</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">RecurrentUnit</span><span class="o">=</span><span class="n">GRU</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit RNN class to data set via unsupervised learning (no Y labels)</span>

<span class="sd">        Args:</span>
<span class="sd">            X: Input samples (sentences)</span>
<span class="sd">            learning_rate: learning rate</span>
<span class="sd">            mu: momentum</span>
<span class="sd">            epochs: Number of training iterations</span>
<span class="sd">            show_fig: Show figure</span>
<span class="sd">            activation: non linear activation function</span>
<span class="sd">            RecurrentUnit: GRU or LSTM</span>
<span class="sd">            normalize: Normalizes word embeddings</span>

<span class="sd">        Returns:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span>
        <span class="n">V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">V</span>
        <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># Number training samples (number of sentences)</span>

        <span class="n">We</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">Mi</span> <span class="o">=</span> <span class="n">D</span>
        <span class="k">for</span> <span class="n">Mo</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_sizes</span><span class="p">:</span> <span class="c1"># Create hidden layers</span>
            <span class="n">ru</span> <span class="o">=</span> <span class="n">RecurrentUnit</span><span class="p">(</span><span class="n">Mi</span><span class="p">,</span> <span class="n">Mo</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span> <span class="c1"># Create recurrent unit (from class GRU or LSTM)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ru</span><span class="p">)</span>
            <span class="n">Mi</span> <span class="o">=</span> <span class="n">Mo</span>

        <span class="n">Wo</span> <span class="o">=</span> <span class="n">init_weight</span><span class="p">(</span><span class="n">Mi</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>
        <span class="n">bo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>

        <span class="c1"># Create theano variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">We</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">We</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wo</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Wo</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bo</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">bo</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">Wo</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bo</span><span class="p">]</span>

        <span class="c1"># For each recurrent unit in hidden_layers, append the params</span>
        <span class="k">for</span> <span class="n">ru</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layers</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">+=</span> <span class="n">ru</span><span class="o">.</span><span class="n">params</span>

        <span class="c1"># Create theano inputs and outputs</span>
        <span class="n">thX</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">ivector</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span> <span class="c1"># Sequence of word indexes</span>
        <span class="n">thY</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">ivector</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">)</span> <span class="c1"># Sequence of word indexes, offset for thX by 1</span>

        <span class="n">Z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">We</span><span class="p">[</span><span class="n">thX</span><span class="p">]</span> <span class="c1"># Input sequence</span>
        <span class="k">for</span> <span class="n">ru</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layers</span><span class="p">:</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">ru</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
        <span class="n">py_x</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">Z</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Wo</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bo</span><span class="p">)</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">py_x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Let&#39;s return py_x too so we can draw a sample instead</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predict_op</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">thX</span><span class="p">],</span>
            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">py_x</span><span class="p">,</span> <span class="n">prediction</span><span class="p">],</span>
            <span class="n">allow_input_downcast</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Create cost and do gradient descent</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="o">-</span><span class="n">T</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">py_x</span><span class="p">[</span><span class="n">T</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">thY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">thY</span><span class="p">]))</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
        <span class="n">dparams</span> <span class="o">=</span> <span class="p">[</span><span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">get_value</span><span class="p">()</span><span class="o">*</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">]</span>

        <span class="c1"># Gradient descent for word embeddings</span>
        <span class="n">dWe</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">We</span><span class="o">.</span><span class="n">get_value</span><span class="p">()</span><span class="o">*</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">gWe</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">We</span><span class="p">)</span>
        <span class="n">dWe_update</span> <span class="o">=</span> <span class="n">mu</span><span class="o">*</span><span class="n">dWe</span> <span class="o">-</span> <span class="n">learning_rate</span><span class="o">*</span><span class="n">gWe</span>
        <span class="n">We_update</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">We</span> <span class="o">+</span> <span class="n">dWe_update</span>
        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="n">We_update</span> <span class="o">/=</span> <span class="n">We_update</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">updates</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span> <span class="o">+</span> <span class="n">mu</span><span class="o">*</span><span class="n">dp</span> <span class="o">-</span> <span class="n">learning_rate</span><span class="o">*</span><span class="n">g</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">dp</span><span class="p">,</span> <span class="n">g</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">dparams</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
        <span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">dp</span><span class="p">,</span> <span class="n">mu</span><span class="o">*</span><span class="n">dp</span> <span class="o">-</span> <span class="n">learning_rate</span><span class="o">*</span><span class="n">g</span><span class="p">)</span> <span class="k">for</span> <span class="n">dp</span><span class="p">,</span> <span class="n">g</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">dparams</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
        <span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">We</span><span class="p">,</span> <span class="n">We_update</span><span class="p">),</span> <span class="p">(</span><span class="n">dWe</span><span class="p">,</span> <span class="n">dWe_update</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_op</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">thX</span><span class="p">,</span> <span class="n">thY</span><span class="p">],</span>
            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">cost</span><span class="p">,</span> <span class="n">prediction</span><span class="p">],</span>
            <span class="n">updates</span><span class="o">=</span><span class="n">updates</span>
        <span class="p">)</span>

        <span class="c1"># Main training loop</span>
        <span class="n">costs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">t0</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">n_correct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">n_total</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span> <span class="c1"># one sentence at a time</span>
                <span class="c1"># 1% of time, will include END token</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.01</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">input_sequence</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                    <span class="n">output_sequence</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">input_sequence</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span><span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">output_sequence</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="n">n_total</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_sequence</span><span class="p">)</span>

                <span class="c1"># test:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># we set 0 to start and 1 to end</span>
                    <span class="n">c</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_op</span><span class="p">(</span><span class="n">input_sequence</span><span class="p">,</span> <span class="n">output_sequence</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">PYX</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_op</span><span class="p">(</span><span class="n">input_sequence</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;input_sequence len:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_sequence</span><span class="p">))</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PYX.shape:&quot;</span><span class="p">,</span><span class="n">PYX</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pred.shape:&quot;</span><span class="p">,</span> <span class="n">pred</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="n">e</span>

                <span class="n">cost</span> <span class="o">+=</span> <span class="n">c</span>
                <span class="k">for</span> <span class="n">pj</span><span class="p">,</span> <span class="n">xj</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">output_sequence</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">pj</span> <span class="o">==</span> <span class="n">xj</span><span class="p">:</span>
                        <span class="n">n_correct</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">j</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Using sys here helps compact the output.</span>
                    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;j/N: </span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2"> correct rate so far: </span><span class="si">%f</span><span class="se">\r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">n_correct</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_total</span><span class="p">))</span>
                    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;i:&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="s2">&quot;cost:&quot;</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="s2">&quot;correct rate:&quot;</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">n_correct</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_total</span><span class="p">),</span> <span class="s2">&quot;time for epoch:&quot;</span><span class="p">,</span>
                  <span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
            <span class="n">costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">show_fig</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">costs</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">train_wikipedia</span><span class="p">(</span><span class="n">we_file</span><span class="o">=</span><span class="s1">&#39;word_embeddings.npy&#39;</span><span class="p">,</span> <span class="n">w2i_file</span><span class="o">=</span><span class="s1">&#39;wikipedia_word2idx.json&#39;</span><span class="p">,</span> <span class="n">RecurrentUnit</span><span class="o">=</span><span class="n">GRU</span><span class="p">):</span>
    <span class="n">sentences</span><span class="p">,</span> <span class="n">word2idx</span> <span class="o">=</span> <span class="n">get_wikipedia_data</span><span class="p">(</span><span class="n">n_files</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_vocab</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;finished retrieving data&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;vocab size:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word2idx</span><span class="p">),</span> <span class="s2">&quot;number of sentences:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">))</span>
    <span class="n">rnn</span> <span class="o">=</span> <span class="n">RNN</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="p">[</span><span class="mi">30</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">word2idx</span><span class="p">))</span>
    <span class="n">rnn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">show_fig</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>

    <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">we_file</span><span class="p">,</span> <span class="n">rnn</span><span class="o">.</span><span class="n">We</span><span class="o">.</span><span class="n">get_value</span><span class="p">())</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">w2i_file</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">word2idx</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">find_analogies</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">w3</span><span class="p">,</span> <span class="n">we_file</span><span class="o">=</span><span class="s1">&#39;word_embeddings.npy&#39;</span><span class="p">,</span> <span class="n">w2i_file</span><span class="o">=</span><span class="s1">&#39;wikipedia_word2idx.json&#39;</span><span class="p">):</span>
    <span class="n">We</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">we_file</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">w2i_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">word2idx</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="n">king</span> <span class="o">=</span> <span class="n">We</span><span class="p">[</span><span class="n">word2idx</span><span class="p">[</span><span class="n">w1</span><span class="p">]]</span>
    <span class="n">man</span> <span class="o">=</span> <span class="n">We</span><span class="p">[</span><span class="n">word2idx</span><span class="p">[</span><span class="n">w2</span><span class="p">]]</span>
    <span class="n">woman</span> <span class="o">=</span> <span class="n">We</span><span class="p">[</span><span class="n">word2idx</span><span class="p">[</span><span class="n">w3</span><span class="p">]]</span>
    <span class="n">v0</span> <span class="o">=</span> <span class="n">king</span> <span class="o">-</span> <span class="n">man</span> <span class="o">+</span> <span class="n">woman</span>

    <span class="k">def</span> <span class="nf">dist1</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">dist2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">a</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">dist</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[(</span><span class="n">dist1</span><span class="p">,</span> <span class="s1">&#39;Euclidean&#39;</span><span class="p">),</span> <span class="p">(</span><span class="n">dist2</span><span class="p">,</span> <span class="s1">&#39;cosine&#39;</span><span class="p">)]:</span>
        <span class="n">min_dist</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
        <span class="n">best_word</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">word2idx</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">w3</span><span class="p">):</span>
                <span class="n">v1</span> <span class="o">=</span> <span class="n">We</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                <span class="n">d</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">v0</span><span class="p">,</span> <span class="n">v1</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">d</span> <span class="o">&lt;</span> <span class="n">min_dist</span><span class="p">:</span>
                    <span class="n">min_dist</span> <span class="o">=</span> <span class="n">d</span>
                    <span class="n">best_word</span> <span class="o">=</span> <span class="n">word</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;closest match by&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="s2">&quot;distance:&quot;</span><span class="p">,</span> <span class="n">best_word</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="s2">&quot;=&quot;</span><span class="p">,</span> <span class="n">best_word</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">w3</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">we</span> <span class="o">=</span> <span class="s1">&#39;lstm_word_embeddings_2019_01_21.npy&#39;</span>
    <span class="n">w2i</span> <span class="o">=</span> <span class="s1">&#39;lstm_wikipedia_word2idx2_2019_01_21.json&#39;</span>
<span class="c1">#     train_wikipedia(we, w2i, RecurrentUnit=LSTM)</span>
    <span class="n">find_analogies</span><span class="p">(</span><span class="s1">&#39;king&#39;</span><span class="p">,</span> <span class="s1">&#39;man&#39;</span><span class="p">,</span> <span class="s1">&#39;woman&#39;</span><span class="p">,</span> <span class="n">we</span><span class="p">,</span> <span class="n">w2i</span><span class="p">)</span>
    <span class="n">find_analogies</span><span class="p">(</span><span class="s1">&#39;france&#39;</span><span class="p">,</span> <span class="s1">&#39;paris&#39;</span><span class="p">,</span> <span class="s1">&#39;london&#39;</span><span class="p">,</span> <span class="n">we</span><span class="p">,</span> <span class="n">w2i</span><span class="p">)</span>
    <span class="n">find_analogies</span><span class="p">(</span><span class="s1">&#39;france&#39;</span><span class="p">,</span> <span class="s1">&#39;paris&#39;</span><span class="p">,</span> <span class="s1">&#39;rome&#39;</span><span class="p">,</span> <span class="n">we</span><span class="p">,</span> <span class="n">w2i</span><span class="p">)</span>
    <span class="n">find_analogies</span><span class="p">(</span><span class="s1">&#39;paris&#39;</span><span class="p">,</span> <span class="s1">&#39;france&#39;</span><span class="p">,</span> <span class="s1">&#39;italy&#39;</span><span class="p">,</span> <span class="n">we</span><span class="p">,</span> <span class="n">w2i</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>closest match by Euclidean distance: seems
king - man = seems - woman
closest match by cosine distance: looking
king - man = looking - woman
closest match by Euclidean distance: pain
france - paris = pain - london
closest match by cosine distance: authority
france - paris = authority - london
closest match by Euclidean distance: plane
france - paris = plane - rome
closest match by cosine distance: culture
france - paris = culture - rome
closest match by Euclidean distance: score
paris - france = score - italy
closest match by cosine distance: picked
paris - france = picked - italy
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see that the embeddings that the RNN yielded do not seem to have the relationships we would like. However, if we utilize a dimensionality reduction technique, we may be able to improve upon this! Note, the above embeddings are based off of one iteration of training. If we had used 10, we would have improved significantly. On my local machine, training one iteration took 90 minutes.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="3.4.6-Visualize-the-word-embeddings">3.4.6 Visualize the word embeddings<a class="anchor-link" href="#3.4.6-Visualize-the-word-embeddings">&#182;</a></h3><p>Below, I will use the interactive plotting library, <code>plotly</code>, in junction with dimensionality reduction via TSNE to plot our word embeddings. We can then tinker with the plot to see what types of embeddings our network learned.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">plotly.plotly</span> <span class="k">as</span> <span class="nn">py</span>
<span class="kn">import</span> <span class="nn">plotly</span>
<span class="kn">import</span> <span class="nn">plotly.graph_objs</span> <span class="k">as</span> <span class="nn">go</span>
<span class="kn">from</span> <span class="nn">plotly.offline</span> <span class="k">import</span> <span class="n">iplot</span>
<span class="c1"># Using cufflinks in offline mode</span>
<span class="kn">import</span> <span class="nn">cufflinks</span>
<span class="n">cufflinks</span><span class="o">.</span><span class="n">go_offline</span><span class="p">()</span>
<span class="c1"># Set the global theme for cufflinks</span>
<span class="n">cufflinks</span><span class="o">.</span><span class="n">set_config_file</span><span class="p">(</span><span class="n">world_readable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">theme</span><span class="o">=</span><span class="s1">&#39;pearl&#39;</span><span class="p">,</span> <span class="n">offline</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>IOPub data rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_data_rate_limit`.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">We</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;gru_nonorm_part1_word_embeddings.npy&#39;</span><span class="p">)</span>
<span class="n">V</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">We</span><span class="o">.</span><span class="n">shape</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;gru_nonorm_part1_wikipedia_word2idx.json&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">word2idx</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">idx2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">word2idx</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">()</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">We</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Z</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Z</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx2word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">V</span><span class="p">)]</span>
<span class="n">color</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">V</span><span class="p">)]</span>
<span class="n">trace</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;markers&#39;</span><span class="p">,</span>
    <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
        <span class="n">colorscale</span><span class="o">=</span><span class="s1">&#39;Viridis&#39;</span><span class="p">,</span>
        <span class="n">showscale</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">trace</span><span class="p">]</span>

<span class="n">layout</span><span class="o">=</span><span class="n">go</span><span class="o">.</span><span class="n">Layout</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Word Embeddings with Dimensionality Reduction&#39;</span><span class="p">,</span>
    <span class="n">hovermode</span><span class="o">=</span><span class="s1">&#39;closest&#39;</span><span class="p">,</span>
    <span class="n">xaxis</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">),</span>
    <span class="n">yaxis</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Principal Component 2&#39;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">layout</span><span class="p">)</span>

<span class="c1"># py.iplot(fig)</span>
<span class="c1"># plotly.offline.plot(fig, include_plotlyjs=False, output_type=&#39;div&#39;)</span>
</pre></div>

</div>
</div>
</div>

</div><script src="https://cdn.plot.ly/plotly-latest.min.js"></script> <div id="d7b28e46-248f-49ae-8672-cf1120945e13" style="height: 100%; width: 100%;" class="plotly-graph-div"></div><script type="text/javascript">window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("d7b28e46-248f-49ae-8672-cf1120945e13", [{"type": "scatter", "x": [55.50918960571289, 10.5789794921875, -35.075111389160156, -43.571346282958984, -48.84832000732422, -45.027626037597656, 2.782909393310547, -37.70212936401367, -53.280338287353516, -4.446917533874512, -52.66564178466797, -40.37825393676758, -39.475128173828125, -6.111392974853516, -38.07558822631836, -41.6874885559082, -41.8047981262207, -52.36846160888672, 8.462077140808105, -32.282432556152344, -48.79505920410156, -40.347774505615234, -41.02658462524414, -52.44196701049805, -37.84937286376953, 26.675559997558594, -39.26947784423828, -52.09120559692383, -42.59437942504883, -41.23157501220703, -42.814510345458984, -41.2198486328125, -41.35883331298828, -34.09801483154297, -34.135379791259766, -8.420211791992188, -38.93013000488281, 29.122400283813477, -32.53129959106445, -15.642963409423828, 31.168582916259766, -52.26858901977539, -27.82468605041504, -20.220460891723633, -40.87769317626953, -36.387664794921875, -10.238162994384766, -39.78331756591797, -41.984901428222656, -32.22323989868164, 4.919669151306152, -26.748722076416016, -9.00633716583252, -4.522874355316162, -43.286949157714844, -0.4443720877170563, 6.182921886444092, -9.93832778930664, -31.025123596191406, -36.228023529052734, -41.90049743652344, -45.290382385253906, 19.429523468017578, -44.14863967895508, 5.677200794219971, -18.69672966003418, -43.5629997253418, 0.6201627254486084, -43.23257827758789, 34.74443054199219, -19.568660736083984, -7.886529445648193, -8.275266647338867, 23.700279235839844, 0.4803219139575958, -27.926481246948242, -32.9929084777832, 29.339984893798828, -4.9769134521484375, -36.71525573730469, -4.4187822341918945, -34.378360748291016, -32.4357795715332, -32.07109832763672, 19.931325912475586, -37.46309280395508, -29.311079025268555, -51.69390869140625, -41.564178466796875, -5.523351669311523, -39.70745849609375, -38.19248962402344, 14.704339981079102, 19.385215759277344, -20.348073959350586, -36.80455780029297, 46.29201889038086, -8.564465522766113, 33.86780548095703, 27.89592933654785, 27.313613891601562, -50.40441131591797, -28.366573333740234, 11.25660228729248, 36.24154281616211, 9.950260162353516, -36.9940185546875, 41.52975845336914, -45.33114242553711, -42.616390228271484, -6.502387046813965, 5.061707973480225, 2.138965368270874, -36.79521179199219, -20.39790916442871, -9.631341934204102, -17.990110397338867, 25.724140167236328, -39.383060455322266, 13.382092475891113, -7.638591766357422, -38.37180709838867, 35.886558532714844, 5.1767425537109375, -13.608475685119629, 7.551181316375732, -14.460875511169434, 0.5737542510032654, 29.693038940429688, 57.92649459838867, -36.82663345336914, -1.8234807252883911, -17.530738830566406, 26.67308235168457, 36.20956039428711, -1.0378001928329468, -4.231281757354736, -32.044132232666016, -36.391700744628906, 36.684967041015625, -29.244850158691406, 16.83310890197754, 24.889034271240234, -27.487897872924805, -35.98842239379883, 25.077131271362305, -30.16602897644043, -44.489070892333984, -10.120713233947754, -1.030144453048706, -20.33737564086914, -39.267112731933594, -38.54862594604492, -15.632954597473145, 8.555852890014648, -43.9314079284668, 8.544343948364258, -43.12689971923828, 47.267494201660156, -9.607305526733398, -46.63884353637695, 10.757782936096191, -25.765018463134766, 10.469891548156738, 13.144196510314941, 28.504638671875, -35.91387939453125, -42.206031799316406, -48.76647186279297, -37.403934478759766, 17.2060489654541, -26.164995193481445, -18.94124984741211, 5.469662189483643, -17.955673217773438, -8.103218078613281, -4.569944858551025, 13.529731750488281, -19.104583740234375, 14.587968826293945, -21.930709838867188, 14.713953971862793, 57.967002868652344, -13.799625396728516, -22.90703010559082, -22.855077743530273, -25.87068748474121, -14.325915336608887, 35.70540237426758, -41.90217208862305, -27.527639389038086, 32.527008056640625, 52.676265716552734, 5.4861979484558105, 2.894467353820801, 22.91176986694336, -24.207651138305664, 30.225799560546875, 34.9503173828125, -3.2950472831726074, 17.259601593017578, -27.820322036743164, 6.265773296356201, 35.36431121826172, 26.131391525268555, 33.49393081665039, -18.81503677368164, -27.107587814331055, -23.768877029418945, 0.44195637106895447, 45.54137420654297, -27.6899356842041, -32.44174575805664, 0.7467786073684692, -38.095367431640625, -40.92856979370117, -2.307117223739624, 5.41515588760376, -8.203702926635742, 43.516456604003906, -31.687458038330078, -7.691412448883057, -3.0146522521972656, 54.20607376098633, 28.36075210571289, -15.640589714050293, -4.08003568649292, -28.359403610229492, 8.64784049987793, -22.611248016357422, -4.645932197570801, -27.708520889282227, -2.1092770099639893, 14.219768524169922, -0.5786073803901672, 20.658227920532227, -0.5990445017814636, -31.722522735595703, -6.154298782348633, 20.944189071655273, 27.336313247680664, 17.315898895263672, 5.841207504272461, -29.509735107421875, 28.312559127807617, -38.9664306640625, -50.48237991333008, 15.451903343200684, 17.372161865234375, 12.392008781433105, 22.35721778869629, -14.807214736938477, 32.65797805786133, -18.261722564697266, -27.228239059448242, -18.595691680908203, -38.42378616333008, -40.85544967651367, 12.038110733032227, -11.262372016906738, 28.406726837158203, -19.330442428588867, -33.89714813232422, -24.3797664642334, 31.362546920776367, -22.960805892944336, -24.362287521362305, -7.200829029083252, 6.502574920654297, 31.786436080932617, 32.33261489868164, 31.22467041015625, 4.491333484649658, -23.157367706298828, 29.275054931640625, -29.245948791503906, 24.006919860839844, 23.24616241455078, -7.706235408782959, 33.428592681884766, 30.06060028076172, 4.70136833190918, 6.944339752197266, -15.199275970458984, -16.729877471923828, -26.879043579101562, -3.7328803539276123, 16.25494384765625, 10.608087539672852, -24.878026962280273, 5.464659214019775, -25.237688064575195, 23.633182525634766, -4.64676570892334, 30.983766555786133, -22.555973052978516, 14.741531372070312, -42.920631408691406, 25.92604637145996, 4.666996955871582, 29.342662811279297, -23.90886116027832, 12.702348709106445, -9.361577033996582, 3.1521527767181396, 30.945674896240234, 14.853192329406738, -41.360408782958984, -37.64018630981445, 2.9083027839660645, 13.145922660827637, 0.10219081491231918, 3.1660244464874268, -43.873313903808594, 4.474045753479004, 30.008785247802734, -7.463464260101318, -10.650531768798828, -25.322940826416016, -26.555253982543945, 20.553457260131836, 58.09596633911133, -13.93060302734375, 42.2061767578125, -3.536713123321533, 29.113182067871094, 13.294088363647461, -37.633033752441406, 29.044296264648438, -37.79402160644531, 32.80408477783203, 13.719897270202637, -12.45883846282959, 28.97712516784668, -41.120361328125, -4.578247547149658, 8.246356964111328, 14.125556945800781, 14.197227478027344, -14.694354057312012, 13.105095863342285, 25.585569381713867, 21.32732391357422, -45.19337844848633, 30.483854293823242, 14.19978141784668, 6.904890537261963, -2.6807563304901123, -4.112513542175293, -7.239934921264648, -1.9139704704284668, 13.406514167785645, 31.04874610900879, -27.0631046295166, -26.28484344482422, 28.752233505249023, 3.77052903175354, -15.850044250488281, 34.25645065307617, 13.273153305053711, -10.99183464050293, 40.29252624511719, 4.14870548248291, -2.987894058227539, 29.51764678955078, -12.277260780334473, -14.313982963562012, -5.162965774536133, -50.14457702636719, -25.466215133666992, 28.591461181640625, 25.145729064941406, 13.564638137817383, -3.37863826751709, 9.161637306213379, 28.580984115600586, -25.476818084716797, 45.46076965332031, 16.900653839111328, -3.366682291030884, -33.47831726074219, 28.512109756469727, 20.047618865966797, -26.80211639404297, 13.843999862670898, -17.543319702148438, 28.531286239624023, 7.1376848220825195, -7.332584857940674, 27.1549129486084, -40.975563049316406, 35.66812515258789, 6.753788471221924, -39.55051803588867, 26.98655891418457, 26.737993240356445, -23.676694869995117, 21.740875244140625, 32.81768035888672, 34.80618667602539, -13.777756690979004, 35.044559478759766, -3.4795212745666504, -24.073793411254883, -3.2875988483428955, -18.0479736328125, -17.72012710571289, -41.21181869506836, -37.83444595336914, 44.019859313964844, 30.31645965576172, 35.485321044921875, -44.761356353759766, 27.837831497192383, 1.6443575620651245, -22.48844337463379, -22.535058975219727, -28.86386489868164, -30.289936065673828, 33.789493560791016, -25.510540008544922, 18.168615341186523, 1.8613964319229126, 36.19365310668945, -2.8199589252471924, 34.138797760009766, 3.7236716747283936, -39.56440353393555, 2.95237398147583, 28.090801239013672, -14.085387229919434, 30.647686004638672, 16.04926300048828, -26.449676513671875, -42.501956939697266, -32.063926696777344, 18.75785255432129, -44.478309631347656, -22.9001407623291, 12.902341842651367, 0.7500590085983276, 41.54009246826172, -19.094459533691406, -36.69829559326172, 13.810037612915039, -7.314825534820557, 1.155314326286316, -30.78708267211914, -15.895659446716309, -13.157389640808105, 26.095821380615234, -16.0467472076416, -27.230167388916016, 11.628110885620117, 11.640870094299316, 17.488967895507812, 2.8806347846984863, 28.16827392578125, -19.13178253173828, 8.428226470947266, 22.203533172607422, -25.192462921142578, 3.453240394592285, -24.1932373046875, -24.78187370300293, 2.4605627059936523, 24.4781494140625, 15.642876625061035, 22.11198616027832, -19.38079261779785, 20.557777404785156, -5.558888912200928, -7.792537212371826, -7.370965480804443, -21.628345489501953, -24.9351863861084, 35.507843017578125, -20.748279571533203, -36.59456253051758, -31.305770874023438, 8.685522079467773, 15.874031066894531, 20.481468200683594, 27.705467224121094, 18.65888023376465, 30.4999942779541, 3.230699062347412, -17.877010345458984, 0.6404354572296143, 33.36056137084961, -24.31470489501953, -10.670488357543945, 13.866856575012207, 17.355571746826172, 26.425411224365234, 59.127010345458984, 44.81098937988281, -25.119258880615234, -7.7638773918151855, 24.180505752563477, -17.334867477416992, 23.406267166137695, 0.5649586319923401, -3.239260196685791, 18.653783798217773, -14.199049949645996, -36.091392517089844, 26.84182357788086, 12.962093353271484, -23.88301658630371, 16.987743377685547, -16.825021743774414, 43.79883575439453, -39.11925506591797, 9.782903671264648, 7.619668483734131, 36.716609954833984, 6.364805221557617, 27.837158203125, 40.48386001586914, -3.9141407012939453, 47.02898406982422, -8.254841804504395, 27.848247528076172, -24.288986206054688, 46.01665496826172, -36.45336151123047, 0.9069574475288391, -24.45677375793457, 3.1277315616607666, 45.47225570678711, -22.459020614624023, -22.225202560424805, -17.242839813232422, 12.275721549987793, 32.96803665161133, 6.347367286682129, 16.406503677368164, 8.214648246765137, -13.542266845703125, -50.11577606201172, -39.58500289916992, 10.090351104736328, -31.791370391845703, -13.428214073181152, -9.741484642028809, -44.165367126464844, 0.9594716429710388, 56.24848937988281, -45.91221237182617, -0.4433944821357727, 27.691633224487305, 4.951732158660889, -28.88344383239746, -2.777855157852173, 2.0735342502593994, 27.63274574279785, -3.111661911010742, -13.15545654296875, 28.502866744995117, -18.671146392822266, 15.70988941192627, 10.732013702392578, 58.06645965576172, -23.742431640625, 16.880170822143555, 57.20962142944336, 9.108893394470215, 5.217117786407471, -38.51089859008789, 58.88846206665039, -27.325468063354492, -36.00307846069336, -40.73981475830078, -11.324816703796387, -21.756481170654297, -24.07039451599121, 10.43564510345459, -33.05104446411133, 46.37617874145508, 57.739830017089844, 25.188621520996094, -14.249580383300781, -35.51737594604492, -18.37126922607422, -28.941621780395508, -19.550561904907227, 33.6057243347168, -1.14021635055542, 0.5407063364982605, -50.349693298339844, 43.606571197509766, 7.835216045379639, 24.206501007080078, 28.131393432617188, 27.728574752807617, 6.814758777618408, 10.484502792358398, -12.728785514831543, 46.838470458984375, 5.869228839874268, -26.664194107055664, 15.979912757873535, 34.93601608276367, 23.7304744720459, -1.6526721715927124, -18.11719512939453, -6.184989929199219, -16.020780563354492, -5.826333045959473, -29.76089096069336, 5.51473331451416, -14.685590744018555, 1.171919822692871, 19.118148803710938, 34.76319122314453, -7.009401798248291, 0.6466686129570007, -21.566587448120117, 4.767778396606445, 23.285106658935547, 25.62479019165039, 8.275480270385742, 28.122438430786133, 45.525856018066406, -8.67409896850586, -21.369009017944336, -23.242568969726562, -31.84712791442871, -19.130395889282227, 18.783323287963867, -18.52334213256836, -16.60604476928711, -27.530879974365234, 8.257515907287598, 11.658902168273926, -4.658785343170166, -39.903167724609375, -18.265684127807617, -17.990657806396484, 6.672067165374756, 57.39923858642578, -2.316189765930176, -13.666330337524414, -30.898176193237305, -40.418460845947266, -22.671127319335938, -19.380401611328125, -1.5429893732070923, -44.48198699951172, 55.14470672607422, -18.917369842529297, -3.8301808834075928, 0.01501033827662468, 14.777965545654297, -5.7339935302734375, 27.315235137939453, -32.06023025512695, 2.2463154792785645, 46.41809844970703, -2.1607723236083984, -2.9825894832611084, -2.91439151763916, -40.394161224365234, 17.978126525878906, 2.2939279079437256, 27.290298461914062, 1.7890057563781738, 9.828335762023926, -26.41877555847168, -1.6370283365249634, -11.978495597839355, -27.432865142822266, -31.357736587524414, 17.5716609954834, -2.7768425941467285, -0.27889418601989746, -20.38573455810547, -22.3445987701416, 3.18083119392395, -36.18739700317383, 24.786893844604492, -13.33652400970459, 17.94679832458496, -10.976178169250488, -3.2082650661468506, -12.764483451843262, 21.14141273498535, -15.415855407714844, -16.659244537353516, -3.3874378204345703, -25.717187881469727, -27.838838577270508, -27.09732437133789, 26.991798400878906, 28.205259323120117, 16.010147094726562, -36.64287567138672, -14.474279403686523, 29.44924545288086, -24.726301193237305, -32.04104995727539, -19.765151977539062, -24.61226463317871, -21.100839614868164, -10.91336727142334, 32.949405670166016, -31.858449935913086, 1.6334917545318604, 19.59754180908203, 25.278047561645508, -28.767457962036133, -44.75067138671875, 26.984941482543945, -2.820408821105957, -2.5070178508758545, -33.59965133666992, 45.695518493652344, -32.90650939941406, -46.874141693115234, 58.35898208618164, 28.66511344909668, -24.167888641357422, -29.08922004699707, 13.843092918395996, -20.762073516845703, 22.08653450012207, 57.52313232421875, 25.50519561767578, 24.806276321411133, -18.45439338684082, -24.192424774169922, -6.861446380615234, -31.75823974609375, 22.688661575317383, -1.9816335439682007, 9.411162376403809, 32.93205261230469, 29.178049087524414, -19.07769012451172, 23.293798446655273, 7.598748207092285, 12.166528701782227, 3.0956289768218994, 27.20435333251953, 28.36025619506836, 56.74333953857422, 16.046777725219727, 28.499561309814453, 21.25775146484375, 13.130066871643066, 34.88162612915039, 16.590002059936523, -11.995530128479004, 17.400142669677734, -8.151046752929688, 10.944636344909668, -24.66801643371582, -32.77198791503906, 58.714874267578125, -37.403079986572266, 28.155576705932617, 28.74930191040039, -24.558818817138672, 28.02907943725586, -21.502559661865234, -43.450889587402344, 5.404385089874268, 44.807132720947266, 26.689693450927734, -29.733287811279297, -43.54231643676758, 41.28805160522461, 20.308223724365234, 16.14878273010254, -21.403789520263672, -36.789546966552734, 45.89767074584961, 5.346333980560303, -38.530452728271484, 25.70662498474121, 16.818588256835938, -24.154253005981445, 3.3023643493652344, -16.80874252319336, 27.21692657470703, -2.267643690109253, -49.0609130859375, 9.664924621582031, -30.817161560058594, 23.329803466796875, 12.036999702453613, 22.081745147705078, 46.00986862182617, -20.040237426757812, -18.188138961791992, -31.353178024291992, 27.593849182128906, 23.227073669433594, 29.963193893432617, 21.714046478271484, 15.325730323791504, 28.475080490112305, -22.287378311157227, 4.6099019050598145, 23.304086685180664, -24.15073585510254, -14.068818092346191, -24.9676513671875, -36.057735443115234, -21.460670471191406, -10.617185592651367, -1.8410117626190186, -15.042508125305176, 24.036884307861328, -2.2680516242980957, 25.551626205444336, 18.062570571899414, 26.687204360961914, 27.107221603393555, -27.303544998168945, 19.806949615478516, -2.6877739429473877, 4.201070785522461, -45.425533294677734, -25.370698928833008, 45.67955017089844, 22.53682518005371, -2.4655280113220215, -40.606380462646484, 26.056617736816406, -2.437344551086426, 43.719181060791016, -2.5249531269073486, 6.590359210968018, -20.71815299987793, -37.820159912109375, 27.07097053527832, -26.24028205871582, -39.13069152832031, -28.650588989257812, -5.101902961730957, -9.516822814941406, -40.16542053222656, -4.647976398468018, 16.381669998168945, -33.943504333496094, 26.251142501831055, -37.3212776184082, 9.329069137573242, -44.35082244873047, 4.541953086853027, -29.679765701293945, 21.310728073120117, 0.2164672315120697, -6.933295249938965, 24.303813934326172, 26.25004005432129, -2.395658493041992, 33.619102478027344, -0.7380083203315735, -22.497047424316406, 20.9846134185791, -33.15811538696289, 25.836782455444336, 13.257914543151855, 21.053037643432617, -4.855881214141846, 27.95882797241211, -21.46714210510254, 18.03927993774414, -36.605751037597656, 25.59747314453125, 21.71125030517578, 20.045005798339844, -47.3355827331543, -23.166379928588867, -22.823631286621094, 23.82819175720215, -18.662412643432617, -32.14570999145508, -27.05030632019043, 32.382266998291016, 7.714363098144531, -20.19392204284668, -12.05068302154541, -41.239471435546875, 28.878032684326172, 16.428104400634766, 20.496417999267578, 1.0350005626678467, -36.764984130859375, 3.754178047180176, -22.330961227416992, 45.651790618896484, 17.368228912353516, 22.01721954345703, 0.9386582970619202, -15.024834632873535, -29.466516494750977, 24.86956787109375, 5.14758825302124, 32.5513916015625, -19.6611328125, 2.482485055923462, 43.53383255004883, -26.79991912841797, 23.96277618408203, -36.121253967285156, 56.08845901489258, -18.649499893188477, 3.178936243057251, -6.640968322753906, 20.604856491088867, 26.01325225830078, 27.4678955078125, -47.27830123901367, 29.133703231811523, -0.24265430867671967, 18.479900360107422, 6.122730731964111, 45.087589263916016, -11.507394790649414, 3.207505702972412, 26.793331146240234, -4.98335599899292, 33.451351165771484, 25.6563720703125, -0.6967771053314209, -15.878106117248535, 32.01504135131836, -13.881121635437012, -22.628568649291992, -29.159610748291016, 17.525060653686523, 4.971792697906494, -30.19912338256836, -18.641267776489258, -1.0147053003311157, -47.38774871826172, -23.41729164123535, 17.694091796875, 7.5878143310546875, 24.653915405273438, -33.368045806884766, 15.143505096435547, 21.80885887145996, 2.366703987121582, 25.244365692138672, 31.700197219848633, 29.438182830810547, 27.364105224609375, -4.675355911254883, 19.658292770385742, -19.608386993408203, -48.39339828491211, 11.848091125488281, 15.143797874450684, 3.7685303688049316, 28.893978118896484, 29.147357940673828, 18.423431396484375, 26.626895904541016, -16.551746368408203, 25.254987716674805, -13.385932922363281, -26.089244842529297, -0.17293380200862885, 35.2630729675293, 11.111995697021484, 15.81080150604248, 4.990835189819336, 29.706499099731445, 41.54292678833008, -9.649680137634277, 16.034082412719727, -0.6547908782958984, 31.592496871948242, 0.4597308933734894, 27.906591415405273, 30.765819549560547, 9.33558464050293, 21.91752052307129, 2.5531911849975586, 32.024696350097656, 7.325140476226807, -17.965150833129883, 40.30705261230469, 1.2141462564468384, 45.11485290527344, -21.86956787109375, 34.561134338378906, -19.84613037109375, -12.666033744812012, -2.9231109619140625, -22.722654342651367, 22.36479949951172, -11.785309791564941, -25.67812156677246, -1.966442346572876, 24.528688430786133, 20.118728637695312, -32.97404098510742, 56.49955749511719, 25.775562286376953, -30.045129776000977, 26.206064224243164, -18.053010940551758, -21.313444137573242, 38.849491119384766, 56.82722854614258, 24.89396858215332, -40.2153205871582, -6.734786510467529, 31.944082260131836, 31.125080108642578, 19.350849151611328, -18.738988876342773, -24.772310256958008, -4.1290602684021, -20.327213287353516, -38.899784088134766, 20.819242477416992, -21.86838722229004, -1.9972560405731201, -21.23761749267578, 7.825399398803711, -22.254560470581055, 32.233272552490234, -26.724681854248047, 19.948579788208008, -35.60750961303711, 11.945122718811035, -11.764236450195312, 42.94368362426758, 29.768659591674805, -15.017332077026367, 4.543636798858643, -21.26622772216797, -19.387205123901367, 24.50452423095703, 26.20876693725586, -14.254095077514648, 18.337432861328125, -39.95174789428711, 25.116531372070312, 31.622041702270508, 11.085320472717285, 26.22152328491211, -39.299564361572266, -10.642427444458008, -11.992902755737305, 3.679896593093872, -37.1429328918457, -19.017112731933594, -15.320340156555176, 10.101117134094238, 6.825736999511719, -1.459794044494629, 26.739791870117188, 18.24403953552246, -7.648201942443848, -40.45662307739258, -38.98207092285156, 0.16331535577774048, 25.321571350097656, 11.900397300720215, 25.31399154663086, 0.9149772524833679, -28.652236938476562, -34.70726013183594, 25.008634567260742, 3.4653730392456055, -4.224040985107422, -16.679134368896484, 32.561668395996094, -32.389095306396484, -1.3944720029830933, -16.744565963745117, 26.170881271362305, -9.54161548614502, 4.013667106628418, 56.24464416503906, -0.7060643434524536, 30.138957977294922, 20.253488540649414, 17.927942276000977, 25.669151306152344, -4.742325782775879, -19.14928436279297, -12.575115203857422, -1.8627322912216187, -9.816930770874023, -20.4715518951416, 12.007094383239746, 16.54366111755371, -28.75665855407715, 5.986639976501465, -28.957517623901367, -20.69278907775879, 17.795644760131836, -27.094640731811523, 4.781304836273193, -22.32741355895996, 27.68099021911621, 23.10989761352539, 9.168869018554688, -12.054335594177246, 38.307525634765625, 3.1068177223205566, 34.660099029541016, -18.611780166625977, 23.745290756225586, 16.995296478271484, 7.7605695724487305, -21.84349822998047, 1.8130104541778564, -5.840334415435791, -21.046524047851562, -11.216817855834961, 30.131032943725586, 12.094273567199707, 3.7047860622406006, 33.26008987426758, 1.5631345510482788, -5.153101921081543, -12.973827362060547, 31.5704345703125, -20.706283569335938, 23.962993621826172, 23.0887508392334, -18.821334838867188, 26.276586532592773, -28.96099090576172, -18.00531005859375, -0.11657220125198364, -7.099998950958252, 43.497352600097656, 9.530937194824219, -6.881280899047852, -23.25316619873047, -8.149654388427734, 18.791425704956055, -0.0507175587117672, 4.563011646270752, 22.37382698059082, 33.01627731323242, -3.554429054260254, 18.539100646972656, 15.574103355407715, -21.03879737854004, -28.042869567871094, 1.0115242004394531, 1.2258565425872803, -22.033525466918945, -0.5437633991241455, -21.39853286743164, 22.180727005004883, -4.558852195739746, 16.85711097717285, -18.9154052734375, 18.442073822021484, 18.635658264160156, -16.16539764404297, 6.7220072746276855, -15.06782341003418, 26.154796600341797, -40.05228805541992, 16.93694305419922, 26.84551239013672, -32.46745300292969, -0.5500783324241638, 25.6104793548584, -18.136194229125977, -26.884620666503906, 39.74517059326172, -4.631011009216309, 20.839988708496094, -50.2545166015625, 44.06391525268555, -21.730560302734375, 11.329129219055176, 19.678354263305664, 22.31165313720703, -1.5385586023330688, -14.751699447631836, 3.7482171058654785, -33.58290100097656, 24.641508102416992, 30.116594314575195, -25.460668563842773, -25.768301010131836, -18.43800163269043, 15.109589576721191, -3.1733076572418213, 1.7128747701644897, -35.53547286987305, -14.612479209899902, 12.627134323120117, -10.395922660827637, -37.79975128173828, 0.7992456555366516, -24.18761444091797, 33.7033576965332, 4.512594699859619, -26.676280975341797, -42.47999572753906, 43.78782653808594, 26.608495712280273, 24.790483474731445, 28.1505069732666, -4.960569858551025, 24.353008270263672, 7.189062118530273, -16.896697998046875, 12.962153434753418, -19.83690643310547, -19.43948745727539, -13.117773056030273, 26.54233741760254, -50.50189971923828, -9.826303482055664, 32.50284194946289, 24.802106857299805, -26.970911026000977, 37.00225830078125, -38.58675765991211, 40.23208999633789, 1.158605933189392, -0.9340906739234924, 37.79425811767578, 4.308593273162842, 2.2073869705200195, 30.32487678527832, -27.15545082092285, 24.696088790893555, -18.31256675720215, -15.467934608459473, -29.04119873046875, -23.078853607177734, -40.343421936035156, -39.19398498535156, 21.832733154296875, 27.369136810302734, -1.6461318731307983, 13.405920028686523, 25.070985794067383, 25.50263023376465, -22.531068801879883, 8.157127380371094, 30.597084045410156, -36.367897033691406, 12.839834213256836, 41.90864562988281, -29.362966537475586, -25.412412643432617, -1.078902006149292, -27.309160232543945, -22.217435836791992, 17.931623458862305, 26.25140953063965, 6.807422161102295, 26.18791389465332, 26.027774810791016, 5.119604110717773, -28.446727752685547, 56.63026809692383, -0.23557251691818237, 26.189889907836914, 1.2482807636260986, 5.4034624099731445, -3.683870553970337, -17.113000869750977, 25.92298126220703, 32.47214889526367, 36.188568115234375, -27.41990089416504, -24.159509658813477, -16.204143524169922, 30.686342239379883, 7.519859790802002, 17.40155029296875, -0.05826801434159279, 12.55604076385498, 29.336692810058594, -26.02661895751953, 9.496623039245605, 24.18297576904297, 16.623323440551758, -28.493534088134766, 0.8881590366363525, 59.27016830444336, -24.901844024658203, 27.06056785583496, 7.451712608337402, -1.4851118326187134, 25.20916175842285, 34.846431732177734, -18.670379638671875, 21.77947998046875, 24.084989547729492, 12.671831130981445, 43.20286178588867, 44.03584289550781, 36.93046951293945, 44.87814712524414, -2.125622034072876, 14.84496784210205, -0.537908136844635, -30.281497955322266, -20.31271743774414, 5.296205043792725, -10.009096145629883, -11.277433395385742, 27.019420623779297, 1.6976337432861328, -17.87839126586914, 24.4420223236084, -13.03928279876709, 17.972455978393555, -16.844594955444336, -12.797064781188965, -0.6974838972091675, -20.7362003326416, -19.600191116333008, -1.0434727668762207, -24.88562774658203, 20.572988510131836, -29.345809936523438, 18.612451553344727, 43.81100082397461, 9.249895095825195, 20.890649795532227, 7.534023284912109, -14.951532363891602, -36.505218505859375, 9.592793464660645, 17.683870315551758, -17.713911056518555, -13.363181114196777, -9.843815803527832, 32.719966888427734, -29.523880004882812, 14.148900985717773, 32.72988510131836, 17.94931983947754, -21.696931838989258, -23.438440322875977, -20.444774627685547, 27.47121810913086, -16.386735916137695, -26.070466995239258, 3.309791088104248, 10.552512168884277, 26.19070816040039, -25.45147132873535, -16.420690536499023, 2.883002281188965, -5.924797058105469, 32.09670639038086, -8.516599655151367, -39.3696174621582, -25.724075317382812, -38.070167541503906, -28.531696319580078, 21.900413513183594, -29.467260360717773, -23.251541137695312, -25.485641479492188, -38.011940002441406, 2.491666078567505, 2.2793798446655273, 24.856128692626953, -14.74375057220459, -18.94321060180664, -0.9886128306388855, 33.72209930419922, -39.244083404541016, 12.558816909790039, -20.637537002563477, 30.794095993041992, 0.35481566190719604, 25.892566680908203, -30.89293098449707, -22.658632278442383, 3.0604817867279053, -45.35752868652344, -10.90176010131836, 25.46402931213379, 34.4916877746582, 1.767771601676941, -44.97987365722656, 15.644421577453613, -26.6708984375, -22.944355010986328, 21.54541015625, 17.91304588317871, 24.37642478942871, 21.90083122253418, 11.416366577148438, -22.178417205810547, 0.5664451122283936, 25.133346557617188, 23.341726303100586, -26.780336380004883, 25.288145065307617, -27.59564208984375, -0.5312612056732178, 27.447898864746094, 20.738786697387695, -4.453166484832764, 32.03997802734375, -27.577848434448242, -4.913322448730469, -5.821854114532471, 1.0001697540283203, 16.945486068725586, 10.337970733642578, -23.345867156982422, -3.666839122772217, -19.61428451538086, -36.12736892700195, 6.672187805175781, -0.8669054508209229, 3.4457993507385254, -38.595703125, -19.166385650634766, 25.911663055419922, 30.086267471313477, -16.481956481933594, -39.54069137573242, -18.449329376220703, -37.869171142578125, 21.474374771118164, 41.408695220947266, -14.108729362487793, 25.429250717163086, 7.880485534667969, 3.27639102935791, 24.985618591308594, -28.547496795654297, 33.18617248535156, 16.680633544921875, 4.313934326171875, 24.6480712890625, 8.998729705810547, -20.87767219543457, 0.6305934190750122, 26.534500122070312, -34.27188491821289, 25.112964630126953, -31.477455139160156, 2.345348834991455, 27.453855514526367, -19.26641273498535, -16.68976402282715, 22.737817764282227, 14.527587890625, -21.302480697631836, -18.31253433227539, 24.179603576660156, 12.934998512268066, 46.42939758300781, -6.438290119171143, 10.245753288269043, 1.0877710580825806, -24.27901840209961, 7.974348545074463, 2.6209349632263184, -41.94482421875, 0.7694444060325623, 17.13794708251953, 4.858843803405762, -26.058679580688477, -25.549659729003906, -4.475615501403809, 27.63546371459961, -16.193437576293945, 24.85696792602539, -34.092193603515625, -21.07390594482422, 31.788238525390625, 8.3639554977417, -26.105649948120117, -26.863996505737305, 25.662708282470703, 8.97281551361084, 23.1972713470459, -1.6304998397827148, 28.172313690185547, -31.74811363220215, -19.183300018310547, 41.74229431152344, 4.620230674743652, -1.1363128423690796, 10.102927207946777, -12.393786430358887, 3.7502660751342773, -30.789043426513672, -1.7733889818191528, 16.290103912353516, -15.720284461975098, -23.888671875, -13.285884857177734, 21.77789878845215, -5.582290172576904, 12.055304527282715, 5.119584560394287, 32.453147888183594, 21.64141845703125, -19.09078598022461, -27.571260452270508, 16.378299713134766, 39.2799072265625, -21.209331512451172, -15.239485740661621, -36.91579055786133, -50.583709716796875, 26.431358337402344, 26.752197265625, -23.08270835876465, -7.5694990158081055, 21.787338256835938, 27.167823791503906, 18.866844177246094, -30.788888931274414, -16.750091552734375, -34.021053314208984, 41.855140686035156, -23.712833404541016, -27.402233123779297, 13.123794555664062, -29.532264709472656, 44.60087585449219, -1.563006043434143, 27.919919967651367, 26.04482650756836, -37.445796966552734, 46.097129821777344, 29.5386905670166, 20.61410903930664, -18.081844329833984, -5.078439235687256, -35.85914993286133, 14.328939437866211, -5.589914798736572, -5.017484188079834, -1.898766040802002, 4.102579116821289, -17.62502670288086, -0.794453501701355, -22.96699333190918, 4.173689842224121, 23.183305740356445, -31.10042953491211, 21.081565856933594, -19.83831787109375, -31.567663192749023, -2.8362414836883545, 24.320344924926758, -22.42424774169922, -46.94960403442383, 18.830385208129883, -15.036055564880371, -32.79603576660156, -28.73630142211914, 6.3549580574035645, -26.64301109313965, 12.6834135055542, 13.096273422241211, -18.065515518188477, -15.31291389465332, 11.324298858642578, 10.004307746887207, -11.775080680847168, -23.965787887573242, 23.6630859375, -16.31955909729004, 0.873968243598938, -12.621478080749512, 2.6176598072052, 34.9443244934082, -20.994701385498047, 13.040436744689941, -39.964290618896484, -5.582472324371338, 32.83418273925781, 34.03776931762695, 28.65487289428711, 19.828718185424805, -2.7923460006713867, -0.023015035316348076, -34.07722091674805, -2.5364410877227783, -31.893238067626953, -12.237890243530273, -30.50804901123047, 34.58063507080078, 40.86246109008789, 21.786035537719727, -2.441685676574707, 17.718034744262695, -23.358535766601562, -4.422000885009766, -37.52185821533203, -0.6147072315216064, -25.94007682800293, -33.59797668457031, 42.568641662597656, -9.88040542602539, 21.483123779296875, -41.19406509399414, -43.24171447753906, 10.975655555725098, -23.261947631835938, 32.43379211425781, 21.603252410888672, 22.922489166259766, -11.5261869430542, -24.325109481811523, 13.85854721069336, 6.7078986167907715, 12.22446060180664, -15.805243492126465, -16.224506378173828, 31.413801193237305, 2.1037027835845947, 2.190777540206909, 14.709565162658691, -23.66458511352539, 35.072669982910156, 0.6603230237960815, 26.939653396606445, 25.030120849609375, 23.074438095092773, -31.659799575805664, -31.32870101928711, 1.2283306121826172, -10.733196258544922, 9.41982650756836, -10.406726837158203, -2.6780688762664795, -0.7060263752937317, -16.092391967773438, -5.66108512878418, -31.96466636657715, -25.056184768676758, 12.005668640136719, -4.954550266265869, -5.388337135314941, 32.17292785644531, -18.034969329833984, 18.579919815063477, 33.732627868652344, 28.334070205688477, -17.78022575378418, -40.196651458740234, -33.2461051940918, 26.00203514099121, 31.151607513427734, -24.150272369384766, 21.518657684326172, 25.816547393798828, -20.041399002075195, 2.512801170349121, 0.9748135209083557, -7.032641887664795, -2.7446658611297607, 21.2432804107666, 10.750129699707031, -23.2210750579834, 22.378435134887695, -29.883956909179688, 25.27194595336914, 42.01506423950195, 2.2560064792633057, -15.028709411621094, -8.21214485168457, -22.93663215637207, -47.44154357910156, -26.047714233398438, -4.605241298675537, -27.539167404174805, -32.874149322509766, 15.289198875427246, 6.0761399269104, -3.010751962661743, -16.786155700683594, 7.840278148651123, 22.00968360900879, 25.222312927246094, 20.419818878173828, 9.883103370666504, -44.70339584350586, 31.725074768066406, 20.260637283325195, 23.86819076538086, -8.429086685180664, 17.415245056152344, -16.230846405029297, -34.100555419921875, 9.507621765136719, 21.609216690063477, 25.5552978515625, -30.05182456970215, 12.939635276794434, 4.848883152008057, -21.6765079498291, -17.113964080810547, 24.437755584716797, -30.894195556640625, 20.49130630493164, -34.69140625, 26.655216217041016, 30.891035079956055, 20.23373031616211, 19.7871036529541, 24.63627052307129, -34.21137237548828, -3.5065360069274902, 56.550106048583984, 6.973825454711914, 28.712909698486328, 5.7987847328186035, 11.868677139282227, 3.1149404048919678, -46.887184143066406, 20.98639488220215, -23.508056640625, -26.538589477539062, 28.195045471191406, -11.983905792236328, -28.997314453125, -12.76823902130127, -28.161470413208008, 30.776256561279297, 40.22913360595703, -4.225356578826904, 7.644998550415039, -18.98753547668457, -33.031070709228516, 14.86701488494873, 39.569000244140625, 3.5889041423797607, 32.87157440185547, 21.45676040649414, -6.311583042144775, 19.289640426635742, -3.443809747695923, -22.819293975830078, -1.170143485069275, 8.804880142211914, -32.23747253417969, 31.62432098388672, 37.8302001953125, 12.08321762084961, 13.515477180480957, 40.41880416870117, 22.096820831298828, -27.919910430908203, -30.66716766357422, 21.044437408447266, 11.685540199279785, 20.710460662841797, 24.497655868530273, -7.833332538604736, -31.730947494506836, -28.30718231201172, -20.877273559570312, 9.911099433898926, -43.632835388183594, -0.776068925857544, -1.0844388008117676, 6.385745048522949, 3.9261953830718994, 23.24905014038086, 18.387516021728516, -12.466343879699707, -3.9449620246887207, -17.91549301147461, 24.98107147216797, -4.768011093139648, -27.129745483398438, -46.284523010253906, 8.517143249511719, -39.37481689453125, 29.223068237304688, 16.123435974121094, -32.04819869995117, -21.703031539916992, 30.012142181396484, -26.6925048828125, -4.434181213378906, 39.207618713378906, 33.45848846435547, 38.7564697265625, -38.806480407714844, -25.43404769897461, 6.950124263763428, -46.71042251586914, 27.79937744140625, 3.6599299907684326, -22.17214012145996, -11.851663589477539, -22.868667602539062, 1.6850697994232178, 23.216548919677734, 4.380006790161133, -30.58191680908203, -4.960527420043945, 13.307388305664062, -26.35893440246582, 17.820878982543945, -28.581832885742188, -1.4691506624221802, 2.4040651321411133, 11.006134033203125, 21.655412673950195, -20.510034561157227, -47.77751922607422, 23.842632293701172, 28.774171829223633, 2.882091760635376, 6.774913787841797, -20.51629066467285, 36.5543098449707, -23.308597564697266, 28.758071899414062, 24.07305145263672, 18.57648468017578, -16.045978546142578, -31.845272064208984, -33.82654571533203, 6.722283363342285, 16.137487411499023, 38.22690963745117, 10.332590103149414, 32.47687530517578, -25.795509338378906, -23.20720863342285, 24.06663703918457, -16.167007446289062, -31.115549087524414, 24.864582061767578, 31.669784545898438, 37.77427291870117, 0.8702659010887146, 38.64299011230469, 7.103562831878662, 25.30538558959961, -20.826271057128906, -17.106121063232422, 15.327537536621094, -32.118675231933594, 14.368037223815918, -24.93183708190918, -31.618627548217773, -18.56861114501953, -23.230112075805664, -27.352514266967773, -5.177478313446045, 25.527793884277344, 4.325202941894531, -26.03451156616211, 18.315542221069336, 37.22272491455078, -23.105194091796875, 20.551721572875977, 23.878337860107422, 0.1943628042936325, 7.821858882904053, -28.027013778686523, -28.217260360717773, -3.744758129119873, -15.03433609008789, -28.656002044677734, 17.605958938598633, 32.68357849121094, 25.145742416381836, -28.081466674804688, -4.972385406494141, -16.97935676574707, 19.981565475463867, 15.668417930603027, 32.72077560424805, -24.337100982666016, -39.264259338378906, -25.90730857849121, 35.89871597290039, -24.33394432067871, -0.9541297554969788, -26.536479949951172, 11.529803276062012, -22.45863151550293, -42.923309326171875, 29.983196258544922, 41.63333511352539, 4.398240566253662, 52.605262756347656, 24.01163673400879, -8.965121269226074, -21.01395606994629, 23.507492065429688, 23.55476951599121, -26.152179718017578, -30.824981689453125, 5.310128688812256, -3.220233917236328, 29.12936782836914, -14.261821746826172, 22.041757583618164, -26.853567123413086, 33.227081298828125, 24.82505226135254, 4.613405227661133, 33.61122512817383, -16.011783599853516, 37.093753814697266, -14.222630500793457, 12.13962173461914, -21.453495025634766, 23.836101531982422, -0.49130648374557495, -16.248554229736328, 21.639184951782227, 3.6205132007598877, -13.725104331970215, 10.53722095489502, -3.994856834411621, -0.6064544320106506, 2.492738962173462, -34.724918365478516, 55.62355041503906, -38.623779296875, -4.514735221862793, 30.617525100708008, 19.22323989868164, -37.443233489990234, -3.5545692443847656, 24.82804298400879, 25.76430892944336, -15.240704536437988, 1.0842509269714355, -0.9812189936637878, -22.51885986328125, 26.767475128173828, 21.311986923217773, -16.975629806518555, 24.00784683227539, -43.56492614746094, -26.751440048217773, -15.261322975158691, 16.491621017456055, -29.013233184814453, -20.344009399414062, -18.567724227905273, -22.541126251220703, 10.693004608154297, 5.276113033294678, -14.369683265686035, 8.471972465515137, -15.031025886535645, 12.094928741455078, 15.826438903808594, -15.221464157104492, 19.095569610595703, -12.264559745788574, 20.68640899658203, 1.5886067152023315, -23.09269905090332, 18.53204917907715, -32.01137924194336, 23.989429473876953, 27.417753219604492, -24.872562408447266, -19.98097801208496, 28.332014083862305, 30.83449363708496, 4.3750691413879395, -17.594051361083984, -12.068830490112305, -22.654335021972656, -29.958263397216797, 56.04355239868164, -14.476184844970703, -10.416093826293945, 19.055849075317383, 31.387353897094727, -11.867124557495117, 9.018814086914062, -26.46405029296875, -28.031526565551758, -16.054899215698242, 25.973114013671875, -40.61726760864258, 9.904240608215332, 42.46415710449219, 19.468069076538086, 29.6097412109375, 14.697296142578125, 55.40787124633789], "y": [0.7759916186332703, -3.6406259536743164, -23.289154052734375, 20.819971084594727, -7.6324896812438965, 19.92123031616211, 43.868072509765625, -22.38821029663086, 4.382019996643066, 31.14177703857422, 5.227027416229248, 15.775803565979004, 21.244674682617188, 26.4199275970459, 22.352277755737305, 17.346235275268555, 19.288986206054688, 3.9507758617401123, 17.513051986694336, -26.014892578125, -7.583819389343262, -18.495525360107422, 20.673688888549805, 6.613767623901367, 7.684512138366699, 41.740203857421875, -21.98958969116211, 4.626789569854736, 6.962502956390381, -4.278114318847656, 4.296160697937012, -4.367135047912598, -3.2892425060272217, -24.11107063293457, -24.088207244873047, 27.893537521362305, -20.867393493652344, -43.78201675415039, -13.896590232849121, -9.131266593933105, 31.887128829956055, 6.330074787139893, 43.68210983276367, -31.87547492980957, -10.428327560424805, -1.3271379470825195, -46.70319366455078, 16.013059616088867, -11.481450080871582, -12.044733047485352, 45.019065856933594, 12.103970527648926, -49.5598030090332, 30.001802444458008, 20.32126235961914, 20.555728912353516, 44.57991409301758, -46.98029327392578, -15.528109550476074, 16.298738479614258, 9.755322456359863, 18.851070404052734, 4.721692085266113, 17.177059173583984, 43.4815673828125, -31.284242630004883, 15.53948974609375, 28.54724884033203, 14.898662567138672, 9.646346092224121, -13.899603843688965, 28.980703353881836, 26.37453842163086, 13.758145332336426, 15.152687072753906, 43.22829055786133, -7.672515869140625, -11.744587898254395, 29.23827362060547, 0.7533389925956726, 29.817140579223633, -4.960275173187256, 16.545259475708008, -25.78920555114746, -11.729554176330566, 22.27324867248535, 26.09400749206543, 6.148700714111328, 18.392223358154297, 6.843252182006836, 20.438711166381836, 1.3748849630355835, 21.295372009277344, -16.57669448852539, 13.390031814575195, 12.800215721130371, 2.9549553394317627, -49.51226043701172, -6.45876932144165, -14.344071388244629, 32.92411422729492, 7.524731159210205, -36.76853942871094, 23.696380615234375, 25.594099044799805, 21.054502487182617, -21.439863204956055, 1.2335810661315918, -6.7063398361206055, 6.073997497558594, 28.4954776763916, 43.61038589477539, 24.489641189575195, -21.32615089416504, -28.614688873291016, -47.32561111450195, -6.075334548950195, -26.88842010498047, 16.83502769470215, 6.519625186920166, 28.32318687438965, 18.86346435546875, 6.448462009429932, 43.968360900878906, -34.0162239074707, 14.745439529418945, -10.197612762451172, 16.45119285583496, -2.6224374771118164, 4.134485721588135, 12.841777801513672, 9.305736541748047, 32.628475189208984, 41.74103927612305, 0.5954746007919312, -30.68280601501465, -57.96308135986328, -18.38710594177246, 23.48569107055664, 26.078645706176758, -9.467785835266113, 1.1537986993789673, 3.85322642326355, -11.789292335510254, 17.834087371826172, 3.609010696411133, -14.587916374206543, -5.926130771636963, -11.294596672058105, -30.636018753051758, -28.590538024902344, 15.399807929992676, -21.39776039123535, -32.911834716796875, 11.017328262329102, 17.789325714111328, 2.735602617263794, 19.007925033569336, -15.052563667297363, 18.667919158935547, -4.862185955047607, -34.30864715576172, 21.452463150024414, -22.733821868896484, 17.196407318115234, 0.7932646870613098, 21.644283294677734, 3.9861629009246826, -2.0519144535064697, 17.14491844177246, 8.654818534851074, -8.979811668395996, -19.38730812072754, 38.0041389465332, 10.616700172424316, -49.55541229248047, 25.972747802734375, -9.587525367736816, 16.502544403076172, -20.032812118530273, -16.00440216064453, -18.5572509765625, 2.7433454990386963, -33.15553283691406, -27.652597427368164, -27.733285903930664, -25.678884506225586, -32.60496520996094, 0.6915316581726074, 4.179028511047363, -11.852914810180664, -0.4855804741382599, 4.078993797302246, 37.95576858520508, -4.512758255004883, 0.9348689913749695, -13.642739295959473, -9.961472511291504, 6.304323196411133, -57.889556884765625, 5.18546199798584, 9.832958221435547, 3.6185193061828613, -11.464271545410156, -13.321733474731445, 21.906234741210938, -11.621875762939453, -9.43506145477295, 36.26283264160156, -45.0124397277832, -9.491462707519531, -22.829792022705078, 7.124952793121338, 25.338552474975586, 20.1191349029541, 5.8305864334106445, -4.9477949142456055, 24.5741024017334, 1.0550473928451538, 4.6953864097595215, 31.262842178344727, 28.226173400878906, 8.964686393737793, 3.9331369400024414, 25.222328186035156, -9.671710014343262, -22.64767837524414, -36.77866744995117, -32.5235595703125, -31.15875816345215, 12.252556800842285, 4.222483158111572, 13.78288459777832, 12.69057846069336, -29.937911987304688, 6.748587608337402, -29.96857452392578, -14.103946685791016, -28.783159255981445, -25.86179542541504, -2.994077682495117, -9.111732482910156, 10.960945129394531, -10.911979675292969, -13.688796043395996, 25.969207763671875, 7.1732988357543945, -5.926497936248779, -17.654809951782227, -4.065486431121826, 29.321311950683594, 14.17231559753418, -8.874011993408203, 7.274558067321777, 35.39114761352539, -25.458070755004883, 6.369959831237793, -10.4157133102417, -5.687098503112793, -30.724294662475586, -4.801995277404785, -15.581323623657227, 30.08646583557129, -7.999466419219971, 29.083349227905273, 32.645469665527344, 18.313222885131836, -48.05224609375, 1.830079197883606, 21.19451904296875, -18.491764068603516, 31.81870460510254, 16.378646850585938, 38.657264709472656, -20.82090187072754, -8.748703956604004, 25.257518768310547, -11.768755912780762, -29.398441314697266, -16.129131317138672, -37.89502716064453, 44.05482864379883, 3.5461015701293945, -28.25984764099121, -14.040812492370605, -1.4267895221710205, -57.37721252441406, -8.748518943786621, 8.615884780883789, -26.06011962890625, 38.01458740234375, -25.57196807861328, -30.617515563964844, 6.66610050201416, -39.96064376831055, 34.473358154296875, -18.524784088134766, 6.104597568511963, 15.898958206176758, -0.5300903916358948, -38.43528366088867, 34.57248306274414, -25.97218132019043, -2.3979744911193848, -13.885912895202637, -40.03122329711914, -16.020170211791992, -3.1643505096435547, -20.54025650024414, -16.34510040283203, -46.7163200378418, -5.3863983154296875, -7.114291667938232, -0.6205394268035889, 43.989566802978516, -37.4459342956543, -49.68186569213867, -13.117973327636719, 15.642889976501465, 35.77949905395508, -9.771641731262207, 2.5934505462646484, -7.895641803741455, -0.7776479721069336, 17.843889236450195, -37.809486389160156, -45.688209533691406, -20.893619537353516, -37.470306396484375, -12.194716453552246, 16.998292922973633, -46.022918701171875, -1.3919328451156616, -38.18083953857422, 5.435263633728027, -5.758548736572266, 27.98616600036621, -46.63465118408203, -45.94627380371094, -10.39089584350586, -46.30592727661133, 25.35544204711914, -21.753767013549805, -6.046205997467041, 15.6948823928833, -46.27445602416992, -12.404379844665527, 8.98470401763916, 28.16304588317871, 0.39995574951171875, 1.182485818862915, 10.441073417663574, -40.12993240356445, -23.776865005493164, 35.06038284301758, -12.518621444702148, -12.832292556762695, 23.829471588134766, 5.107411861419678, -46.01994705200195, -16.0703182220459, -3.348914384841919, 5.341588020324707, -0.9730135202407837, 3.311143398284912, -31.741125106811523, 2.4080357551574707, -5.740680694580078, 1.494563341140747, 29.171024322509766, -38.56761932373047, -12.913494110107422, -46.833065032958984, -54.739784240722656, 12.93856143951416, -19.282224655151367, 27.617679595947266, 3.1039764881134033, -2.5165631771087646, -57.066261291503906, 29.720731735229492, -19.87661361694336, 24.11783218383789, 40.96733856201172, -46.62106704711914, 1.3331401348114014, 17.62744140625, -12.534945487976074, -29.566848754882812, -4.508371829986572, 19.431447982788086, 24.004526138305664, -12.145401954650879, 17.694210052490234, -11.696256637573242, -18.13347816467285, -30.353351593017578, -15.849960327148438, 3.0157411098480225, 8.881616592407227, 9.378565788269043, -12.187970161437988, -16.668642044067383, 32.76882553100586, -56.650054931640625, 16.42916488647461, -8.83505916595459, -0.6585278511047363, -0.24564270675182343, -8.940010070800781, -19.759305953979492, 24.538841247558594, 18.8416690826416, -36.22917175292969, -1.7818069458007812, -2.9447414875030518, -31.22865867614746, 28.857421875, 29.070600509643555, 21.18728256225586, 15.55053997039795, 2.7294938564300537, 22.312501907348633, 22.843660354614258, 3.639774799346924, -16.01744270324707, 18.59756088256836, 25.695396423339844, 3.4735426902770996, -22.09805679321289, -12.499480247497559, -39.63468551635742, 28.55989646911621, 39.558555603027344, 11.248486518859863, 12.636414527893066, -9.02102279663086, 11.281500816345215, -20.532854080200195, 8.832164764404297, 13.049269676208496, 1.2043235301971436, -13.029067993164062, 2.7660069465637207, -45.554264068603516, -29.701200485229492, -1.2450398206710815, -13.692541122436523, -11.029437065124512, -29.53367042541504, 15.181724548339844, 38.493106842041016, -10.194744110107422, -32.65067672729492, 31.825620651245117, 26.2127742767334, 11.965360641479492, -37.44447708129883, -21.543901443481445, 17.388879776000977, 10.793193817138672, -24.685773849487305, -24.396690368652344, -15.48706340789795, 33.94578552246094, -16.025362014770508, -3.269977569580078, -10.456891059875488, -12.494912147521973, -12.503396034240723, -6.363353252410889, -12.147751808166504, -29.596725463867188, -49.4099235534668, -8.321805953979492, -5.229683876037598, 0.19916322827339172, -7.144326686859131, -14.467777252197266, 37.583805084228516, 5.688825607299805, 5.6951398849487305, -15.17912483215332, -21.907642364501953, 26.914804458618164, 1.7487894296646118, -24.344215393066406, -35.596832275390625, 9.990474700927734, -0.6582975387573242, -11.492061614990234, -9.019193649291992, 2.9483137130737305, 29.936277389526367, -5.140666484832764, 1.6827157735824585, -4.371549606323242, 33.33695983886719, -28.923458099365234, -0.8300164341926575, 36.16974639892578, -17.705703735351562, -6.815948009490967, -53.53717041015625, -11.594026565551758, -31.042531967163086, 6.675070762634277, 21.32356834411621, 15.529623031616211, 11.944430351257324, -0.35534003376960754, -32.538063049316406, -7.438989639282227, 19.631589889526367, 1.2588131427764893, -13.630205154418945, -2.7878239154815674, 21.90275764465332, -36.98292541503906, -8.45212459564209, -54.142417907714844, -14.612138748168945, -25.026395797729492, -38.37811279296875, -30.370031356811523, -15.353935241699219, -13.950182914733887, 25.341711044311523, -1.7874261140823364, -0.3069932460784912, -15.212424278259277, 27.007305145263672, 6.750950813293457, -29.710237503051758, 15.56069564819336, 16.70290756225586, 6.388589382171631, -14.45158863067627, 7.113020420074463, -32.05584716796875, 1.5075082778930664, -0.3893561065196991, 9.943115234375, -23.212430953979492, -6.821053504943848, 20.08639907836914, 18.715293884277344, 8.827033042907715, 1.9056798219680786, -5.7058563232421875, -11.652870178222656, -3.387932777404785, 0.3786715567111969, 14.380252838134766, -56.71847152709961, 21.117446899414062, -37.71965789794922, -54.241943359375, -14.350103378295898, -20.81332015991211, 3.2878334522247314, -10.67265510559082, -0.32053342461586, 3.7592899799346924, 10.428070068359375, 10.407997131347656, 2.4972734451293945, -0.7062227725982666, 19.14634132385254, 6.398151397705078, 4.299874782562256, 3.760450601577759, 24.132062911987305, 5.995715141296387, 14.573549270629883, 19.48911476135254, -13.851371765136719, -21.003219604492188, 16.970165252685547, -15.885420799255371, 3.628730058670044, 2.1503610610961914, -29.923032760620117, 26.20111083984375, 7.741284370422363, 32.105648040771484, 9.180292129516602, -6.98648738861084, -17.33780288696289, 0.8712888956069946, 4.751728057861328, 4.846525192260742, -10.59486198425293, 18.15997886657715, 29.683685302734375, -38.07197952270508, -0.5222833752632141, -21.02174949645996, -23.334903717041016, -15.432982444763184, 21.344350814819336, -2.668494939804077, 3.6932883262634277, -0.5974640846252441, 20.32716941833496, -14.283095359802246, 26.619932174682617, -3.412144184112549, 21.585500717163086, -9.751676559448242, 14.95763874053955, 29.44719696044922, -31.72940444946289, 19.2071590423584, -15.646669387817383, 8.777139663696289, -18.36425018310547, -9.207395553588867, 7.805053234100342, 43.865821838378906, -9.268631935119629, 23.75750160217285, 0.1431180089712143, 18.36624526977539, -13.629610061645508, -1.7064800262451172, -25.253143310546875, -25.676639556884766, -24.98975944519043, 16.742345809936523, 10.481975555419922, 20.030044555664062, 8.42503833770752, -17.38140296936035, 12.415413856506348, 31.848012924194336, 28.064455032348633, 27.80669403076172, -7.410601615905762, -31.07542610168457, 5.595579147338867, 3.3153092861175537, -56.518585205078125, 12.477738380432129, 23.689945220947266, 0.7076516151428223, 36.359779357910156, 8.955078125, -13.739992141723633, 5.325536251068115, 3.711031913757324, 4.538945198059082, 16.6110782623291, -0.9360362887382507, -1.6802998781204224, 3.214501142501831, 2.177314519882202, 12.627079010009766, -19.1135311126709, -13.703083992004395, -52.57640838623047, -56.358882904052734, -8.494319915771484, 4.367031097412109, 25.281288146972656, 25.92384147644043, 32.85138702392578, 13.90208625793457, -33.06500244140625, -0.4284071922302246, 5.393108367919922, 37.30439376831055, 40.432037353515625, -18.66435432434082, 25.425935745239258, -53.192962646484375, 15.78935718536377, 21.69871711730957, -22.50216293334961, 31.68001365661621, -13.779940605163574, -2.1182498931884766, -27.12453269958496, -20.296337127685547, -12.237710952758789, 6.601306915283203, 9.061166763305664, 19.914657592773438, 23.388690948486328, -26.082355499267578, -19.783044815063477, -21.549659729003906, -14.530941009521484, -22.935094833374023, -37.760894775390625, 22.845394134521484, 22.464988708496094, -13.845258712768555, -29.445293426513672, -21.789569854736328, -6.736682891845703, 2.93696665763855, -1.3603414297103882, -23.988555908203125, 20.869529724121094, -28.432355880737305, 25.28561019897461, 38.1281623840332, 27.745927810668945, 23.473039627075195, 9.339628219604492, 9.099048614501953, 5.129001140594482, 28.864513397216797, -0.3137497007846832, -54.67223358154297, 25.58904457092285, -9.30627727508545, 23.365406036376953, 2.256967544555664, 3.1911873817443848, -2.8428878784179688, 35.362064361572266, 41.96004867553711, -7.315688133239746, 27.356828689575195, 26.3509578704834, 5.115618705749512, -14.568831443786621, -14.39768123626709, 19.519746780395508, -22.476869583129883, -49.64778137207031, -24.16710090637207, 27.224422454833984, -17.75432586669922, 3.946225643157959, -16.034032821655273, -21.94512367248535, -30.58548927307129, -11.801558494567871, 3.9472570419311523, -9.92831039428711, 31.418649673461914, -37.11894226074219, -33.55390167236328, 2.69364333152771, -5.62164306640625, -21.898717880249023, 20.201242446899414, 11.143776893615723, -0.9852340221405029, -15.852481842041016, -11.356022834777832, -16.995529174804688, -6.735117435455322, 6.937357425689697, -24.757993698120117, 36.51011276245117, 3.2063052654266357, -11.438278198242188, 4.0546464920043945, 11.91310977935791, 6.914626121520996, -19.14011001586914, 11.65318775177002, 12.897249221801758, 14.38511848449707, -4.37410306930542, -37.29780960083008, -7.478130340576172, 0.46273118257522583, -6.789975643157959, 26.4666805267334, 8.990625381469727, 38.568851470947266, 20.849870681762695, -12.860421180725098, 10.092039108276367, -1.787328839302063, -14.560946464538574, 14.645828247070312, -22.623170852661133, -6.202895164489746, 3.3157286643981934, 25.402128219604492, -6.753644943237305, 5.25481653213501, -5.244412422180176, 32.03647994995117, 30.024538040161133, 6.682212829589844, 27.788909912109375, -9.103846549987793, 23.700529098510742, -29.771560668945312, -13.56213092803955, -19.744098663330078, -13.870864868164062, 2.712986946105957, 24.046051025390625, 22.184139251708984, 4.568563461303711, -23.761152267456055, 22.46992301940918, 22.445980072021484, -7.387307167053223, -4.319103240966797, -14.376227378845215, -13.77026653289795, -36.65332794189453, -26.4950008392334, -54.92448425292969, 8.357664108276367, -4.819983005523682, -54.225399017333984, -41.1038703918457, 0.14171889424324036, -38.531986236572266, -16.904813766479492, -15.91237735748291, 31.67957878112793, -53.91611099243164, 44.03260803222656, 1.6492999792099, -12.868844985961914, -14.737887382507324, -8.23492431640625, -5.757556438446045, 1.4833632707595825, 15.8489408493042, 1.2068268060684204, -7.378403663635254, -57.002525329589844, -10.101675987243652, -4.78950309753418, 29.095613479614258, -38.468135833740234, -7.888494968414307, 27.4762020111084, -16.027069091796875, -51.45581817626953, 4.596038341522217, 19.15445899963379, -22.513975143432617, 3.3046040534973145, 25.72966766357422, 21.823604583740234, -11.551633834838867, -33.01319885253906, 11.394084930419922, 7.195469856262207, 20.212482452392578, 26.48271369934082, 2.616854190826416, -31.474384307861328, -3.3472626209259033, -40.955039978027344, -53.38508605957031, -10.928792953491211, 0.8469574451446533, -19.17632293701172, 4.6781415939331055, 33.966583251953125, -40.198062896728516, 9.147497177124023, -11.084015846252441, 26.845853805541992, 5.6857991218566895, -36.65394973754883, -20.510520935058594, 25.275686264038086, -10.551287651062012, 32.241004943847656, -5.730658054351807, -0.3945542573928833, 29.486865997314453, -17.8513240814209, 9.543658256530762, -9.149157524108887, 37.03864288330078, 32.328590393066406, 15.512519836425781, -10.74400520324707, 2.3266823291778564, -23.358440399169922, 0.8889482021331787, -4.2739644050598145, 1.9216173887252808, -19.088502883911133, 4.031036376953125, 3.417526960372925, -11.423294067382812, -25.521724700927734, -14.192239761352539, 23.400466918945312, -20.943145751953125, 3.9157347679138184, 22.556297302246094, 30.496557235717773, 7.984382629394531, -3.638749837875366, 5.608305931091309, -8.861174583435059, 32.77473068237305, -8.162479400634766, 34.356563568115234, -6.460723400115967, 6.522906303405762, 2.5926249027252197, 32.44685745239258, -11.160355567932129, -50.011566162109375, 2.577341079711914, -0.5713502168655396, -20.630334854125977, 2.567573070526123, -1.846222996711731, -17.234952926635742, 28.67310905456543, -10.089690208435059, -14.510554313659668, -11.778240203857422, 26.57242202758789, -39.66093063354492, -12.767410278320312, 17.243572235107422, 2.609018087387085, -1.9138067960739136, 27.499021530151367, 14.962827682495117, -31.684127807617188, -25.13447380065918, -19.923690795898438, 9.577275276184082, 7.907087802886963, -13.212389945983887, 34.18522262573242, 2.8239285945892334, 2.7354648113250732, 11.643756866455078, -14.516242980957031, 5.816092014312744, -41.812923431396484, 17.552597045898438, -2.690308094024658, -15.177886009216309, 29.552677154541016, 26.495576858520508, 3.952030897140503, 27.153745651245117, -19.63973045349121, 0.9816049337387085, -23.426044464111328, 2.2506816387176514, -1.8218797445297241, 3.250652551651001, -15.55886459350586, 20.178489685058594, 4.852514743804932, 12.609853744506836, -11.798691749572754, -23.207653045654297, -12.790054321289062, 24.35922622680664, 10.42775821685791, -16.434619903564453, 6.914855003356934, 7.492265701293945, -12.619941711425781, -25.9012451171875, -7.9760966300964355, -21.230833053588867, -3.630035161972046, -14.867901802062988, -0.35423076152801514, -0.6106939315795898, 13.123774528503418, -44.9942626953125, 19.986244201660156, 28.199037551879883, -3.123006582260132, -22.448719024658203, 9.610121726989746, 24.544523239135742, 12.60300064086914, -16.888952255249023, -14.031962394714355, -36.67163848876953, -15.05661392211914, 30.34974479675293, 23.105133056640625, 32.002872467041016, 16.440832138061523, -11.571399688720703, 16.418912887573242, -10.097561836242676, 37.063053131103516, -18.26340675354004, -53.910606384277344, 28.30499267578125, 29.525915145874023, 29.519241333007812, 2.9121196269989014, -42.81007385253906, 22.29466438293457, -19.3885498046875, 22.281566619873047, 19.744543075561523, -16.422435760498047, 3.2500834465026855, -6.457674026489258, 4.619200706481934, -49.97755432128906, 15.043401718139648, 22.46116828918457, 28.95647621154785, 1.4530792236328125, 34.82822799682617, -7.443260669708252, -25.117441177368164, 26.038700103759766, 1.2658637762069702, 22.584590911865234, -53.17228698730469, 9.3774995803833, -7.009722709655762, -5.534932613372803, 7.382497310638428, -20.55126190185547, 17.998048782348633, 26.282962799072266, -32.52316665649414, 37.13994598388672, -13.446436882019043, -3.2907660007476807, 8.345915794372559, 15.826263427734375, -21.35399627685547, 11.428261756896973, -42.56570816040039, 28.10856819152832, 35.52616882324219, -14.433711051940918, 1.1021771430969238, -8.268823623657227, -3.7668635845184326, 4.9448113441467285, -19.526470184326172, 2.66465163230896, 5.401305675506592, 9.786561012268066, -24.440528869628906, 18.771129608154297, 10.653404235839844, -31.617456436157227, 9.267374038696289, -18.506229400634766, -1.6746933460235596, -42.627220153808594, -33.23947525024414, -19.29519271850586, 1.689980149269104, 1.1554228067398071, 16.554014205932617, -42.282466888427734, 12.354695320129395, -14.205859184265137, 6.010349273681641, 9.209749221801758, 35.26630401611328, -43.28328323364258, 30.620046615600586, -20.646316528320312, -1.2343077659606934, -9.094980239868164, 37.518123626708984, -53.82072448730469, -19.026453018188477, -42.10103225708008, 3.522247791290283, 8.613943099975586, 3.4824914932250977, -6.721401691436768, -27.41962432861328, -7.104013919830322, 27.73940658569336, -42.060035705566406, -51.68498229980469, -28.932476043701172, 12.493768692016602, -2.7183451652526855, 19.425046920776367, 22.9385986328125, -10.088871002197266, -7.47999906539917, -2.735816240310669, -8.022076606750488, 34.17253112792969, -23.6005916595459, -15.019525527954102, 26.5590877532959, 2.8506388664245605, 35.221946716308594, -3.8205103874206543, -9.607722282409668, -12.471139907836914, -30.087482452392578, 15.80795669555664, 6.9476728439331055, 24.500682830810547, 3.4189887046813965, -42.94443893432617, 9.062100410461426, 7.27286958694458, 34.79240417480469, 9.981236457824707, -8.266950607299805, -20.488422393798828, 14.630905151367188, -27.451807022094727, 8.353620529174805, 29.953956604003906, 29.543075561523438, -12.243266105651855, -23.57456398010254, 18.62401580810547, -10.91314697265625, 27.78925132751465, -10.855302810668945, -22.235307693481445, -15.47803020477295, -43.05320739746094, 25.06253433227539, 2.8007993698120117, -14.876740455627441, -13.747426986694336, -9.446224212646484, -6.749480724334717, -18.140047073364258, 38.32002639770508, 4.602319240570068, -15.886719703674316, 20.376914978027344, -16.322406768798828, 22.679086685180664, -17.22351837158203, -4.058629035949707, -1.938485026359558, 7.621813774108887, 35.44670486450195, -8.306989669799805, -16.5284481048584, -36.681434631347656, 10.834392547607422, -7.179368019104004, 24.452959060668945, 31.199195861816406, 13.634305000305176, 31.2050838470459, -18.586206436157227, 27.690475463867188, -7.666504859924316, -25.985719680786133, 7.818426132202148, -11.01034164428711, -43.69028091430664, 4.021851062774658, -20.881772994995117, 23.704246520996094, -7.899613857269287, 32.738101959228516, -44.56741714477539, 1.8844717741012573, 37.626583099365234, -5.24144172668457, 21.363521575927734, 27.337909698486328, 4.751648426055908, -10.247143745422363, -12.972007751464844, 2.7422146797180176, -7.876216888427734, 30.515762329101562, -52.91660690307617, 35.96887969970703, 29.363994598388672, 29.742387771606445, -45.714054107666016, -27.35686492919922, 7.925130844116211, -22.251312255859375, 8.754838943481445, -1.1651092767715454, 2.740516185760498, 27.35274887084961, -12.397228240966797, -30.726787567138672, 11.874800682067871, 3.16971755027771, 29.09548568725586, -10.352903366088867, -21.480329513549805, 7.276698112487793, 25.828920364379883, 2.999915599822998, 2.584071636199951, -9.826889038085938, 29.582595825195312, -6.500749588012695, -1.9245585203170776, -3.5498569011688232, 28.257556915283203, -7.236792087554932, 17.172605514526367, 1.0830292701721191, 25.240825653076172, -0.7858383059501648, -14.722410202026367, -2.903956174850464, 6.5788774490356445, 11.20622730255127, 1.1998697519302368, -44.09264373779297, 1.6563920974731445, -7.91575813293457, 2.560762405395508, -3.444949150085449, 1.4204050302505493, -16.109498977661133, -6.369657516479492, 25.77358627319336, -19.093509674072266, -27.77699089050293, 21.405914306640625, 8.816835403442383, -23.35803985595703, -29.92902946472168, 18.97443962097168, -17.118349075317383, -0.7852721810340881, 18.43147850036621, -25.507673263549805, -6.011343479156494, -54.502540588378906, -5.621122360229492, -42.9461784362793, -43.98518753051758, -8.189393997192383, 8.95803165435791, 25.20613670349121, 25.393083572387695, -6.824323654174805, -1.0370063781738281, 22.44027328491211, -16.982379913330078, -54.37163162231445, 28.903043746948242, 10.674015998840332, 31.102336883544922, -6.245202541351318, 27.56028175354004, -45.206451416015625, 20.572690963745117, -9.800185203552246, -5.719703197479248, 3.9438767433166504, 6.029404640197754, 20.127408981323242, 26.55581283569336, 29.3535099029541, -3.3826112747192383, 37.89126968383789, -45.72521209716797, 28.212398529052734, -11.574592590332031, 28.098995208740234, -19.332401275634766, 16.459447860717773, -6.503080368041992, -4.933900356292725, -28.981624603271484, 4.8802266120910645, 4.094231128692627, 0.23389028012752533, -17.13031005859375, -9.752185821533203, -44.72557067871094, -8.139307975769043, 40.69459533691406, -7.863031387329102, 1.246816873550415, -18.945724487304688, -19.06878662109375, 7.979964733123779, -26.17671775817871, -46.273983001708984, 23.464200973510742, -23.82752227783203, 31.805917739868164, -45.519325256347656, -12.884078025817871, -10.195247650146484, -11.517685890197754, -4.2917866706848145, -11.577947616577148, -18.62554931640625, 25.70341682434082, -53.603782653808594, -8.916252136230469, 3.2286136150360107, 24.467247009277344, 8.652841567993164, 16.867761611938477, -20.173830032348633, 2.77109432220459, 38.81968307495117, -43.56083297729492, -28.26770782470703, -3.6898720264434814, 25.631732940673828, 18.620853424072266, -10.59304428100586, -16.88636016845703, 21.960092544555664, -52.786651611328125, 23.639202117919922, 4.716640949249268, 37.02110290527344, 20.70582389831543, -12.141824722290039, -9.729571342468262, 23.95210838317871, 14.417019844055176, 8.991204261779785, 17.456459045410156, -15.950798034667969, -32.850528717041016, 22.243404388427734, 12.584044456481934, 19.512664794921875, 23.624696731567383, 14.941689491271973, -5.087347030639648, -15.072732925415039, -18.409549713134766, -13.70997142791748, -10.212864875793457, 10.903144836425781, -10.701608657836914, 37.52454376220703, 34.070274353027344, 4.8295793533325195, -21.00509262084961, -47.068729400634766, 27.624401092529297, -14.416326522827148, 1.776346206665039, 0.52314293384552, -15.591980934143066, -22.075176239013672, 27.451723098754883, -12.812394142150879, -1.4619221687316895, 40.7308349609375, 16.904830932617188, 24.41512107849121, 21.31136131286621, 34.79662322998047, 28.70189094543457, 8.184965133666992, 19.252370834350586, -9.774378776550293, 35.921417236328125, 0.7778817415237427, -53.37324523925781, 17.26987075805664, 0.589078426361084, 8.533644676208496, -1.2233484983444214, -6.287142276763916, 5.880637168884277, 22.094619750976562, 22.084705352783203, 6.707516670227051, -10.882472038269043, 0.5475532412528992, -28.359086990356445, -49.4267578125, 6.98879861831665, -3.3697876930236816, 0.7589502930641174, 0.9440802931785583, -6.276461601257324, 34.41896438598633, -2.4345481395721436, -15.256546020507812, -5.88403844833374, -22.929655075073242, -6.005350112915039, -14.547087669372559, -8.89285659790039, 21.535478591918945, 31.29326057434082, -3.576249361038208, 30.719072341918945, -8.388545036315918, -16.34214973449707, -10.10149097442627, -10.008967399597168, -51.94231414794922, 22.701107025146484, 41.681827545166016, -9.164434432983398, 13.69013500213623, 4.549229621887207, 14.761117935180664, -33.20355224609375, -21.428340911865234, 14.69298267364502, 27.409534454345703, 34.580562591552734, 8.292879104614258, -20.871402740478516, -1.8461962938308716, 27.309144973754883, 32.16613006591797, -22.063623428344727, 24.815797805786133, 19.848581314086914, 0.4081062972545624, 8.959510803222656, 3.706320285797119, 27.501232147216797, -9.021251678466797, -28.175527572631836, 23.62824058532715, -6.212672710418701, 22.011613845825195, -8.009370803833008, 41.88353729248047, 28.455570220947266, -15.914687156677246, 2.378023386001587, -4.079905033111572, -35.547061920166016, 26.85785675048828, -17.868234634399414, -9.061722755432129, 34.791133880615234, -45.81586837768555, 25.81400489807129, 10.499910354614258, -6.076362609863281, -10.066451072692871, 9.4410400390625, 10.478606224060059, 0.6059494614601135, -24.64291763305664, -4.701423645019531, 23.98299217224121, 16.230878829956055, -14.77796459197998, -50.1327018737793, -33.60856246948242, 26.69098663330078, 9.143117904663086, 3.906924247741699, 22.734912872314453, 11.754240989685059, 0.13564573228359222, 26.99451446533203, 5.556237697601318, 25.403553009033203, -16.737192153930664, 13.741060256958008, 24.77353858947754, -25.017141342163086, -47.05302047729492, 20.074440002441406, -26.56513786315918, 23.76919937133789, -6.931262493133545, -20.281999588012695, 38.82170104980469, -46.615745544433594, 8.474113464355469, -47.083560943603516, -17.17325782775879, 22.148731231689453, -24.429988861083984, 22.657020568847656, -1.5047237873077393, 1.7599259614944458, 15.541141510009766, 7.296482086181641, -28.78550148010254, 20.022775650024414, 29.17530632019043, 13.650616645812988, 18.54542350769043, 17.617597579956055, 19.547687530517578, -31.989700317382812, 30.343250274658203, 27.962610244750977, -12.470407485961914, -5.585540294647217, 13.800868034362793, 29.846416473388672, 24.083078384399414, 17.290719985961914, 18.604541778564453, -1.3190189599990845, -7.761160850524902, 12.337324142456055, 26.320308685302734, 6.183485984802246, -19.028907775878906, -21.495079040527344, -15.942479133605957, -27.256750106811523, -25.538957595825195, 17.644630432128906, -6.5476789474487305, 21.076566696166992, 23.490497589111328, 20.887544631958008, -9.46084213256836, 21.0205078125, 22.596948623657227, 17.097875595092773, 21.0606689453125, -10.266593933105469, 6.378859043121338, 24.138309478759766, 18.664182662963867, 4.688022136688232, -14.38139820098877, 6.293054103851318, -8.4316987991333, 24.882814407348633, -0.753765881061554, 20.90117073059082, 5.530480861663818, -21.878915786743164, 25.217113494873047, 12.01472282409668, 11.36120891571045, -35.40458297729492, -53.971012115478516, -6.60587215423584, 28.25444221496582, -46.08564376831055, 33.228477478027344, -7.237435817718506, -15.297768592834473, 35.44676208496094, -6.290627479553223, -46.43275833129883, -22.239255905151367, -0.4857376515865326, 2.3210763931274414, 17.837665557861328, 34.64336395263672, 23.92397689819336, 9.41584587097168, -19.049131393432617, 15.62318229675293, -1.3057444095611572, 33.06262969970703, 22.474796295166016, 10.681458473205566, -22.489822387695312, 16.38488006591797, -17.32120132446289, 23.208200454711914, -30.904647827148438, 1.0187898874282837, 11.17858600616455, 4.051210403442383, -12.239486694335938, 10.60641860961914, -1.3662785291671753, 18.934354782104492, 14.83105754852295, 28.703580856323242, 6.925921440124512, -11.431870460510254, -10.252763748168945, 2.9490394592285156, 2.3163979053497314, 25.25587272644043, -2.996349573135376, 36.66163635253906, 10.755424499511719, 23.011899948120117, 8.402533531188965, -10.327049255371094, -9.12518310546875, -1.6904947757720947, 23.304828643798828, 11.040984153747559, 0.5750462412834167, 26.6600399017334, -54.6497688293457, 31.16869354248047, 19.860271453857422, -16.006023406982422, 8.609127044677734, -14.740387916564941, 3.0118277072906494, 1.1655805110931396, -3.3464064598083496, -12.846391677856445, 25.64476203918457, 22.821697235107422, 10.269889831542969, 11.518893241882324, -19.433908462524414, -1.2656147480010986, 8.973549842834473, -20.535322189331055, 17.572790145874023, -25.782304763793945, -15.54978084564209, 2.976494312286377, -13.213238716125488, 27.62223243713379, -15.44670581817627, 7.367940425872803, 26.781267166137695, -21.46682357788086, -32.518890380859375, 28.537105560302734, 37.38386154174805, -18.678647994995117, 5.904191970825195, -15.800373077392578, -4.7943949699401855, 16.118717193603516, -12.455345153808594, 12.73672866821289, -14.845305442810059, 3.2951207160949707, 6.335077285766602, -20.538362503051758, -0.7352592349052429, -3.5416147708892822, -21.970212936401367, -16.752727508544922, 25.919876098632812, -0.4146997928619385, 29.375722885131836, -40.06963348388672, -26.91667938232422, 2.935887098312378, 21.90707015991211, 23.222925186157227, -8.56371021270752, -20.6973819732666, 29.601594924926758, -48.700340270996094, -9.443586349487305, 6.319009304046631, -22.616588592529297, 4.38931131362915, -7.117061614990234, 22.28324317932129, -14.365506172180176, -15.806327819824219, -9.32514476776123, -12.723501205444336, -47.112911224365234, -12.782297134399414, 6.941136360168457, 17.777040481567383, 4.677065372467041, -23.01091194152832, -1.360054850578308, 30.7772216796875, -15.2069091796875, 28.182159423828125, 22.2259578704834, 2.001328706741333, -0.42510491609573364, 12.925050735473633, -18.827749252319336, 11.853730201721191, -20.94610595703125, -10.660883903503418, 25.371606826782227, -5.070911884307861, 1.5295438766479492, 3.880300998687744, -13.029332160949707, 29.007823944091797, -1.519002914428711, -16.879907608032227, 23.02596664428711, 22.731128692626953, -15.942485809326172, -10.090974807739258, 22.611129760742188, 33.613155364990234, 12.174323081970215, 21.12932014465332, -17.134122848510742, 37.9313850402832, -49.86051940917969, -8.613064765930176, -3.06887149810791, 19.992908477783203, -20.261343002319336, 24.10550308227539, 30.387548446655273, 4.12537956237793, -21.320270538330078, 24.748403549194336, -3.5747556686401367, 4.1420392990112305, 27.175556182861328, -23.12799072265625, 8.29029369354248, -8.003615379333496, 14.00313949584961, -2.035797357559204, -18.49028968811035, -11.100184440612793, 2.9782118797302246, 12.756921768188477, 16.341196060180664, 22.716461181640625, -27.473403930664062, 32.007835388183594, 25.87482452392578, -8.310724258422852, -20.78783416748047, -8.257468223571777, -27.316051483154297, 24.592079162597656, 22.39656639099121, -5.7170233726501465, 9.437000274658203, 24.11405372619629, 4.76743745803833, -17.03681755065918, 29.36756706237793, -3.0117275714874268, -24.866165161132812, -8.117352485656738, -3.045196056365967, 21.2962703704834, 28.328601837158203, -7.045621871948242, -4.941740036010742, -7.105769634246826, -7.636569976806641, 21.06814956665039, 22.286588668823242, 34.85944747924805, 25.457000732421875, -5.0673298835754395, 2.696906805038452, -49.4389533996582, -6.681904315948486, 18.987241744995117, 34.137786865234375, 3.9316608905792236, -33.40628433227539, 2.584902763366699, 1.35608971118927, -0.07626982033252716, -9.89172077178955, 0.612320601940155, -49.24447250366211, 16.618911743164062, 11.085185050964355, -17.39734649658203, -26.995595932006836, -49.023563385009766, -15.301987648010254, 33.17325973510742, 1.3640056848526, -21.36125946044922, 5.78532600402832, -8.106476783752441, -5.967525005340576, 35.40576171875, -12.130590438842773, -27.077579498291016, 18.185331344604492, -9.871763229370117, -8.480135917663574, 24.90987205505371, -11.32273006439209, 18.40519905090332, 23.88498306274414, 6.777762413024902, 2.3873069286346436, 23.256311416625977, 26.43995475769043, 24.29882049560547, 9.829943656921387, -10.936753273010254, -3.374974250793457, 23.7333984375, 13.079255104064941, 36.922794342041016, -7.867142677307129, 25.147607803344727, 32.12080383300781, 27.866975784301758, 37.176334381103516, -26.19255256652832, -13.004867553710938, -10.54293441772461, 15.211745262145996, -11.080645561218262, -1.3635472059249878, -46.36931228637695, 21.373476028442383, 26.576370239257812, -3.900158405303955, -18.332239151000977, 9.256752967834473, 27.100833892822266, 10.849624633789062, -30.95633888244629, -15.050372123718262, 17.755800247192383, 21.873323440551758, 34.669273376464844, -1.9021167755126953, -0.8155902624130249, -11.336173057556152, -16.848039627075195, 25.659622192382812, 18.749881744384766, 3.1531455516815186, -47.01699447631836, -31.435880661010742, 25.973209381103516, -48.7140007019043, -3.756977081298828, -11.38253402709961, -16.616331100463867, -3.5210320949554443, 6.467102527618408, -49.96825408935547, -17.897247314453125, -34.05746078491211, 5.996475696563721, 24.97088623046875, 0.2881949841976166, 31.716686248779297, 22.698575973510742, 23.673656463623047, 38.03388595581055, -14.777045249938965, 14.437602996826172, 19.74437713623047, 21.201669692993164, 39.55492401123047, -20.823749542236328, -3.649378538131714, -14.629413604736328, -19.17437171936035, -49.023372650146484, -14.627720832824707, 12.096596717834473, 30.59984016418457, 34.0128173828125, 6.310059070587158, -11.272665023803711, 32.96205139160156, -5.688619136810303, 24.376863479614258, 29.339460372924805, 28.751968383789062, 27.233930587768555, -1.4427504539489746, 28.084806442260742, 9.05785846710205, -10.457371711730957, 23.119043350219727, 1.3470439910888672, -7.605332851409912, 23.605287551879883, 7.740678310394287, -20.7741756439209, 18.161678314208984, 24.659751892089844, 22.06919288635254, 12.107924461364746, 21.279216766357422, -11.047853469848633, -0.7493904232978821, 0.9257198572158813, -47.59543228149414, 4.252862453460693, -24.12782859802246, 28.721227645874023, -48.321937561035156, 33.089542388916016, 35.11252975463867, -0.7266768217086792, -7.674515724182129, -8.179985046386719, -16.52964210510254, -23.913606643676758, -18.524898529052734, 7.137425422668457, 8.235429763793945, 29.23381233215332, 29.5884952545166, 16.170333862304688, -7.871369361877441, 35.33595657348633, 24.436603546142578, -36.649662017822266, -49.925506591796875, 12.567042350769043, 27.106979370117188, -1.5349466800689697, 0.2940431535243988, -30.44342613220215, -2.4922311305999756, 5.979637145996094, -4.833876132965088, 9.079828262329102, 35.043758392333984, 2.727872848510742, 3.295454502105713, -51.851322174072266, -19.088613510131836, 16.62021255493164, 4.669281959533691, 15.097481727600098, -47.66859436035156, -0.046405766159296036, -16.92814826965332, -14.55053424835205, 3.400102376937866, 4.460333824157715, 17.839284896850586, -5.617920875549316, 13.729016304016113, 26.647069931030273, 0.8734463453292847, 21.921430587768555, 12.813416481018066, -1.7558257579803467, -11.032368659973145, -25.106700897216797, 24.81439781188965, 4.714295387268066, -7.06387186050415, -3.4276835918426514, 25.686635971069336, -8.647257804870605, -28.464155197143555, -12.29775619506836, 0.3871571719646454, -31.09954071044922, 25.867111206054688, -26.647804260253906, -2.6839208602905273, 4.403846263885498, 29.169578552246094, -0.31644386053085327, 20.938724517822266, 23.118982315063477, 18.158130645751953, -17.91675567626953, 10.140777587890625, -10.195860862731934, 22.553781509399414, 11.15100383758545, 37.688297271728516, -19.254682540893555, -11.348230361938477, 36.74447250366211, 3.7288873195648193, 10.179970741271973, 5.220588684082031, 25.636913299560547, -10.16256332397461, -26.516897201538086, -8.115053176879883, -17.853200912475586, 33.36912155151367, -27.071144104003906, -15.770822525024414, 5.146474838256836, -32.91862869262695, -12.848506927490234, 28.57415199279785, 22.626911163330078, 0.9072468280792236, 5.382614612579346], "text": ["START", "END", "the", "of", "and", "in", "to", "a", "is", "as", "was", "for", "by", "that", "with", "on", "from", "are", "it", "his", "or", "an", "at", "be", "which", "he", "this", "were", "not", "have", "also", "has", "had", "their", "its", "but", "one", "\\u2013", "other", "first", "they", "been", "such", "new", "more", "who", "some", "after", "most", "all", "can", "used", "two", "when", "into", "there", "may", "many", "these", "than", "only", "during", "time", "between", "would", "american", "over", "world", "about", "years", "no", "while", "however", "states", "use", "known", "both", "war", "where", "later", "if", "united", "called", "her", "state", "including", "made", "being", "through", "system", "under", "then", "number", "city", "up", "since", "i", "three", "century", "government", "them", "became", "early", "part", "people", "out", "any", "him", "well", "often", "because", "will", "so", "each", "national", "several", "same", "us", "before", "work", "although", "against", "year", "could", "english", "example", "second", "form", "university", "b", "until", "name", "found", "she", "film", "south", "1", "high", "include", "those", "major", "life", "group", "large", "like", "series", "different", "even", "general", "north", "international", "following", "another", "british", "language", "around", "power", "within", "john", "according", "much", "de", "set", "population", "based", "history", "using", "now", "very", "among", "end", "common", "modern", "did", "due", "four", "what", "music", "began", "country", "own", "area", "d", "french", "public", "military", "political", "german", "game", "still", "small", "book", "order", "do", "law", "period", "great", "church", "day", "2", "death", "led", "development", "president", "party", "members", "long", "important", "published", "million", "king", "human", "considered", "said", "without", "usually", "water", "way", "see", "player", "given", "though", "term", "family", "countries", "last", "air", "late", "isbn", "european", "support", "along", "control", "place", "east", "times", "west", "various", "central", "york", "school", "home", "theory", "main", "army", "make", "become", "force", "island", "point", "systems", "back", "ii", "similar", "developed", "local", "thus", "less", "line", "old", "house", "original", "took", "popular", "others", "held", "left", "few", "age", "forces", "company", "we", "case", "included", "europe", "largest", "groups", "union", "western", "team", "2010", "must", "production", "roman", "single", "written", "3", "service", "result", "economic", "does", "social", "press", "process", "2012", "released", "region", "sometimes", "areas", "field", "2007", "established", "named", "total", "land", "2013", "river", "having", "per", "research", "march", "space", "science", "further", "should", "2011", "five", "former", "down", "produced", "court", "c", "best", "god", "wrote", "2008", "january", "every", "2009", "rather", "games", "september", "either", "2006", "generally", "data", "show", "june", "october", "third", "december", "languages", "london", "just", "works", "july", "black", "word", "how", "standard", "light", "role", "2014", "natural", "created", "empire", "sea", "came", "season", "april", "free", "man", "body", "energy", "version", "greek", "right", "information", "especially", "played", "2005", "council", "november", "10", "study", "france", "play", "you", "art", "4", "take", "germany", "species", "described", "august", "possible", "islands", "white", "northern", "society", "near", "men", "red", "upon", "kingdom", "england", "foreign", "republic", "act", "days", "addition", "minister", "trade", "built", "5", "continued", "next", "never", "again", "son", "america", "women", "throughout", "2000", "model", "available", "soviet", "won", "received", "member", "off", "movement", "means", "children", "range", "league", "instead", "making", "level", "china", "short", "2015", "terms", "seen", "least", "above", "rights", "almost", "special", "position", "change", "himself", "little", "once", "february", "southern", "design", "certain", "final", "christian", "parts", "died", "significant", "st", "forms", "numbers", "type", "2004", "official", "itself", "together", "religious", "television", "traditional", "formed", "education", "center", "program", "nations", "good", "head", "computer", "eastern", "six", "current", "present", "album", "particular", "higher", "followed", "side", "title", "battle", "india", "elements", "books", "radio", "civil", "function", "story", "low", "middle", "character", "words", "office", "m", "actor", "introduced", "ancient", "record", "located", "born", "earth", "20", "community", "chinese", "today", "services", "influence", "lost", "culture", "japanese", "father", "despite", "rate", "young", "band", "evidence", "2001", "author", "15", "william", "latin", "2003", "prime", "james", "lower", "thought", "live", "source", "david", "taken", "open", "royal", "effect", "films", "structure", "capital", "nature", "spanish", "particularly", "eventually", "rule", "whose", "top", "referred", "across", "value", "j", "far", "market", "college", "class", "half", "6", "meaning", "2002", "12", "full", "africa", "required", "project", "network", "s", "increased", "beginning", "e", "building", "cases", "therefore", "x", "associated", "includes", "typically", "able", "allowed", "strong", "industry", "eg", "robert", "p", "list", "russian", "provide", "related", "provided", "leading", "bc", "business", "mass", "remained", "person", "rock", "aircraft", "players", "1999", "star", "economy", "independent", "george", "view", "living", "style", "song", "studies", "food", "run", "complex", "went", "individual", "outside", "fact", "italian", "hand", "town", "months", "football", "technology", "limited", "might", "policy", "events", "base", "cities", "paul", "average", "private", "health", "my", "started", "majority", "moved", "lead", "real", "practice", "features", "whether", "gave", "recent", "indian", "size", "r", "8", "return", "uses", "originally", "founded", "close", "oil", "commonly", "v", "designed", "writing", "sound", "action", "material", "director", "below", "growth", "charles", "30", "7", "software", "always", "lines", "believed", "themselves", "increase", "la", "working", "code", "appeared", "defined", "primary", "points", "11", "cause", "brought", "historical", "announced", "larger", "award", "african", "park", "future", "method", "subject", "changes", "come", "federal", "security", "physical", "specific", "nuclear", "1998", "schools", "types", "greater", "jewish", "canada", "earlier", "too", "key", "legal", "sent", "catholic", "students", "caused", "stated", "effects", "relations", "elected", "widely", "characters", "surface", "25", "produce", "emperor", "saw", "mostly", "g", "museum", "recorded", "served", "date", "away", "names", "f", "parliament", "election", "returned", "personal", "seven", "our", "problems", "media", "percent", "club", "australia", "canadian", "association", "construction", "love", "reported", "1997", "uk", "h", "division", "japan", "results", "interest", "novel", "coast", "true", "territory", "video", "performance", "cultural", "replaced", "n", "longer", "release", "help", "complete", "britain", "added", "approximately", "problem", "actress", "1996", "highest", "directly", "producer", "units", "success", "involved", "via", "henry", "concept", "soon", "constitution", "attack", "scientific", "text", "need", "companies", "metal", "remains", "fire", "proposed", "products", "site", "conditions", "pope", "put", "australian", "numerous", "italy", "independence", "edition", "sources", "variety", "issue", "commercial", "idea", "laws", "successful", "famous", "direct", "smaller", "19th", "native", "18", "access", "organization", "16", "1990", "religion", "1994", "rome", "basic", "examples", "14", "cannot", "largely", "separate", "richard", "authority", "gas", "already", "regions", "pressure", "mother", "9", "blue", "past", "allow", "1995", "active", "give", "additional", "100", "basis", "towards", "police", "tradition", "create", "operations", "better", "san", "nearly", "knowledge", "shows", "rules", "speed", "politician", "centre", "1991", "13", "leader", "color", "classical", "era", "killed", "1992", "status", "peace", "whom", "article", "20th", "station", "contains", "revolution", "methods", "front", "highly", "sold", "entire", "relationship", "previous", "supported", "performed", "records", "green", "likely", "peoples", "ever", "hall", "philosophy", "street", "unit", "yet", "road", "financial", "thomas", "levels", "paris", "product", "go", "reached", "agreement", "letter", "night", "worlds", "estimated", "wife", "adopted", "report", "currently", "w", "discovered", "ground", "ten", "event", "board", "russia", "mainly", "journal", "training", "functions", "gold", "peter", "whole", "claimed", "1993", "internet", "teams", "collection", "property", "divided", "stories", "dutch", "medical", "wide", "rest", "analysis", "multiple", "placed", "temperature", "primarily", "changed", "county", "length", "1989", "ie", "money", "treaty", "shown", "programs", "summer", "race", "spain", "test", "academic", "enough", "relatively", "operation", "lake", "sense", "volume", "turn", "bank", "navy", "regular", "issues", "response", "simple", "amount", "centuries", "\\u2014", "chief", "ice", "asia", "me", "news", "literature", "memory", "letters", "billion", "ships", "individuals", "stage", "california", "element", "parties", "experience", "musical", "singer", "female", "michael", "worked", "troops", "done", "attempt", "web", "met", "assembly", "appear", "heavy", "17", "animals", "cells", "taking", "l", "1986", "find", "israel", "move", "forced", "married", "t", "committee", "simply", "eight", "songs", "powers", "objects", "difficult", "signed", "cell", "regional", "makes", "career", "get", "24", "applied", "sun", "latter", "fall", "chemical", "footballer", "provides", "saint", "appears", "mark", "institute", "reference", "matter", "global", "compared", "1980", "stars", "exist", "district", "initially", "campaign", "department", "section", "ireland", "probably", "account", "approach", "tv", "behind", "prior", "irish", "activity", "border", "blood", "1987", "ed", "super", "previously", "finally", "lack", "1984", "degree", "congress", "treatment", "appointed", "joined", "1979", "noted", "defense", "potential", "iii", "influenced", "21", "grand", "1988", "except", "image", "k", "machine", "1980s", "command", "properties", "1985", "50", "professional", "rise", "object", "refer", "passed", "fiction", "plan", "resulting", "car", "accepted", "industrial", "port", "playing", "cost", "completed", "library", "administration", "ad", "holy", "elections", "loss", "jews", "needed", "1982", "start", "origin", "opened", "definition", "ones", "annual", "ability", "1970s", "location", "suggested", "scholars", "climate", "armed", "decided", "louis", "derived", "nation", "washington", "big", "1983", "composed", "intended", "management", "operating", "daughter", "dead", "baseball", "featured", "reason", "province", "here", "arts", "ideas", "magazine", "acid", "marriage", "course", "ended", "notable", "transport", "male", "reduced", "engine", "carried", "applications", "feature", "things", "contemporary", "values", "birth", "democratic", "creation", "fourth", "1981", "actually", "airport", "activities", "earliest", "declared", "1975", "necessary", "represented", "child", "consists", "models", "remain", "lord", "upper", "square", "freedom", "materials", "22", "occur", "argued", "takes", "1970", "1960s", "increasing", "sexual", "equal", "speech", "distance", "believe", "older", "polish", "presence", "responsible", "allows", "environment", "internal", "hours", "claims", "combined", "frequently", "brother", "humans", "commission", "academy", "carbon", "plants", "paper", "failed", "read", "running", "alternative", "critical", "prize", "becoming", "opposition", "episode", "1976", "starting", "smith", "recently", "woman", "quality", "engineering", "bill", "claim", "exchange", "1990s", "call", "conflict", "urban", "imperial", "clear", "initial", "quickly", "beyond", "oxford", "festival", "19", "flight", "1978", "1973", "online", "existence", "workers", "contain", "ship", "jesus", "hold", "normal", "23", "hit", "extended", "etc", "conference", "notes", "1972", "resources", "iron", "remaining", "y", "risk", "weapons", "say", "note", "dna", "lived", "1971", "artists", "governor", "win", "digital", "continue", "coach", "ball", "singersongwriter", "distribution", "figure", "review", "positive", "brown", "1974", "mission", "identified", "disease", "0", "electric", "egypt", "direction", "pacific", "1968", "soldiers", "ethnic", "techniques", "1969", "bowl", "prince", "mary", "kings", "alexander", "sports", "versions", "28", "greatest", "expected", "ways", "reaction", "efforts", "poland", "scale", "resulted", "1977", "muslim", "decision", "spread", "agreed", "plant", "minor", "turned", "26", "offered", "respectively", "directed", "acts", "martin", "stone", "fields", "instance", "contrast", "unlike", "channel", "al", "pass", "introduction", "refers", "leaders", "inside", "winter", "tour", "mexico", "poor", "effective", "opposed", "wars", "occurred", "presented", "motion", "sector", "1967", "plays", "double", "table", "mean", "cup", "executive", "giving", "distinct", "immediately", "recognized", "places", "share", "asked", "issued", "allowing", "charge", "question", "politics", "occurs", "hard", "27", "bands", "officially", "appearance", "unique", "manager", "application", "buildings", "keep", "advanced", "ocean", "fully", "orthodox", "1945", "month", "protection", "completely", "faith", "growing", "launched", "competition", "bay", "convention", "chicago", "bridge", "powerful", "equipment", "stations", "standards", "spoken", "users", "prominent", "tax", "meeting", "justice", "40", "churches", "regarded", "animal", "host", "content", "attacks", "von", "formal", "cross", "comes", "entered", "formation", "railway", "heart", "gives", "observed", "zealand", "governments", "helped", "subsequently", "relative", "perhaps", "structures", "writer", "islamic", "figures", "universe", "something", "vote", "serve", "writers", "valley", "price", "foundation", "et", "removed", "income", "victory", "defeated", "1965", "develop", "sequence", "theatre", "subsequent", "equivalent", "deal", "mind", "domestic", "programming", "families", "focus", "joseph", "nine", "van", "says", "closed", "expansion", "know", "spent", "supply", "sets", "identity", "awarded", "negative", "cover", "organizations", "supreme", "1964", "prevent", "naval", "citizens", "moon", "solar", "expressed", "1966", "purpose", "1960", "intelligence", "communities", "your", "moving", "christ", "generation", "face", "goal", "medieval", "principle", "gained", "understanding", "difference", "wanted", "ordered", "portuguese", "devices", "whereas", "movie", "voice", "friends", "factors", "cut", "notably", "differences", "gods", "overall", "travel", "require", "becomes", "scotland", "korea", "extensive", "los", "cambridge", "mountains", "arms", "follows", "grew", "leaving", "friend", "told", "write", "depending", "showed", "queen", "search", "institutions", "fish", "specifically", "edward", "scene", "staff", "shot", "constant", "containing", "translation", "labour", "nor", "address", "kind", "cold", "29", "worldwide", "belief", "1962", "determined", "branch", "daily", "marked", "fuel", "1963", "literary", "increasingly", "situation", "refused", "destroyed", "reach", "behavior", "quantum", "impact", "physics", "mentioned", "going", "importance", "gdp", "attempts", "actual", "actions", "scottish", "core", "attention", "phase", "secretary", "connected", "mathematics", "toward", "opening", "authors", "week", "dynasty", "student", "flow", "weight", "creating", "signal", "controlled", "resistance", "causes", "weeks", "historian", "affairs", "heat", "rates", "expanded", "target", "requires", "31", "raised", "reduce", "sir", "solution", "invasion", "possibly", "easily", "round", "deep", "americans", "theories", "contact", "aid", "electronic", "medicine", "evolution", "census", "attempted", "communist", "championship", "cycle", "mountain", "combination", "existing", "decades", "saying", "pakistan", "nfl", "instruments", "inspired", "secondary", "care", "secret", "drive", "plans", "mobile", "measure", "dark", "device", "proved", "mathematical", "architecture", "hydrogen", "labor", "awards", "runs", "christianity", "critics", "2016", "liberal", "traditionally", "describe", "projects", "reign", "external", "processes", "1948", "countrys", "capacity", "broadcast", "formula", "brain", "principles", "am", "serious", "leadership", "typical", "1961", "dr", "choice", "tried", "reasons", "technical", "quite", "kept", "communication", "winning", "describes", "spirit", "tree", "sign", "golden", "context", "berlin", "crisis", "classes", "track", "significantly", "spring", "post", "computers", "maximum", "settlement", "fell", "represent", "windows", "reform", "sites", "ruled", "lives", "statement", "universal", "arrived", "1939", "oldest", "fighting", "avoid", "greece", "courts", "compounds", "alone", "texas", "providing", "oxygen", "o", "reports", "netherlands", "discovery", "dance", "display", "slightly", "hill", "fixed", "mixed", "hands", "effort", "offer", "arab", "achieved", "persons", "poet", "defence", "guitar", "joint", "receive", "thousands", "artist", "symbol", "officers", "ages", "bass", "particles", "radiation", "environmental", "steel", "room", "consider", "scientists", "lee", "zone", "route", "composer", "positions", "pay", "shared", "bodies", "wall", "match", "1944", "card", "developing", "organized", "planned", "le", "closely", "output", "frequency", "silver", "wave", "1941", "views", "failure", "combat", "conservative", "1947", "sex", "conducted", "heavily", "agriculture", "otherwise", "temple", "fleet", "rejected", "hot", "1950s", "meet", "drug", "journalist", "christians", "professor", "regarding", "granted", "shape", "entirely", "policies", "meant", "carry", "damage", "rare", "learning", "texts", "factor", "owned", "user", "aspects", "studied", "components", "translated", "atlantic", "forest", "studio", "houses", "unknown", "extremely", "1959", "territories", "felt", "nothing", "permanent", "shortly", "suffered", "crew", "publishing", "village", "sought", "follow", "captured", "guitarist", "trial", "bishop", "vol", "authorities", "leave", "forward", "1958", "swedish", "build", "1949", "ministry", "duke", "investment", "doctor", "strength", "1946", "marine", "korean", "publication", "perform", "bible", "constructed", "maintain", "coming", "contained", "fundamental", "recording", "goods", "condition", "listed", "stadium", "brothers", "widespread", "angeles", "1940", "safety", "purposes", "ranked", "obtained", "technique", "fifth", "maintained", "flag", "officials", "cards", "finished", "why", "useful", "temperatures", "popularity", "officer", "paid", "ultimately", "influential", "parents", "improved", "rail", "stop", "sides", "bring", "roughly", "seats", "captain", "string", "die", "1956", "demand", "agricultural", "engines", "1950", "employed", "covered", "ring", "file", "palace", "hebrew", "columbia", "linear", "minutes", "alliance", "suggests", "historians", "continues", "jones", "exists", "advantage", "18th", "1942", "limit", "split", "contract", "chain", "persian", "cast", "format", "zero", "expression", "visited", "u", "historically", "60", "corporation", "writings", "similarly", "reading", "1957", "calendar", "arabic", "crime", "density", "chosen", "rivers", "master", "visit", "networks", "greatly", "setting", "rose", "sciences", "principal", "administrative", "break", "selected", "yards", "message", "look", "wood", "ottoman", "opera", "poetry", "turkish", "images", "asian", "fight", "ratio", "ran", "islam", "determine", "practices", "towns", "magnetic", "dedicated", "defeat", "tribes", "piece", "settled", "2nd", "stable", "operated", "q", "respect", "accounts", "pieces", "crown", "indigenous", "page", "atomic", "acquired", "presidential", "senate", "normally", "der", "jack", "atoms", "residents", "truth", "UNKNOWN"], "mode": "markers", "marker": {"size": 12, "color": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000], "colorscale": "Viridis", "showscale": true}}], {"title": "Word Embeddings with Dimensionality Reduction", "hovermode": "closest", "xaxis": {"title": "Principal Component 1"}, "yaxis": {"title": "Principal Component 2"}}, {"showLink": true, "linkText": "Export to plot.ly"})</script>
<hr>
&copy; 2018 Nathaniel Dake

</div>
</div>
</body>
</html>
